{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 순환 신경망(RNN)\n",
    "\n",
    "지금까지 살펴본 feed forward형태의 신경망과는 달리 순환적 특징을 가진 순환 신경망(Recurrent neural network)를 다뤄보자.\n",
    "\n",
    "RNN은 특히 시계열 데이터를 잘 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 확률과 언어 모델\n",
    "\n",
    "### 5.1.1 word2vec을 확률 관점에서 바라보다\n",
    "\n",
    "t번째 단어를 target, 그 전후 단어(t-1번째, t+1번째)를 context로 생각해보자.\n",
    "\n",
    "위의 상황에서 CBOW모델의 확률은 $P(w_t | w_{t-1}, w_{t+1})$이다. (window_size = 1)\n",
    "\n",
    "이번엔 비대칭 window_size를 갖는, 왼쪽 window = 2, 오른쪽 window = 0인 상황을 생각해보자.\n",
    "\n",
    "수식으로 표현하면 다음과 같다. \n",
    "\n",
    "$$P(w_t | w_{t-2}, w_{t-1})$$\n",
    "\n",
    "cross entrophy loss에 의해 손실함수를 유도하면 다음과 같다.\n",
    "\n",
    "$$ L = -\\log P(w_t | w_{t-2}, w_{t-1}) $$\n",
    "\n",
    "CBOW 모델의 학습으로 수행하는 일은 말뭉치 전체의 손실 함수의 총합을 최소화하는 가중치 매개변수를 찾는 것이다.\n",
    "\n",
    "이처럼 CBOW 모델을 학습시키는 본래 목적은 맥락으로부터 타깃을 정확하게 추측하는 것이다.\n",
    "\n",
    "그럼 CBOW 모델의 본래 목적인 '맥락으로부터 타깃을 추측하는 것'은 어디에 사용할 수 있을까?\n",
    "\n",
    "이때 '언어 모델'이 등장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 언어 모델\n",
    "\n",
    "P195에 있는 마지막 수식 잘못 된거 아닌가? $\\prod_{t=1}^m P(w_t | w_1, \\cdots, w_{t-1})$ 아닌가?\n",
    "\n",
    "__언어 모델(Language Model)__은 단어 나열에 확률을 부여한다. 특정한 단어의 시퀸스에 대해서, 그 시퀸스가 일어날 가능성이 어느 정도인지를 확률로 평가하는 것이다.\n",
    "\n",
    "언어 모델을 수식으로 표현해보자.\n",
    "\n",
    "$w_1, \\cdots, w_m$이라는 m개 단어로 된 문장을 생각해보자. 이때 단어가 $w_1, \\cdots, w_m$이라는 순서로 출현할 확률을 $P(w_1, \\cdots, w_m)$이라고 하자.\n",
    "\n",
    "이 동시 확률 $P(w_1, \\cdots, w_m)$ 은 사후 확률을 사용하여 다음과 같이 분해할 수 있다.\n",
    "\n",
    "$$\\begin{align*}P(w_1, \\cdots, w_m) &= P(w_m | w_{1}, \\cdots, w_{m-1})P(w_{m-1} | w_{1}, \\cdots, w_{m-2})\\cdots P(w_3 | w_1, w_2)P(w_2 | w_1)P(w_1) \\\\ &= \\prod_{t=1}^m P(w_t | w_1, \\cdots, w_{t-1})\\end{align*}$$\n",
    "\n",
    "정리하자면, 우리의 목표는 $P(w_t | w_1, \\cdots, w_{t-1})$ 이라는 확률을 얻는 것이다.\n",
    "\n",
    "이 확률을 계산할 수 있다면 언어 모델의 동시 확률 $P(w_1, \\cdots, w_m)$을 구할 수 있다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-3.png\" width=\"70%\" height=\"50%\">\n",
    "\n",
    "\n",
    "### 5.1.3 CBOW 모델을 언어 모델로?\n",
    "\n",
    "word2vec의 CBOW 모델을 언어 모델에 적용하려면 어떻게 하면 좋을까?\n",
    "\n",
    "맥락의 크기를 특정 값으로 한정하여 근사적으로 나타낼 수 있다.\n",
    "\n",
    "$$\\begin{align*}P(w_1, \\cdots, w_m) &= \\prod_{t=1}^m P(w_t | w_1, \\cdots, w_{t-1}) \\\\ &\\approx \\prod_{t=1}^m P(w_t | w_{t-2}, w_{t-1}\\end{align*}$$ \n",
    "\n",
    "위에서는 맥락을 왼쪽 2개의 단어로 한정한다. 상황에 따라 맥락의 크기는 달라 질 수 있다.\n",
    "\n",
    "우리가 이전에 보았던 CBOW 모델은 은닉층에서 단어벡터들이 더해지므로 맥락의 단어 순서는 무시된다. 예를 들어 (you, say)와 (say, you)가 같다.\n",
    "\n",
    "이상적으로 맥락을 고려한 단어 순서도 고려한 모델이 바람직하다. 이를 위해 다음 그림의 오른쪽과 같이 맥락의 단어 벡터를 은닉층에서 연결하는 방식을 생각할 수 있다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-5.png\" width=\"70%\" height=\"50%\">\n",
    "\n",
    "그러나 연결하는 방식을 취하면 맥락의 크기에 비례해 자우치 매개변수도 늘어나는 단점이 있다.\n",
    "\n",
    "이 단점을 해결한 것이 RNN이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 RNN이란?\n",
    "\n",
    "Recurrent Neural Network의 약자로 순환하는 신경망을 뜻한다.\n",
    "\n",
    "### 5.2.1 순환하는 신경망\n",
    "\n",
    "신경망에 순환하는 경로가 존재하여 이 경로를 따라 데이터가 순환되어 과거의 정보를 기억하는 동시에 최신 데이터로 갱신될 수 있다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-6.png\" width=\"30%\" height=\"30%\">\n",
    "\n",
    "이는 시계열 데이터 $(\\textbf{x}_0, \\textbf{x}_1, \\cdots, \\textbf{x}_t, \\cdots)$가 RNN 계층에 입력되고 $(\\textbf{h}_0, \\textbf{h}_1, \\cdots, \\textbf{h}_t, \\cdots)$가 출력됨을 표현한 것이다.\n",
    "\n",
    "각 시각에 입력되는 $(\\textbf{x}_t)$는 벡터라고 가정하자. 문장을 다루는 경우 각 단어의 분산 표현이 $\\textbf{x}_t$가 된다.\n",
    "\n",
    "이 분산 표현이 순서대로 하나씩 RNN 계층에 입력되는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 순환 구조 펼치기\n",
    "\n",
    "다음은 RNN 계층의 순환 구조를 펼친 것인데 이때까지 본 신경망들과 다르게 다수의 RNN 계층 모두가 실제로는 '같은 계층'인 것이 특징이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-8.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "각 시각의 RNN 계층은 그 계층으로의 입력과 1개 전의 RNN 계층으로부터의 출력을 받는다. \n",
    "\n",
    "그리고 이 두 정보를 바탕으로 출력값을 계산한다. 식은 다음과 같다.\n",
    "\n",
    "$$ \\textbf{h}_t = tanh(\\textbf{h}_{t-1}\\textbf{W}_h+\\textbf{x}_t\\textbf{W}_x+\\textbf{b})$$ \n",
    "\n",
    "$\\textbf{W}_x$는 입력x를 출력h로 변환하기 위한 가중치, $\\textbf{W}_h$는 출력을 다음 시각의 출력으로 변환하기 위한 가중치이다. $\\textbf{h}_{t-1}$과 $\\textbf{x}_t$는 행벡터이다.\n",
    "\n",
    "RNN의 $\\textbf{h}$는 '상태'를 기억해 시각이 1 스텝 진행될 떄마다 위의 형태로 갱신된다. 많은 문헌에서 RNN의 출력 $\\textbf{h}_t$를 __은닉 상태(hidden state)__ 혹은 __은닉 상태 벡터(hidden state vector)__라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 BPTT\n",
    "\n",
    "RNN에서의 오차역전파를 Backpropagation Through Time, 줄여서 BPTT라고 부른다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-10.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "그러나 문제가 하나 있다. 긴 시계열 데이터를 학습할 때 시간 크기가 커지는 것에 비례하여 BPTT가 소비하는 컴퓨팅자원도 증가하고, 역전파 시의 기울기가 불안정해지는 것도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Truncated BPTT\n",
    "\n",
    "큰 시계열 데이터를 취급할 때는 흔히 신경망 연결을 적당한 길이로 끊는다. 적당한 지점에서 잘라내어 작은 신경망 여러 개로 만든다는 아이디어다.\n",
    "\n",
    "이 잘라낸 작은 신경망에서 오차역전파법을 수행한다. 이것이 바로 __Truncated BPTT__라는 기법이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-11.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "반드시 유의해야 할 점은 역전파의 연결은 끊어지지만, 순전파의 연결은 끊어지지 않는다는 점이다. 그러므로 RNN을 학습시킬 때는 순전파가 연결된다는 점을 고려해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.5 Truncated BPTT의 미니배치 학습\n",
    "\n",
    "미니배치 학습을 시키기 위해서 각 데이터를 미니배치 사이즈에 맞게 이동시켜야 한다.\n",
    "\n",
    "다음은 미니배치 사이즈가 500, BPTT를 10개 단위로 학습할 때의 그림이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-15.png\" width=\"60%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 RNN 구현\n",
    "\n",
    "우리가 지금부터 구현해야 할 것은 Truncated BPTT 방식의 학습을 따르는 가로 방향으로 성장한 신경망이다. \n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-16.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "길이가 T인 시계열 데이터가 있다고 하자. 그리고 각 시각의 은닉 상태를 T개 출력한다. 그리고 모듈화를 생각해, 옆으로 성장한 신경망을 하나의 계층으로 구현하자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-17.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "즉, $(\\textbf{x}_0, \\textbf{x}_1, \\cdots, \\textbf{x}_{T-1})$을 묶은 __xs__를 입력하면 $(\\textbf{h}_0, \\textbf{h}_1, \\cdots, \\textbf{h}_{T-1})$을 묶은 __hs__를 출력하는 단일 계층으로 볼 수 있다.\n",
    "\n",
    "이때 Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층을 'RNN 계층'이라 하고, T개 단계분의 작업을 한꺼번에 처리하는 계층을 'Time RNN 계층'이라 한다.(앞에 'Time'을 붙인건 독자적인 명명규칙이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 RNN 계층 구현\n",
    "\n",
    "미니배치 크기가 N, 입력 벡터의 차원수가 D, 은닉 상태 벡터의 차원 수가 H라면, $\\textbf{h}_t$의 사이즈는 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-18.png\" width=\"60%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        # 매개변수를 인스턴스 변수 params에 리스트로 저장\n",
    "        self.params = [Wx, Wh, b]\n",
    "        # 각 매개변수에 대응하는 형태로 기울기를 초기화한 수 grads에 저장\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        # 역전파 계산 시 사용하는 중간 데이터를 담을 cache를 None으로 초기화\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_prev^2)\n",
    "        db = np.sum(dt, axis =0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 계층의 순전파를 계산그래프로 나타내면 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-19.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "역전파는 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-20.png\" width=\"50%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Time RNN 계층 구현\n",
    "\n",
    "RNN 계층의 은닉 상태 __h__를 인스턴스 변수로 유지한다. 이 변수를 다음 그림과 같이 은닉 상태를 '인계'받는 용도로 사용한다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-22.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "이처럼 우리는 RNN 계층의 은닉 상태를 Time RNN 계층에서 관리하기로 한다.\n",
    "\n",
    "이렇게 하면 Time RNN 사용자는 RNN 계층 사이에서 은닉 상태를 '인계하는 작업'을 생각하지 않아도 된다는 장점이 있다.\n",
    "\n",
    "그리고 이 기능을 stateful이라는 인수로 조정할 수 있게 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TImeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        sefl.params = [Wx. Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        # 다수의 RNN 계층을 리스트로 저장한다.\n",
    "        self.layers = None\n",
    "        \n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs    \n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            # 합산된 기울기\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh) \n",
    "            dxs[:, t, :] = dx\n",
    "            \n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 Time RNN 계층의 역전파 구현이다. 역전파의 계산 그래프는 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-23.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "Truncated BPTT를 수행하기 때문에 이 블록의 이전 시각 역전파는 필요하지 않다. 단, 이전 시각의 은닉 상태 기울기는 인스턴스 변수 dh에 저장해 놓는다.\n",
    "\n",
    "전체적인 그림은 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-24.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "여기에서 주의점은 RNN 계층의 순전파에서는 출력이 2개로 분기된다는 것이다. 순전파 시 분기했을 경우, 그 역전파에서는 각 기울기가 합산되어 전해진다.\n",
    "\n",
    "따라서 역전파 시 RNN 계층에는 합산된 기울기 $(\\textbf{dh}_t+\\textbf{dh}_{next})$가 입력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 시계열 데이터  처리 계층 구현\n",
    "\n",
    "앞으로 RNN을 사용한 언어 모델은 영어로 RNN Language Model이므로 앞으로 RNNLM이라 칭하겠다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 RNNLM의 전체 그림\n",
    "\n",
    "다음은 RNNLM의 신경망에 'you say goodbye and I say hello.'를 학습시킨 그림이다.\n",
    "\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-26.png\" width=\"50%\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Time 계층 구현\n",
    "\n",
    "시계열 데이터를 한꺼번에 처리하는 계층을 Time Embedding, Time Affine 형태의 이름으로 구현하겠다.\n",
    "\n",
    "이 Time XX 계층들을 다 만들면 우리가 원하는 신경망을 구현한다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-27.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "Time Embedding과 Time Affine 계층은 어렵지 않다.\n",
    "\n",
    "아래처럼 각 계층을 T개 준비해서, 각 시각의 데이터를 개별적으로 처리하면 된다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-28.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "근데 Time Affine 계층은 단순히 Affine 계층 T개를 이용하는 방식 대신 행렬 계산으로 한꺼번에 처리하는, 효율 좋은 방식으로 구현하는 것이 좋다.\n",
    "\n",
    "Softmax 계층을 구현하자. Softmax 계층은 손실 오차를 구하는 Cross Entropy Error 계층도 함께 구현하자.\n",
    "\n",
    "여기에서는 다음 사진과 같은 구성의 Time Softmax with Loss 계층으로 구현할 것이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-29.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "그림에서 보듯, T개의 Softmax with Loss 계층 각각이 손실을 산출한다. 그리고 그 손실들을 합산해 평균한 값이 최종 손실이 된다.\n",
    "\n",
    "$$ L = {1 \\over T}(L_0 + L_1 + \\cdots + L_{T-1})$$\n",
    "\n",
    "    * 참고\n",
    "      \n",
    "      이 책의 Softmax with Loss 계층은 미니배치에 해당하는 손실의 평균을 구했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 RNNLm 학습과 평가\n",
    "\n",
    "### 5.5.1 RNNLM 구현\n",
    "\n",
    "SimpleRnnlm이라는 이름의 클래스로 RNNLM신경망을 구현해보자.\n",
    "\n",
    "계층 구성은 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-30.png\" width=\"40%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        # Xavier 초깃값 사용\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ] # Truncated BPTT로 학습\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)    \n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 언어 모델의 평가\n",
    "\n",
    "언어 모델은 주어진 과거 단어로부터 다음에 출현할 단어의 확률분포를 출력한다.\n",
    "\n",
    "\n",
    "이때 언어 모델의 예측 성능을 평가하는 척도로 __Perplexity__를 자주 이용한다.\n",
    "\n",
    "perplexity는 간단히 말하면 '확률의 역수'이다. 아래의 그림을 예를 들면 모델1의 언어 모델에서 'you'단어를 학습시켰을 때 정답이 'say'라면, 그 확률은 .8이다. 이때의 perplexity는 ${1 \\over 0.8} = 1.25$이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 5-32.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "모델2의 정답인 'say'의 확률이 .2라고 예측했다. 이때의 perplexity는 ${1 \\over 0.2}=5$이다.\n",
    "\n",
    "1.25나 5이라는 값은 직관적으로 해석해보자.\n",
    "\n",
    "이 값은 '분기수'(number of branches)로 해석할 수 있다. 분기 수란 다음에 취할 수 있는 선택사항(다음에 출현할 수 있는 단어의 후보 수)를 말한다.\n",
    "\n",
    "앞의 예에서, 좋은 모델이 예측한 '분기 수'가 1.25라는 것은 다음에 출현할 수 있는 단어의 후보를 1개 정도로 좁혔다는 뜻이다.\n",
    "\n",
    "Perplexity는 다음 공식에 따라 계산한다.\n",
    "\n",
    "$$ L = -{1 \\over N}\\sum_{n}\\sum_{k} t_{nk}\\log y_{nk}$$\n",
    "$$ perplexity = e^L$$\n",
    "\n",
    "N은 데이터의 총개수이다. $t_n$은 원핫 벡터로 나타낸 정답 레이블이고 $t_{nk}$는 n개째 데이터의 k번째 값을 의미한다. 그리고 $y_{nk}$는 확률분포를 나타낸다(신경망에서는 Softmax의 출력)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.3 RNNLM의 학습 코드\n",
    "\n",
    "PTB 데이터 셋을 이용해 RNNLM 학습을 수행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기 : '1000', 어휘 수 : '418'\n",
      "| 에폭 '1' | perplexity '271.22'\n",
      "| 에폭 '2' | perplexity '201.64'\n",
      "| 에폭 '3' | perplexity '193.19'\n",
      "| 에폭 '4' | perplexity '189.19'\n",
      "| 에폭 '5' | perplexity '182.53'\n",
      "| 에폭 '6' | perplexity '179.74'\n",
      "| 에폭 '7' | perplexity '173.52'\n",
      "| 에폭 '8' | perplexity '165.80'\n",
      "| 에폭 '9' | perplexity '154.66'\n",
      "| 에폭 '10' | perplexity '141.98'\n",
      "| 에폭 '11' | perplexity '127.25'\n",
      "| 에폭 '12' | perplexity '112.16'\n",
      "| 에폭 '13' | perplexity '98.32'\n",
      "| 에폭 '14' | perplexity '83.16'\n",
      "| 에폭 '15' | perplexity '69.37'\n",
      "| 에폭 '16' | perplexity '58.85'\n",
      "| 에폭 '17' | perplexity '48.77'\n",
      "| 에폭 '18' | perplexity '40.02'\n",
      "| 에폭 '19' | perplexity '33.32'\n",
      "| 에폭 '20' | perplexity '27.81'\n",
      "| 에폭 '21' | perplexity '22.82'\n",
      "| 에폭 '22' | perplexity '18.71'\n",
      "| 에폭 '23' | perplexity '15.99'\n",
      "| 에폭 '24' | perplexity '13.11'\n",
      "| 에폭 '25' | perplexity '10.80'\n",
      "| 에폭 '26' | perplexity '9.46'\n",
      "| 에폭 '27' | perplexity '7.83'\n",
      "| 에폭 '28' | perplexity '6.73'\n",
      "| 에폭 '29' | perplexity '5.91'\n",
      "| 에폭 '30' | perplexity '5.07'\n",
      "| 에폭 '31' | perplexity '4.36'\n",
      "| 에폭 '32' | perplexity '3.89'\n",
      "| 에폭 '33' | perplexity '3.39'\n",
      "| 에폭 '34' | perplexity '2.95'\n",
      "| 에폭 '35' | perplexity '2.83'\n",
      "| 에폭 '36' | perplexity '2.39'\n",
      "| 에폭 '37' | perplexity '2.20'\n",
      "| 에폭 '38' | perplexity '2.03'\n",
      "| 에폭 '39' | perplexity '1.86'\n",
      "| 에폭 '40' | perplexity '1.73'\n",
      "| 에폭 '41' | perplexity '1.73'\n",
      "| 에폭 '42' | perplexity '1.59'\n",
      "| 에폭 '43' | perplexity '1.55'\n",
      "| 에폭 '44' | perplexity '1.48'\n",
      "| 에폭 '45' | perplexity '1.42'\n",
      "| 에폭 '46' | perplexity '1.41'\n",
      "| 에폭 '47' | perplexity '1.36'\n",
      "| 에폭 '48' | perplexity '1.30'\n",
      "| 에폭 '49' | perplexity '1.26'\n",
      "| 에폭 '50' | perplexity '1.26'\n",
      "| 에폭 '51' | perplexity '1.27'\n",
      "| 에폭 '52' | perplexity '1.27'\n",
      "| 에폭 '53' | perplexity '1.21'\n",
      "| 에폭 '54' | perplexity '1.21'\n",
      "| 에폭 '55' | perplexity '1.18'\n",
      "| 에폭 '56' | perplexity '1.17'\n",
      "| 에폭 '57' | perplexity '1.16'\n",
      "| 에폭 '58' | perplexity '1.17'\n",
      "| 에폭 '59' | perplexity '1.15'\n",
      "| 에폭 '60' | perplexity '1.19'\n",
      "| 에폭 '61' | perplexity '1.23'\n",
      "| 에폭 '62' | perplexity '1.16'\n",
      "| 에폭 '63' | perplexity '1.14'\n",
      "| 에폭 '64' | perplexity '1.12'\n",
      "| 에폭 '65' | perplexity '1.10'\n",
      "| 에폭 '66' | perplexity '1.10'\n",
      "| 에폭 '67' | perplexity '1.09'\n",
      "| 에폭 '68' | perplexity '1.09'\n",
      "| 에폭 '69' | perplexity '1.08'\n",
      "| 에폭 '70' | perplexity '1.08'\n",
      "| 에폭 '71' | perplexity '1.08'\n",
      "| 에폭 '72' | perplexity '1.08'\n",
      "| 에폭 '73' | perplexity '1.08'\n",
      "| 에폭 '74' | perplexity '1.07'\n",
      "| 에폭 '75' | perplexity '1.07'\n",
      "| 에폭 '76' | perplexity '1.07'\n",
      "| 에폭 '77' | perplexity '1.07'\n",
      "| 에폭 '78' | perplexity '1.07'\n",
      "| 에폭 '79' | perplexity '1.07'\n",
      "| 에폭 '80' | perplexity '1.06'\n",
      "| 에폭 '81' | perplexity '1.06'\n",
      "| 에폭 '82' | perplexity '1.07'\n",
      "| 에폭 '83' | perplexity '1.07'\n",
      "| 에폭 '84' | perplexity '1.06'\n",
      "| 에폭 '85' | perplexity '1.07'\n",
      "| 에폭 '86' | perplexity '1.08'\n",
      "| 에폭 '87' | perplexity '1.07'\n",
      "| 에폭 '88' | perplexity '1.12'\n",
      "| 에폭 '89' | perplexity '1.20'\n",
      "| 에폭 '90' | perplexity '1.17'\n",
      "| 에폭 '91' | perplexity '1.15'\n",
      "| 에폭 '92' | perplexity '1.10'\n",
      "| 에폭 '93' | perplexity '1.07'\n",
      "| 에폭 '94' | perplexity '1.06'\n",
      "| 에폭 '95' | perplexity '1.06'\n",
      "| 에폭 '96' | perplexity '1.05'\n",
      "| 에폭 '97' | perplexity '1.05'\n",
      "| 에폭 '98' | perplexity '1.05'\n",
      "| 에폭 '99' | perplexity '1.04'\n",
      "| 에폭 '100' | perplexity '1.04'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from ch05.simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수 \n",
    "time_size = 5 # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = .1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기 (전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1] # 입력 (처음부터 마지막-1)\n",
    "ts = corpus[1:] # 출력 (정답 레이블, 두 번째부터 마지막)\n",
    "data_size = len(xs)\n",
    "print (\"말뭉치 크기 : '{0}', 어휘 수 : '{1}'\".format(corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size + time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# (1) 각 미니배치에서 샘플을 읽기 시작 위치를 계산\n",
    "jump  = (corpus_size - 1) // batch_size\n",
    "offsets = [j * jump for j in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # (2) 미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i ,t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "            \n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    # (3) 에폭마다 perplexity 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print (\"| 에폭 '{0}' | perplexity '{1:.2f}'\".format(epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : '0.21'\n"
     ]
    }
   ],
   "source": [
    "num = 0.2145443\n",
    "print (\"a : '{0:.2f}'\".format(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.4 RNNLM의 Trainer 클래스\n",
    "\n",
    "이 클래스는 방금 수행한 RNNLM 학습을 클래스 안으로 숨겨준다. 그래서 앞 절의 학습 코드를 RnnlmTrainer 클래스를 사용해 다시 쓰면 다음과 같이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 417.42\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 385.52\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 263.42\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 226.43\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 214.50\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 212.06\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 202.33\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 200.98\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 195.73\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 190.76\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 192.82\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 188.80\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 191.94\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 186.91\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 186.45\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 190.59\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 188.69\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 184.01\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 180.17\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 180.50\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 177.95\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 175.82\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 177.31\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 174.16\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 167.43\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 168.64\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 166.04\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 165.37\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 159.47\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 154.96\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 152.59\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 147.09\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 7[s] | 퍼플렉서티 147.20\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 144.46\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 138.04\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 133.51\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 8[s] | 퍼플렉서티 133.18\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 124.82\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 122.34\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 9[s] | 퍼플렉서티 117.23\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 110.95\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 109.68\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 106.24\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 10[s] | 퍼플렉서티 102.61\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 11[s] | 퍼플렉서티 94.36\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 11[s] | 퍼플렉서티 91.77\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 11[s] | 퍼플렉서티 88.90\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 11[s] | 퍼플렉서티 85.60\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 12[s] | 퍼플렉서티 81.99\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 12[s] | 퍼플렉서티 75.56\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 12[s] | 퍼플렉서티 73.64\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 12[s] | 퍼플렉서티 68.13\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 12[s] | 퍼플렉서티 66.67\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 13[s] | 퍼플렉서티 62.90\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 13[s] | 퍼플렉서티 60.20\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 13[s] | 퍼플렉서티 55.33\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 13[s] | 퍼플렉서티 53.79\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 14[s] | 퍼플렉서티 50.73\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 14[s] | 퍼플렉서티 48.34\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 14[s] | 퍼플렉서티 44.72\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 14[s] | 퍼플렉서티 42.60\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 15[s] | 퍼플렉서티 41.80\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 15[s] | 퍼플렉서티 39.39\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 15[s] | 퍼플렉서티 37.32\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 15[s] | 퍼플렉서티 33.38\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 16[s] | 퍼플렉서티 32.11\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 16[s] | 퍼플렉서티 30.36\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 16[s] | 퍼플렉서티 28.95\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 16[s] | 퍼플렉서티 27.84\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 17[s] | 퍼플렉서티 27.44\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 17[s] | 퍼플렉서티 25.06\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 17[s] | 퍼플렉서티 23.19\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 17[s] | 퍼플렉서티 22.37\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 18[s] | 퍼플렉서티 20.63\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 18[s] | 퍼플렉서티 19.84\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 18[s] | 퍼플렉서티 19.89\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 18[s] | 퍼플렉서티 18.42\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 19[s] | 퍼플렉서티 16.78\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 19[s] | 퍼플렉서티 16.22\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 19[s] | 퍼플렉서티 15.12\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 20[s] | 퍼플렉서티 14.77\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 20[s] | 퍼플렉서티 14.43\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 20[s] | 퍼플렉서티 13.23\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 20[s] | 퍼플렉서티 13.11\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 21[s] | 퍼플렉서티 12.15\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 21[s] | 퍼플렉서티 11.67\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 21[s] | 퍼플렉서티 11.10\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 22[s] | 퍼플렉서티 9.62\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 22[s] | 퍼플렉서티 10.32\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 23[s] | 퍼플렉서티 9.26\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 23[s] | 퍼플렉서티 8.76\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 24[s] | 퍼플렉서티 8.44\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 24[s] | 퍼플렉서티 7.99\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 24[s] | 퍼플렉서티 7.75\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 25[s] | 퍼플렉서티 8.05\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 25[s] | 퍼플렉서티 7.46\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 25[s] | 퍼플렉서티 6.85\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 25[s] | 퍼플렉서티 6.49\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 26[s] | 퍼플렉서티 6.20\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 26[s] | 퍼플렉서티 5.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from ch05.simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리해보자면 다음과 같은 순서대로 작업이 이루어진다.\n",
    "\n",
    "1. 미니배치를 '순차적'으로 만들어\n",
    "\n",
    "2. 모델의 순전파와 역전파를 호출하고\n",
    "\n",
    "3. 옵티마이저로 가중치를 갱신하고\n",
    "\n",
    "4. perplexity를 구한다.\n",
    "\n",
    "## 5.6 이번 장에서 배운 내용\n",
    "\n",
    "    * RNN은 순환하는 경로가 있고, 이를 통해 내부에 '은닉 상태'를 기억할 수 있다.\n",
    "    \n",
    "    * RNN의 순환 경로를 펼침으로써 다수의 RNN 계층이 연결된 신경망으로 해석할 수 있으며, 보통의 오차역전파법으로 학습할 수 있다.(=BPTT)\n",
    "    \n",
    "    * 긴 시계열 데이터를 학습할 때는 데이터를 적당한 길이씩 모으고(이를 '블록'이라 한다.), 블록 단위로 BPTT에 의한 학습을 수행한다(=Truncated BPTT).\n",
    "    \n",
    "    * Truncated BPTT에서는 역전파의 연결만 끊는다.\n",
    "    \n",
    "    * Truncated BPTT에서는 순전파의 연결을 유지하기 위해 데이터를 '순차적'으로 입력해야 한다.\n",
    "    \n",
    "    * 언어 모델은 단어 시퀸스를 확률로 해석한다.\n",
    "    \n",
    "    * RNN 계층을 이용한 조건부 언어 모델은(이론적으로는) 그때까지 등장한 모든 단어의 정보를 기억할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 게이트가 추가된 RNN\n",
    "\n",
    "앞 장에서 본 RNN은 순환 경로를 포함해 과거의 정보를 기억할 수 있다. 그러나 단점이 있는데 장기 기억을 못한다는 것이다.\n",
    "\n",
    "그래서 이번 장에선 '게이트'라는 구조가 더해져 기본RNN의 단점을 극복한 LSTM과 GRU에 대해 알아보자.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 RNN의 문제점\n",
    "\n",
    "기본 RNN은 BPTT에서 기울기 소실 혹은 기울기 폭발이 일어나서 장기 기억이 힘들다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 기울기 소실 또는 기울기 폭발\n",
    "\n",
    "다음과 같은 예시를 보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-3.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "'?'에 들어갈 정답은 'Tom'이다. 이 문제에 올바른 대답을 하기 위해선 'Tom이 방에서 Tv를 보고 있음'과 '그 방에 Mary가 들어옴'이란 정보를 기억해둬야 한다. 다시 말해 이런 정보를 RNN 계층의 은닉 상태에 인코딩해 보관해야 한다.\n",
    "\n",
    "RNNLM관점에서 봐보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-4.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "RNN 계층이 과거 방향으로 '의미 있는 기울기'를 전달함으로써 시간 방향의 의존 관계를 학습할 수 있는 것이다. \n",
    "\n",
    "이때 기울기는 학습해야 할 의미가 있는 정보가 들어 있고, 그것을 과거로 전달함으로써 장기 의존 관계를 학습한다. \n",
    "\n",
    "하지만 만약 이 기울기가 중간에 사그라들면 가중치 매개변수는 전혀 갱신되지 않게 된다. 즉, 장기 의존 관계를 학습할 수 없게 된다.\n",
    "\n",
    "이런 경우 단순한 RNN 계층에서는 시간을 거슬러 올라갈수록 기울기가 작아지거나 혹은 커질 수 있으며, 대부분 둘 중 하나이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 기울기 소실과 기울기 폭발의 원인\n",
    "\n",
    "RNN 계층에서 기울기 소실 or 폭발이 일어나는 원인을 알아보자.\n",
    "\n",
    "다음은 $tanh(x)$와 $tanh(x)$의 미분 그래프이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-6.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "미분 값은 1이하이고 $x$가 0으로 멀어질수록 작아진다. 다시 말해서 역전파에서는 기울기가 $tanh$노드를 지날 때마다 값은 계속 작아진다.\n",
    "\n",
    "다음은 MatMul노드이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-7.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "전개를 단순화하기 위해 tanh노드를 무시하기로 하자. 그럼 RNN 계층의 역전파 시 기울기는 위와 같은 그림으로 나타난다.\n",
    "\n",
    "Matmul노드에서 역전파는 $\\textbf{dhW}_\\textbf{h}^T$라는 행렬 곱으로 기울기를 계산한다.\n",
    "\n",
    "그리고 같은 계산을 시계열 데이터의 시간 크기만큼 반복한다. 여기에서 주목해야 할 점은 매번 똑같은 가중치인 $\\textbf{W}_\\textbf{h}$가 사용된다는 점이다.\n",
    "\n",
    "그러면 역전파 시 기울기는 Matmul 노드를 지날 때 어떻게 변할까?\n",
    "\n",
    "코드를 통해 알아보자\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 2 # 미니배치 크기\n",
    "H = 3 # 은닉 상태 벡터의 차원 수 \n",
    "T = 20 # 시계열 데이터의 길이\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3) # 재현할 수 있도록 난수의 시드 고정\n",
    "Wh = np.random.randn(H, H)\n",
    "\n",
    "norm_list_1 = []\n",
    "for t in range(T):\n",
    "    dh = np.matmul(dh, Wh.T)이ㅅ\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.4684068094579303,\n",
       " 3.3357049741610365,\n",
       " 4.783279375373182,\n",
       " 6.279587332087612,\n",
       " 8.080776465019053,\n",
       " 10.251163032292936,\n",
       " 12.936063506609896,\n",
       " 16.276861327786712,\n",
       " 20.45482961834598,\n",
       " 25.688972842084684,\n",
       " 32.25315718048336,\n",
       " 40.48895641683869,\n",
       " 50.8244073070191,\n",
       " 63.79612654485427,\n",
       " 80.07737014308985,\n",
       " 100.5129892205125,\n",
       " 126.16331847536823,\n",
       " 158.35920648258823,\n",
       " 198.7710796761195,\n",
       " 249.495615421267]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wh의 초깃값을 np.random.randn(H,H) * .5로 하면 급격하게 감소한다. 즉, 기울기 소실이 발생한다.\n",
    "\n",
    "Wh이 어떻게 변하는지 보기 위해선 행렬의 '특잇값'을 봐야한다.\n",
    "\n",
    "이 특잇값의 값이 1보다 큰지 여부를 보면 기울기 크기가 어떻게 변할지 예측할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 기울기 폭발 대책\n",
    "\n",
    "기울기 폭발 해결책 먼저 알아보자.\n",
    "\n",
    "먼저 전통적인 기법을 알아보자. 바로 __기울기 클리핑(gradient clipping)__이다. 의사코드는 다음과 같다.\n",
    "\n",
    "$$ if\\;\\lVert \\hat{\\textbf{g}} \\rVert \\ge threshold: \\\\ \\hat{\\textbf{g}} = {threshold \\over \\lVert \\hat{\\textbf{g}} \\rVert}\\hat{\\textbf{g}}$$\n",
    "\n",
    "여기에서는 신경망에서 사용되는 모든 매개변수에 대한 기울기를 하나로 처리한다고 가정하고, 이를 기호 $\\lVert \\hat{\\textbf{g}} \\rVert $으로 표기했다.\n",
    "\n",
    "이제 기울기 클리핑을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dW1 = np.random.randn(3, 3) * 10\n",
    "dW2 = np.random.randn(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)    \n",
    "    \n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 소실과 LSTM\n",
    "\n",
    "기울기 소실도 큰 문제이다. 이번 장의 핵심 주제인 '게이트'가 추가된 RNN인 LSTM으로 기울기 소실을 해결해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 LSTM의 인터페이스\n",
    "\n",
    "LSTM의 계층을 살펴보기 앞서 계산 그래프를 단순화하는 도법을 하나 도입하자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-10.png\" width=\"80%\" height=\"30%\">\n",
    "\n",
    "위와 같이 변경된 계산 그래프로 RNN와 LSTM을 비교해보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-11.png\" width=\"80%\" height=\"30%\">\n",
    "\n",
    "보다시피 LSTM에는 __c__라는 경로가 있다는 차이가 있다. 이 __c__를 __기억 셀(memory cell)__이라고 하며, LSTM 전용의 기억 메커니즘이다.\n",
    "\n",
    "기억 셀의 특징은 데이터를 자기 자신으로만(LSTM 계층 내에서만) 주고받는다는 것이다. 즉, LSTM 계층 내에서만 완결되고, 다른 계층으로는 출력되지 않는다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 LSTM 계층 조립하기\n",
    "\n",
    "이번 설명은 [understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)을 참고했다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-12.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "LSTM 계층 안에서 이루어지는 계산은 위와 같다.\n",
    "\n",
    "'게이트'라는 기능에 대해 알아보자. 이름에서 알 수 있듯이 게이트는 데이터의 흐름을 제어한다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-14.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 output 게이트\n",
    "\n",
    "바로 앞에서 은닉 상태 $\\textbf{h}_t$는 기억 셀 $\\textbf{c}_t$에 단순히 $tanh$함수를 적용했을 뿐이라고 설명했다.\n",
    "\n",
    "이번 절에서는 $tanh(\\textbf{c}_t)$에 게이트를 적용하는 걸 생각해보자.\n",
    "\n",
    "즉, $tanh(\\textbf{c}_t)$의 각 원소에 대해 '그것이 다음 시각의 은닉 상태에 얼마나 중요한가'를 조정한다.\n",
    "\n",
    "이 게이트는 다음 은닉 상태 $\\textbf{h}_t$의 출력을 담당하는 게이트이므로 __output 게이트__라고 한다.\n",
    "\n",
    "output 게이트의 열림 상태는 입력 $\\textbf{x}_t$와 이전 상태 $\\textbf{h}_{t-1}$로부터 구한다.\n",
    " \n",
    "output 게이트는 다음과 같이 쓸 수 있다.\n",
    "\n",
    "$$\\textbf{o}=\\sigma(\\textbf{x}_t\\textbf{W}_\\textbf{x}^\\textbf{(o)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(o)} + \\textbf{b}^\\textbf{(o)})$$  \n",
    "\n",
    "아래의 계산 그래프를 참고하자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-15.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "그리고 $\\textbf{h}_t$는 $\\textbf{o}$와 $tanh(\\textbf{c}_t)$의 곱으로 계산된다. 여기서 말하는 곱이란 원소별 곱이며, 이것을 __아다마르 곱(Hadamar product)__라고 한다. \n",
    "\n",
    "기호로는 $\\odot$이고 다음과 같은 계산을 수행한다. \n",
    "\n",
    "$$\\textbf{h}_t = \\textbf{o}\\odot tanh(\\textbf{c}_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 forget 게이트\n",
    "\n",
    "이름에서 알 수 있듯이 불필요한 데이터를 잊는 작업을 하는 게이트다.\n",
    "\n",
    "계산 그래프로 나타내면 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-16.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "forget 게이트에선 다음 식의 계산이 수행된다.\n",
    "\n",
    "$$\\textbf{f}=\\sigma(\\textbf{x}_t\\textbf{W}_\\textbf{x}^\\textbf{(f)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(f)} + \\textbf{b}^\\textbf{(f)})$$\n",
    "\n",
    "\n",
    "그리고 최종적으로 $\\textbf{f}$와 이전 기억 셀인 $\\textbf{c}_{t-1}$과의 원소별 곱을 통해 $\\textbf{c}_{t}$를 출력한다.\n",
    "\n",
    "$$\\textbf{c}_t = \\textbf{f}\\odot tanh(\\textbf{c}_{t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 새로운  기억 셀\n",
    "\n",
    "fortget게이트를 거치면서 이전 시각의 기억 셀로부터 잊어야 할 기억이 삭제되었다.\n",
    "\n",
    "그래서 새로 기억해야 할 정보를 기억 셀에 추가해야 된다. 아래 그림과 같이 $tanh$노드를 추가한다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-17.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "그림에서 보듯 $tanh$노드가 계산한 결과가 이전 시각의 기억 셀 $\\textbf{c}_{t-1}$에 더해진다. \n",
    "\n",
    "기억 셀에 새로운 '정보'가 추가된 것이다. 이 $tanh$ 노드는 '게이트'가 아니며, 새로운 '정보'를 기억 셀에 추가하는 것이 목적입니다.\n",
    "\n",
    "$tanh$노드에서 수행되는 계산은 다음과 같다.\n",
    "\n",
    "$$\\textbf{g} = tanh(\\textbf{x}_t\\textbf{W}_x^\\textbf{(g)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(g)} + \\textbf{b}^\\textbf{(g)})$$\n",
    "\n",
    "여기에서는 기억 셀에 추가하는 새로운 기억을 $\\textbf{g}$로 표기했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.6 input 게이트\n",
    "\n",
    "마지막으로 $\\textbf{g}$의 각 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰지를 판단하는 __input 게이트__를 추가하자.\n",
    "\n",
    "이는 새 정보를 무비판적으로 수용하는 게 아니라, 적절히 취사선택하는 것이 이 게이트의 역할이다.\n",
    "\n",
    "다른 관점으로 보자면, input 게이트에 의해 가중된 정보가 새로 추가되는 것이다.\n",
    "\n",
    "수행되는 계산은 다음과 같다.\n",
    "\n",
    "$$\\textbf{i} = tanh(\\textbf{x}_t\\textbf{W}_x^\\textbf{(i)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(i)} + \\textbf{b}^\\textbf{(i)})$$\n",
    "\n",
    "그리고 $\\textbf{i}$와 $\\textbf{g}$의 원소별 곱 결과를 기억 셀에 추가한다.\n",
    "\n",
    "다음은 LSTM 안에서 이뤄지는 과정이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-18.png\" width=\"50%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.7 LSTM의 기울기 흐름\n",
    "\n",
    "LSTM에서 어떤 원리로 기울기 소실을 없애주는 걸까? 기억 셀$\\textbf{c}$의 역전파에 주목해보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-19.png\" width=\"80%\" height=\"50%\">\n",
    "\n",
    "보면 기억 셀의 역전파에서는 '+'와 '$\\times$' 노드만을 지나게 된다. 그래서 '$\\times$' 노드에서 기울기 변화가 일어난다.\n",
    "\n",
    "그런데 앞에서 본 RNN의 역전파에서는 똑같은 가중치 행렬로 행렬 곱을 반복했다. 그래서 기울기 소실이 일어났다.\n",
    "\n",
    "하지만 LSTM의 역전파에서는 행렬 곱이 아닌 원소별 곱이 이뤄지고, 매 시각 다른 게이트 값을 이용해 원소별 곱을 계산한다. 그래서 기울기 소실이 일어나지 않는 것이다.\n",
    "\n",
    "$\\times$노드 계산은 forget 게이트가 제어한다. 그래서 forget 게이트의 값에 의해 흘러가는 기울기의 값이 결정된다. 따라서 기억 셀의 기울기가 소실 없이 전파되리라 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 LSTM 구현\n",
    "\n",
    "우선 최초의 한 단계만 처리하는 LSTM 클래스를 구현한 다음, 이어서 T개의 단계를 한꺼번에 처리하는 Time LSTM 클래스를 구현하겠다.\n",
    "\n",
    "다음은 LSTM에서 수행하는 계산을 정리한 수식들이다.\n",
    "\n",
    "$$\\begin{matrix}\n",
    "\\textbf{f} &=& \\sigma(\\textbf{x}_t\\textbf{W}_\\textbf{x}^\\textbf{(f)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(f)} + \\textbf{b}^\\textbf{(f)}) \\\\ \n",
    "\\textbf{g} &=& tanh(\\textbf{x}_t\\textbf{W}_x^\\textbf{(g)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(g)} + \\textbf{b}^\\textbf{(g)}) \\\\ \n",
    "\\textbf{i} &=& tanh(\\textbf{x}_t\\textbf{W}_x^\\textbf{(i)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(i)} + \\textbf{b}^\\textbf{(i)}) \\\\ \n",
    "\\textbf{o} &=& \\sigma(\\textbf{x}_t\\textbf{W}_\\textbf{x}^\\textbf{(o)} + \\textbf{h}_{t-1}\\textbf{W}_\\textbf{h}^\\textbf{(o)} + \\textbf{b}^\\textbf{(o)})\n",
    "\\end{matrix}$$\n",
    "\n",
    "$$ \\textbf{c}_t = \\textbf{f} \\odot \\textbf{c}_{t-1} + \\textbf{g} \\odot \\textbf{i} $$\n",
    "\n",
    "$$\\textbf{h}_t = \\textbf{o}\\odot tanh(\\textbf{c}_t)$$\n",
    "\n",
    "여기서 주목할 부분은 네 수식에 포함된 아핀 변환이다. 이를 행렬로 묶어 하나의 식으로 정리할 수 있다.\n",
    "\n",
    "아래의 그림을 보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-20.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "위와 같은 과정을 거쳤을 때 계산 그래프를 보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-21.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "위를 참고하여 LSTM 클래스를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        # 초기화\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        # 순전파때 중간 결과를 보관했다가 역전파 계산에 사용하려는 용도\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = 0 * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Time LSTM 구현\n",
    "\n",
    "Time LSTM은 T개분의 시계열 데이터를 한꺼번에 처리하는 계층이다. 다음 그림과 같이 구성되어 있다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-24.png\" width=\"60%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 LSTM을 사용한 언어 모델\n",
    "\n",
    "여기서 구현하는 언어 모델은 앞 장에서 구현한 언어 모델과 거의 같다. 앞 장에서는 Time RNN 계층이 차지하던 부분이 Time LSTM 계층으로 바뀌었는데 그게 유일한 차이이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-26.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "오른쪽 신경망을 Rnnlm이라는 클래스로 구현할 것이다. Rnnlm 클래스는 앞 장에서 설명한 SimpleRnnlm 클래스와 거의 같고, 새로운 method를 몇 개 더 제공한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 신경망을 사용해 PTB 데이터셋을 학습해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| 에폭 1 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 9999.69\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 19[s] | 퍼플렉서티 2965.97\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 35[s] | 퍼플렉서티 1238.42\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 51[s] | 퍼플렉서티 970.91\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 67[s] | 퍼플렉서티 816.29\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 82[s] | 퍼플렉서티 667.55\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 98[s] | 퍼플렉서티 645.83\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 113[s] | 퍼플렉서티 598.52\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 129[s] | 퍼플렉서티 574.64\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 144[s] | 퍼플렉서티 591.08\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 160[s] | 퍼플렉서티 515.65\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 175[s] | 퍼플렉서티 495.28\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 191[s] | 퍼플렉서티 452.63\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 210[s] | 퍼플렉서티 472.14\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 227[s] | 퍼플렉서티 464.27\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 244[s] | 퍼플렉서티 397.72\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 259[s] | 퍼플렉서티 351.02\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 274[s] | 퍼플렉서티 408.25\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 289[s] | 퍼플렉서티 418.44\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 304[s] | 퍼플렉서티 343.06\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 320[s] | 퍼플렉서티 350.63\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 336[s] | 퍼플렉서티 350.08\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 351[s] | 퍼플렉서티 336.52\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 367[s] | 퍼플렉서티 329.48\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 383[s] | 퍼플렉서티 307.70\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 399[s] | 퍼플렉서티 320.06\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 415[s] | 퍼플렉서티 307.84\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 430[s] | 퍼플렉서티 318.13\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 448[s] | 퍼플렉서티 293.38\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 464[s] | 퍼플렉서티 260.03\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 480[s] | 퍼플렉서티 337.75\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 495[s] | 퍼플렉서티 310.45\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 511[s] | 퍼플렉서티 286.97\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 527[s] | 퍼플렉서티 274.97\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 542[s] | 퍼플렉서티 229.74\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 557[s] | 퍼플렉서티 252.63\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 574[s] | 퍼플렉서티 260.68\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 589[s] | 퍼플렉서티 222.12\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 604[s] | 퍼플렉서티 235.87\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 620[s] | 퍼플렉서티 220.77\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 638[s] | 퍼플렉서티 242.68\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 654[s] | 퍼플렉서티 224.78\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 672[s] | 퍼플렉서티 232.52\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 690[s] | 퍼플렉서티 221.17\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 708[s] | 퍼플렉서티 208.21\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 725[s] | 퍼플렉서티 253.49\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 744[s] | 퍼플렉서티 228.78\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 760[s] | 퍼플렉서티 234.27\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 779[s] | 퍼플렉서티 245.84\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 798[s] | 퍼플렉서티 229.18\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 815[s] | 퍼플렉서티 194.11\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 831[s] | 퍼플렉서티 226.54\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 854[s] | 퍼플렉서티 209.35\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 880[s] | 퍼플렉서티 196.20\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 904[s] | 퍼플렉서티 170.62\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 922[s] | 퍼플렉서티 192.27\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 939[s] | 퍼플렉서티 228.55\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 955[s] | 퍼플렉서티 206.44\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 970[s] | 퍼플렉서티 198.92\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 986[s] | 퍼플렉서티 190.97\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 1004[s] | 퍼플렉서티 163.19\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 1020[s] | 퍼플렉서티 160.40\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 1039[s] | 퍼플렉서티 188.68\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 1058[s] | 퍼플렉서티 171.58\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 1078[s] | 퍼플렉서티 178.85\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 1096[s] | 퍼플렉서티 222.68\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 1117[s] | 퍼플렉서티 210.40\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 1125[s] | 퍼플렉서티 226.05\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 1144[s] | 퍼플렉서티 204.13\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 1160[s] | 퍼플렉서티 189.88\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 1179[s] | 퍼플렉서티 174.65\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 1200[s] | 퍼플렉서티 161.08\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 1220[s] | 퍼플렉서티 153.60\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 1246[s] | 퍼플렉서티 160.89\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 1263[s] | 퍼플렉서티 177.00\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 1280[s] | 퍼플렉서티 192.54\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 1296[s] | 퍼플렉서티 201.82\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 1320[s] | 퍼플렉서티 186.03\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 1348[s] | 퍼플렉서티 183.90\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 1365[s] | 퍼플렉서티 176.25\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 1385[s] | 퍼플렉서티 184.54\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 1402[s] | 퍼플렉서티 185.59\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 1419[s] | 퍼플렉서티 167.29\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 1436[s] | 퍼플렉서티 138.51\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 1453[s] | 퍼플렉서티 172.25\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 1473[s] | 퍼플렉서티 197.50\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 1499[s] | 퍼플렉서티 154.06\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 1536[s] | 퍼플렉서티 167.34\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 1563[s] | 퍼플렉서티 154.72\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 1580[s] | 퍼플렉서티 162.69\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 1597[s] | 퍼플렉서티 156.21\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 1613[s] | 퍼플렉서티 155.96\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 1630[s] | 퍼플렉서티 169.42\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 1647[s] | 퍼플렉서티 171.63\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 1665[s] | 퍼플렉서티 173.18\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 1683[s] | 퍼플렉서티 155.68\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 1700[s] | 퍼플렉서티 137.63\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 1720[s] | 퍼플렉서티 187.72\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 1739[s] | 퍼플렉서티 181.98\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 1756[s] | 퍼플렉서티 163.10\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 1772[s] | 퍼플렉서티 154.87\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 1789[s] | 퍼플렉서티 130.93\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 1805[s] | 퍼플렉서티 150.89\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 1822[s] | 퍼플렉서티 159.42\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 1838[s] | 퍼플렉서티 133.55\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 1854[s] | 퍼플렉서티 130.70\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 1870[s] | 퍼플렉서티 134.78\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 1886[s] | 퍼플렉서티 147.02\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 1902[s] | 퍼플렉서티 142.99\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 1918[s] | 퍼플렉서티 143.49\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 1935[s] | 퍼플렉서티 143.61\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 1951[s] | 퍼플렉서티 128.63\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 1966[s] | 퍼플렉서티 165.29\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 1982[s] | 퍼플렉서티 147.09\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 1999[s] | 퍼플렉서티 153.46\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 2016[s] | 퍼플렉서티 162.99\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 2032[s] | 퍼플렉서티 153.97\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 2048[s] | 퍼플렉서티 131.10\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 2065[s] | 퍼플렉서티 154.49\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 2082[s] | 퍼플렉서티 143.03\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 2099[s] | 퍼플렉서티 128.21\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 2115[s] | 퍼플렉서티 110.02\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 2132[s] | 퍼플렉서티 121.37\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 2149[s] | 퍼플렉서티 153.79\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 2164[s] | 퍼플렉서티 141.06\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 2180[s] | 퍼플렉서티 132.36\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 2195[s] | 퍼플렉서티 133.11\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 2211[s] | 퍼플렉서티 112.16\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 2226[s] | 퍼플렉서티 109.72\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 2241[s] | 퍼플렉서티 129.81\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 2257[s] | 퍼플렉서티 122.70\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 2272[s] | 퍼플렉서티 122.18\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 2287[s] | 퍼플렉서티 157.42\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 2302[s] | 퍼플렉서티 151.56\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 2308[s] | 퍼플렉서티 161.43\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 2323[s] | 퍼플렉서티 143.55\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 2338[s] | 퍼플렉서티 134.77\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 2353[s] | 퍼플렉서티 127.15\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 2368[s] | 퍼플렉서티 117.70\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 2384[s] | 퍼플렉서티 105.56\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 2399[s] | 퍼플렉서티 115.71\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 2414[s] | 퍼플렉서티 125.48\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 2429[s] | 퍼플렉서티 141.25\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 2444[s] | 퍼플렉서티 150.64\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 2459[s] | 퍼플렉서티 142.89\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 2474[s] | 퍼플렉서티 141.15\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 2489[s] | 퍼플렉서티 133.70\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 2505[s] | 퍼플렉서티 137.72\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 2520[s] | 퍼플렉서티 140.07\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 2535[s] | 퍼플렉서티 124.29\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 2551[s] | 퍼플렉서티 101.65\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 2566[s] | 퍼플렉서티 124.13\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 2581[s] | 퍼플렉서티 153.05\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 2596[s] | 퍼플렉서티 115.11\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 2611[s] | 퍼플렉서티 129.63\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 2627[s] | 퍼플렉서티 112.40\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 2642[s] | 퍼플렉서티 124.94\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 2658[s] | 퍼플렉서티 118.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 481 / 1327 | 시간 2673[s] | 퍼플렉서티 118.40\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 2688[s] | 퍼플렉서티 128.83\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 2703[s] | 퍼플렉서티 137.51\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 2718[s] | 퍼플렉서티 136.25\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 2734[s] | 퍼플렉서티 117.98\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 2749[s] | 퍼플렉서티 105.36\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 2764[s] | 퍼플렉서티 148.43\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 2779[s] | 퍼플렉서티 142.43\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 2795[s] | 퍼플렉서티 127.47\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 2810[s] | 퍼플렉서티 121.27\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 2825[s] | 퍼플렉서티 101.23\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 2840[s] | 퍼플렉서티 118.34\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 2856[s] | 퍼플렉서티 125.37\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 2871[s] | 퍼플렉서티 107.23\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 2887[s] | 퍼플렉서티 102.09\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 2902[s] | 퍼플렉서티 104.52\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 2917[s] | 퍼플렉서티 115.75\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 2932[s] | 퍼플렉서티 117.28\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 2948[s] | 퍼플렉서티 113.76\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 2963[s] | 퍼플렉서티 117.97\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 2979[s] | 퍼플렉서티 104.72\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 2994[s] | 퍼플렉서티 130.82\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 3009[s] | 퍼플렉서티 117.63\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 3024[s] | 퍼플렉서티 127.57\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 3040[s] | 퍼플렉서티 130.55\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 3055[s] | 퍼플렉서티 124.16\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 3070[s] | 퍼플렉서티 108.21\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 3085[s] | 퍼플렉서티 126.69\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 3101[s] | 퍼플렉서티 119.44\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 3116[s] | 퍼플렉서티 102.29\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 3131[s] | 퍼플렉서티 88.70\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 3146[s] | 퍼플렉서티 96.22\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 3162[s] | 퍼플렉서티 122.77\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 3177[s] | 퍼플렉서티 114.86\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 3192[s] | 퍼플렉서티 106.49\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 3207[s] | 퍼플렉서티 109.70\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 3223[s] | 퍼플렉서티 94.08\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 3238[s] | 퍼플렉서티 89.16\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 3253[s] | 퍼플렉서티 104.81\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 3269[s] | 퍼플렉서티 104.13\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 3284[s] | 퍼플렉서티 100.83\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 3299[s] | 퍼플렉서티 129.35\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 3315[s] | 퍼플렉서티 125.42\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 3320[s] | 퍼플렉서티 134.79\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 3336[s] | 퍼플렉서티 121.76\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 3351[s] | 퍼플렉서티 106.95\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 3366[s] | 퍼플렉서티 107.65\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 3382[s] | 퍼플렉서티 96.82\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 3397[s] | 퍼플렉서티 86.97\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 3412[s] | 퍼플렉서티 95.07\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 3427[s] | 퍼플렉서티 102.64\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 3443[s] | 퍼플렉서티 117.86\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 3458[s] | 퍼플렉서티 128.81\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 3474[s] | 퍼플렉서티 121.92\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 3489[s] | 퍼플렉서티 121.71\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 3504[s] | 퍼플렉서티 114.52\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 3519[s] | 퍼플렉서티 113.96\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 3534[s] | 퍼플렉서티 120.91\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 3549[s] | 퍼플렉서티 103.05\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 3564[s] | 퍼플렉서티 84.06\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 3580[s] | 퍼플렉서티 99.97\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 3595[s] | 퍼플렉서티 127.91\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 3610[s] | 퍼플렉서티 97.96\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 3625[s] | 퍼플렉서티 110.22\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 3641[s] | 퍼플렉서티 93.35\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 3656[s] | 퍼플렉서티 104.07\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 3671[s] | 퍼플렉서티 100.62\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 3686[s] | 퍼플렉서티 101.48\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 3701[s] | 퍼플렉서티 109.27\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 3717[s] | 퍼플렉서티 117.20\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 3732[s] | 퍼플렉서티 113.26\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 3747[s] | 퍼플렉서티 101.91\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 3762[s] | 퍼플렉서티 88.80\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 3778[s] | 퍼플렉서티 126.87\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 3793[s] | 퍼플렉서티 121.66\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 3808[s] | 퍼플렉서티 109.26\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 3824[s] | 퍼플렉서티 103.28\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 3839[s] | 퍼플렉서티 85.34\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 3854[s] | 퍼플렉서티 101.99\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 3869[s] | 퍼플렉서티 106.70\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 3884[s] | 퍼플렉서티 94.71\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 3900[s] | 퍼플렉서티 88.58\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 3915[s] | 퍼플렉서티 88.03\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 3930[s] | 퍼플렉서티 98.71\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 3946[s] | 퍼플렉서티 102.55\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 3961[s] | 퍼플렉서티 98.30\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 3976[s] | 퍼플렉서티 102.30\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 3991[s] | 퍼플렉서티 91.04\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 4006[s] | 퍼플렉서티 113.13\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 4022[s] | 퍼플렉서티 102.59\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 4037[s] | 퍼플렉서티 112.67\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 4052[s] | 퍼플렉서티 112.28\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 4068[s] | 퍼플렉서티 107.44\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 4083[s] | 퍼플렉서티 95.96\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 4098[s] | 퍼플렉서티 111.97\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 4113[s] | 퍼플렉서티 104.27\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 4128[s] | 퍼플렉서티 88.53\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 4143[s] | 퍼플렉서티 79.01\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 4159[s] | 퍼플렉서티 80.22\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 4174[s] | 퍼플렉서티 102.50\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 4189[s] | 퍼플렉서티 99.00\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 4204[s] | 퍼플렉서티 92.33\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 4220[s] | 퍼플렉서티 95.66\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 4235[s] | 퍼플렉서티 83.36\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 4250[s] | 퍼플렉서티 76.32\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 4265[s] | 퍼플렉서티 90.94\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 4280[s] | 퍼플렉서티 93.68\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 4296[s] | 퍼플렉서티 89.66\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 4311[s] | 퍼플렉서티 111.54\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 4326[s] | 퍼플렉서티 110.06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  134.60764776603213\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from ch06.rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 RNNLM 추가 개선\n",
    "\n",
    "RNNLM의 개선 포인트 3가지를 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.1 LSTM 계층 다층화\n",
    "\n",
    "RNNLM으로 정확하나 모델을 만들고자 한다면 많은 경우 LSTM 계층을 깊게 쌓아 효과를 볼 수 있다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-29.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "그럼 몇 층이나 쌓아야 할까? 그건 하이퍼파라미터에 관한 문제이다. 문제에 따라 다르다.\n",
    "\n",
    "참고로 PTB 데이터셋의 언어 모델에서는 LSTM의 층 수는 2~4 정도일 때 좋은 결과를 얻는 것 같습니다.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 드롭아웃에 의한 과적합 억제\n",
    "\n",
    "LSTM 계층을 다층화하면 과적합의 위험이 있다. 그래서 과적합을 억제하는 방법들을 알아보자.\n",
    "\n",
    "첫 번째로 드랍아웃 계층을 어디에 위치시켜야 할지 생각해야 한다.\n",
    "\n",
    "아래와 같이 위치시키는 걸 생각해보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-32.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "이는 좋은 방법이 아니다. 왜냐하면 시계열 방향으로 드롭아웃을 넣어버리면 시간이 흐름에 따라 정보가 사라질 수 있다. \n",
    "\n",
    "즉, 흐르는 시간에 비례해 드롭아웃에 의한 노이즈가 축적된다. 그래서 노이즈 축적을 고려하면, 시간축 방향으로의 드롭아웃은 안하는 것이 좋다.\n",
    "\n",
    "깊이 방향으로 적용하는 것이 적절하다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-33.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "지금까지 이야기한 것처럼, '일반적인 드롭아웃'은 시간 방향에는 적합하지 않다. 그러나 최근 연구에서는 RNN의 시간 방향 정규화를 목표로 하는 방법이 다양하게 제안되고 있다. 예로 __Variational Dropout__이 있다.\n",
    "\n",
    "Variational Dropout은 깊이 방향은 물론 시간 방향에도 이용할 수 있어서 언어 모델의 정확도를 한층 더 향상시킬 수 있다.\n",
    "\n",
    "구조는 이렇다. 같은 계층에 속한 드롭아웃들은 같은 마스크를 공유한다.\n",
    "\n",
    "'마스크'란 데이터의 '통과/차단'을 결정하는 이진형태의 무작위 패턴을 말한다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-34.png\" width=\"50%\" height=\"40%\">\n",
    "\n",
    "위에서 보듯 계층의 드롭아웃끼리 마스크를 공유함으로써 마스크가 '고정'된다. 그 결과 정보를 잏게 되는 방법도 고정되므로, 일반적인 드롭아웃 때와 달리 정보가 지수적으로 손실되는 사태를 피할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 가중치 공유\n",
    "\n",
    "언어 모델을 개선하는 아주 간단한 트릭 중 __가중치 공유(Weight tying)__이 있다.\n",
    "\n",
    "다음 사진은 Embedding 계층과 Affine 계층의 가중치를 공유하는 경우이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-35.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "가중치 공유가 효과가 있는 이유는 다음과 같다.\n",
    "\n",
    "직관적으로 가중치를 공유함으로써 학습해야할 매개변수 수를 줄일 수 있고, 그 결과 학습하기가 더 쉬워지기 때문이다. \n",
    "\n",
    "자세한 내용은 다음 논문을 읽어보자 [weight tying](https://arxiv.org/abs/1611.01462)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.34 개선된 RNNLM 구현\n",
    "\n",
    "\n",
    "앞에서 알아본 개선점 3개를 적용하여 BetterRnnlm 클래스를 구현하자.\n",
    "\n",
    "    * LSTM 계층의 다층화\n",
    "    \n",
    "    * 드롭아웃 사용 (깊이 방향)\n",
    "    \n",
    "    * 가중치 공유 (Emdedding 계층과 Affine 계층)\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-36.png\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BetterRnnlm 클래스를 이용해 학습을 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ==============================================\n",
    "# config.GPU = True\n",
    "# ==============================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 첨단 연구\n",
    "\n",
    "현재 perplexity를 줄이는 연구가 계속 되고 있다. 몇 가지를 알아보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 6-37.png\" width=\"60%\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 이번 장에서 배운 내용\n",
    "\n",
    "    * 단순한 RNN의 학습에서는 기울기 소실과 기울기 폭발이 문제가 된다.\n",
    "    \n",
    "    * 기울기 폭발에는 기울기 클리핑, 기울긱 소실에는 게이트가 추가된 RNN(LSTM과 GRU 등이) 효과적이다.\n",
    "    \n",
    "    * LSTM에는 input 게이트, forget 게이트, output 게이트 등 3개의 게이트가 있다.\n",
    "    \n",
    "    * 게이트에는 전용 가중치가 있으며, 시그모이드 함수를 사용하여 0.0~1.0 사이의 실수를 출력한다.\n",
    "    \n",
    "    * 언어 모델 개선에는 LSTM 계층 다층화, 드롭아웃, 가중치 공유 등의 기법이 효과적이다.\n",
    "    \n",
    "    * RNN의 정규화는중요한 주제이며, 드롭아웃 기반의 다양한 기법이 제안되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 RNN을 사용한 문장 생성\n",
    "\n",
    "이번 장에서는 언어 모델을 사용해 '문장 생성'을 수행할 것이다. 구체적으로는 우선 말뭉치를 사용해 학습한 언어 모델을 이용하여 새로운 문장을 만들어낸다.\n",
    "\n",
    "그런 다음 개선된 언어 모델을 이용하여 더 자연스러운 문장을 생성하자.\n",
    "\n",
    "더 나아가 seq2seq라는 새로운 구조의 신경망도 다룰 것이다. seq2seq란 한 시계열 데이터를 다른 시계열 데이터롤 변환하는 걸 말한다.\n",
    "\n",
    "이번 장에서는 RNN 두 개를 연결하는 아주 간단한 방법으로 seq2seq를 구현해볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 언어 모델을 사용한 문장 생성\n",
    "\n",
    "이번 절에서는 언어 모델로 문장 생성을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 RNN을 사용한 문장 생성의 순서\n",
    "\n",
    "언어 모델은 지금까지 주어진 단어들에서 다음에 출현하는 단어의 확률분포를 출력한다. 이 결과를 기초로 다음 단어를 새로 생성하려면 어떻게 해야 할까?\n",
    "\n",
    "첫 번째로, 확률이 가장 높은 단어를 선택하는 방법이다. 이런 방법을 결정적인 방법이라 부른다.\n",
    "\n",
    "마지막으로 '확률적'으로 선택하는 방법도 있다. 각 후보 단어의 확률에 맞게 선택하는 것으로, 확률이 높은 단어는 선택되기 쉽고, 낮은 단어는 선택되기 어렵다.\n",
    "\n",
    "이 방식에서는 선택되는 단어가 매번 다를 수 있다. 따라서 다양한 문장을 생성할 수 있다.\n",
    "\n",
    "첫 번째 방법도 헷갈리지 말아야 하는게, 첫 번째 방법은 확률이 가장 높은 단어를 '선택'하는 것이고 두 번째 방법은 확률을 근거로 '랜덤뽑기'하는 것이다.\n",
    "\n",
    "입력 단어로 다음 단어를 생성하고 생성된 단어로 다음 단어를 생성한다. 이런 반복적인 구조를 통해 문장을 생성하는 것이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-4.png\" width=\"50%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 문장 생성 구현\n",
    "\n",
    "문장을 생성하는 코드를 구현해보자. 앞 장에서 구현한 Rnnlm 클래스를 상속해 RnnlmGen 클래스를 만들고 이 클래스에 문장 생성 method를 추가하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from ch06.rnnlm import Rnnlm\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "        \n",
    "        '''\n",
    "        start_id : 최초로 주는 단어의 ID\n",
    "        sample_size : 샘플링하는 단어의 수\n",
    "        skip_ids : 샘플링되지 않는 단어의 ID를 모아놓은 리스트\n",
    "        '''\n",
    "        \n",
    "        x = start_id   \n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 아무런 학습도 없이 문장을 생성해보자(즉, 가중치 매개변수는 무작위 초깃값인 상태)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you expect half of a policy that can be all the postal programs are offset by its passing involved and a computer system of the eye.\n",
      " an economy may be is expected to lose them with american express ltd. morgan stanley & co. by a computer co. unit.\n",
      " dual home products between both drug firms especially structure have intended hurting the company could pay in what change customers a month for occurred usually answer.\n",
      " he think bowed to defend economic cooperation the economy will be of the mega-issues that sea barriers have.\n",
      " all of its assets\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from ch07.rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "# model.load_params('ch06/Rnnlm.pkl')의 주석처리에 따라 문장의 질이 달라진다.\n",
    "model = RnnlmGen()\n",
    "model.load_params('ch06/Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 더 좋은 문장으로\n",
    "\n",
    "앞 장에서 만든 'BetterRnnlm'을 이용해서 더 좋은 문장을 만들어보자. 앞의 예와 같이 첫 문자로 'you'를 입력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you issue from some succeeded.\n",
      " but it 's very difficult to see the word in our editorial right now to resolve and 'm ok says mr. eidsmo.\n",
      " one of those many money managers believe they should love things off to side.\n",
      " the massachusetts news board would pay over less than pro bono to its new rent and cigarette documents.\n",
      " a federal judge in new york upheld an investigation by china 's top management bureau.\n",
      " two months ago asarco voted to extend usage of about five million the customers.\n",
      " these are the two ministers roll\n",
      "--------------------------------------------------\n",
      "the meaning of life is lower but according to the picket drives begun by the morgan stanley pact which came as they acquired used from operations.\n",
      " in august.\n",
      " the period which tracks from the industrial sector of india was a disappointing slump in his regional city.\n",
      " and coal are the main century to cost of u.s. instruments.\n",
      " guardian of its roots in the u.s. and europe with keeping their cars this year has been pet.\n",
      " in washington an audience that makes with the trade of the seed producing sales are a dead compared with confidence.\n",
      " i can take\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from ch07.rnnlm_gen import BetterRnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('ch06/BetterRnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)\n",
    "\n",
    "\n",
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x)\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 seq2seq\n",
    "\n",
    "세상엔 다양한 시계열 데이터가 많다. 그래서 입출력이 모두 시계열인 경우도 있다.\n",
    "\n",
    "그래서 이번에는 시계열 데이터를 다른 시계열 데이터로 변환하는 모델을 생각해보자.\n",
    "\n",
    "이를 위한 기법으로, 여기에서는 2개의 RNN을 이용하는 __seq2seq__라는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 seq2seq의 원리\n",
    "\n",
    "seq2seq를 Encoder-Decoder 모델이라고 한다. 문자 그대로 Encoder와 Decoder를 이어주는 모델이다.\n",
    "\n",
    "다음과 같은 경우를 보자.\n",
    "\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-5.png\" width=\"40%\" height=\"30%\">\n",
    "\n",
    "'나는 고양이로소이다'를 받아 encoder를 통해 encoding한 값을 decoder를 통해 decodingd을 해서 'I am a cat'으로 출력한다.\n",
    "\n",
    "먼저 Encoder를 알아보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-6.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "Encoder는 RNN을 이용해 시계열 데이터를 __h__라는 은닉 상태 벡터로 변환한다.\n",
    "\n",
    "이 은닉 상태 __h__에 입력 문장을 번역하는데 필요한 정보가 인코딩된다. 여기에서 중요한 점은 __h__는 고정 길이 벡터라는 점이다.\n",
    "\n",
    "그래서 인코딩 작업은 결국 임의 길이의 문장을 고정 길이 벡터로 변환하는 작업이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-7.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "이번에는 Decoder를 알아보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-8.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "이전에서 문장 생성했을 때 사용한 모델을 그대로 적용한다.\n",
    "\n",
    "단, 한 가지 다른 점이 LSTM 계층이 벡터 __h__를 입력받는다는 점이다.\n",
    "\n",
    "참고로 앞 절의 언어 모델에서는 LSTM 계층이 아무것도 받지 않았다. 이런 사소한 차이가 번역을 하게 만든다!!\n",
    "\n",
    "그럼 seq2seq의 전체 계층 구성을 보자\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-9.png\" width=\"80%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 시계열 데이터 변환용 Toy problem\n",
    "\n",
    "머신러닝을 평가하고자 만든 간단한 문제를 'toy prblem'이라고 부른다.\n",
    "\n",
    "toy prblem으로 '덧셈'을 학습시켜보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-10.png\" width=\"40%\" height=\"30%\">\n",
    "\n",
    "seq2seq는 덧셈의 예제들로부터, 사용되는 문자의 패턴을 학습한다.\n",
    "\n",
    "과연 이런 식으로 해서 \"덧셈의 규칙을 올바르게 학습할 수 있는가?\"가 이번 문제의 중점 사항이다.\n",
    "\n",
    "지금까지 word2vec이나 언어 모델에서 문장을 '단어' 단위로 분할해왔다.\n",
    "\n",
    "그러나 이번 문제에서는 단어가 아닌 '문자' 단위로 분할한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 가변 길이 시계열 데이터\n",
    "\n",
    "덧셈을 문자의 리스트로써 다룰 때 주의해야 할 점은 덧셈 문장이나 그 출력의 문자 수가 문제마다 다르다는 것이다.\n",
    "\n",
    "그러므로 기존의 고정 길이 데이터가 아니라 가변 길이 데이터를 다룬다는 것이다.\n",
    "\n",
    "따라서 신경망 학습 시 '미니배치 처리'를 하려면 무언가 추가적인 조작이 필요하다.\n",
    "\n",
    "가장 단순한 방법으로 __패딩__을 사용하는 것이 있다.\n",
    "\n",
    "패딩이란 원래의 데이터에 의미 없는 데이터를 채워 모든 데이터의 길이를 균일하게 맞추는 기법이다.\n",
    "\n",
    "다음과 같이 적용을 한다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-11.png\" width=\"70%\" height=\"30%\">\n",
    "\n",
    "(위의 사진과 같이 decoder 출력의 경우, 문자 출력의 종료를 알리는 구분자를 정답 레이블로 입력하도록 구현할 수 있다. 그러나 여기에서는 단순화하기 위해 그러지 않도록 한다.)\n",
    "\n",
    "이렇게 패딩을 적용해 데이터 크기를 통일시키면 가변 길이 시계열 데이터도 처리할 수 있다. \n",
    "\n",
    "그런데 원래 존재하지 않던 패딩용 문자까지 seq2seq가 학습할 수 있으므로 SoftmaxWithLoss 계층에서 적절한 조치를 통해 해결해야 하지만 복잡하니 여기에선 그냥 다루기로 한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 덧셈 데이터셋\n",
    "\n",
    "addition.txt에 있는 50,000개의 데이터를 들여다보자.\n",
    "\n",
    "정석대로라면 데이터셋을 훈련, 검증, 테스트용으로 나눠서 사용해야 하는데 이야기를 단순화하기 위해 훈련, 테스트로만 나눠서 진행하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n",
      "[ 3  0  2  0  0 11  5]\n",
      "[ 6  0 11  7  5]\n",
      "71+118 \n",
      "_189 \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import sequence\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('addition.txt', seed=1984)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)\n",
    "# (45000, 7) (45000, 5)\n",
    "# (5000, 7) (5000, 5)\n",
    "\n",
    "print(x_train[0])\n",
    "print(t_train[0])\n",
    "# [ 3  0  2  0  0 11  5]\n",
    "# [ 6  0 11  7  5]\n",
    "\n",
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))\n",
    "# 71+118\n",
    "# _189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 seq2seq 구현\n",
    "\n",
    "두 RNN을 Encoder와 Decoder 클래스로 구현하고 두 클래스를 연결하는 seq2seq 클래스를 구현하는 흐름으로 진행해보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Encoder 클래스\n",
    "\n",
    "Encoder 클래스는 그림과 같이 문자열을 받아 벡터 __h__로 변환한다.\n",
    "\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-13.png\" width=\"20%\" height=\"30%\">\n",
    "\n",
    "Encoder 계층을 다시보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-14.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "LSTM 계층에서 오른쪽으로 은닉 상태와 셀을 출력하고 위쪽으로 은닉 상태만 출력한다. 그런데 위쪽으로 계층이 없으니 LSTM 계층의 위쪽 출력은 폐기된다.\n",
    "\n",
    "그리고 마지막 문자를 처리한 후 LSTM 계층의 은닉 상태 __h__를 출력하고 이 값은 Decoder로 전달된다.\n",
    "\n",
    "Encoder 클래스의 코드를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 주의해야 할 점이 'stateful'변수인데 지금까지는 긴 시계열 데이터가 하나뿐인 문제를 다뤄와서 Time LSTM 계층의 stateful을 True로 설정하여 은닉 상태를 유지했다.\n",
    "\n",
    "그러나 이번에는 짧은 시계열 데이터가 여러 개이기 때문에 문제마다 LSTM의 은닉 상태를 다시 초기화해야하기 때문에 False로 설정해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 Decoder 클래스\n",
    "\n",
    "앞에서 알아봤던 것 처럼 decoder는 encoder에서 출력한 __h__를 받아 목적으로 하는 다른 문자열을 출력한다.\n",
    "\n",
    "Encoder와 마찬가지로 LSTM 계층을 사용한다. 학습 시 계층 구성은 다음과 같다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-17.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "그런데 7.1절에서는 확률적 선택을 했는데 이 문제는 '덧셈'문제이므로 '결정적'인 답을 요구한다. 그러므로 softmax함수의 확률분포에서 점수가 가장 높은 문자 하나만 고르겠다.\n",
    "\n",
    "다음은 문자열 생성 시 계층 구성을 보자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-18.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "보시다시피 argmax라는 노드를 통해 최댓값을 가진 원소의 인덱스를 선택해서 반환한다. 다만 이번에는 softmax 계층을 사용하지 않고, Affine 계층이 출력하는 점수가 가장 큰 문자 ID를 선택한다. \n",
    "\n",
    "왜냐하면 softmax함수는 단조 증가 함수이기 때문에 적용 전후의 대소 관계가 달라지지 않기 때문이다.\n",
    "\n",
    "이렇게 decoder에서는 학습 시와 생성 시에 Softmax 계층을 다르게 취급한다. 그러니 SoftmaxWithLoss 계층은 이후에 구현하는 seq2seq 클래스에서 처리하기로 하고, decoder 클래스는 Time Softmax With Loss 계층의 앞까지만 담당하기로 하자.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-19.png\" width=\"40%\" height=\"30%\">\n",
    "\n",
    "Decoder 클래스는 Time Embedding, Time LSTM, Time Affine의 3가지 계층으로 구성된다.\n",
    "\n",
    "구현해보자.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        # 한 번 설정된 이 은닉 상태는 재설정되지 않고, 즉 Encoder의 h를 유지하면서 순전파가 이루어진다.\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잠시 역전파에 관해서 보충 설명을 하겠다. backward() method는 위쪽의 Softmax With Loss 계층으로 기울기 dscore를 받아 Time Affine 계층, Time LSTM 계층, Time Embedding 계층 순서로 전파시킨다.\n",
    "\n",
    "이때 Time LSTM 계층의 시간 방향으로의 기울기는 TimeLSTM 클래스의 인스턴스 변수 dh에 저장되어 있다(자세한 내용은 6.3참고).\n",
    "\n",
    "그래서 이 시간 방향의 기울기 dh를 꺼내서 Decoder 클래스의 backward()의 출력으로 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 Seq2seq 클래스\n",
    "\n",
    "seq2seq 클래스   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.4 seq2seq 평가\n",
    "\n",
    "seq2seq의 학습은 다음과 같은 흐름으로 이뤄진다.\n",
    "\n",
    "1. 학습 데이터에서 미니배치를 선택하고,\n",
    "\n",
    "\n",
    "2. 미니배치로부터 기울기를 계산하고,\n",
    "\n",
    "\n",
    "3. 기울기를 사용하여 매개변수를 갱신한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 3[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 5[s] | 손실 2.17\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 7[s] | 손실 1.96\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 9[s] | 손실 1.92\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 11[s] | 손실 1.87\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 13[s] | 손실 1.85\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 15[s] | 손실 1.83\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 17[s] | 손실 1.79\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 19[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 22[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 24[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 26[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 28[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 30[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 32[s] | 손실 1.74\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 35[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 37[s] | 손실 1.74\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "검증 정확도 0.180%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 2[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 4[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 6[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 8[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 11[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 14[s] | 손실 1.72\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 16[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 18[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 20[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 22[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 25[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 27[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 30[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 32[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 35[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 37[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 40[s] | 손실 1.67\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 994 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1544\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "검증 정확도 0.220%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 2[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 4[s] | 손실 1.65\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 6[s] | 손실 1.63\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 8[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 10[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 13[s] | 손실 1.60\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 15[s] | 손실 1.59\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 17[s] | 손실 1.57\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 19[s] | 손실 1.57\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 21[s] | 손실 1.56\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 24[s] | 손실 1.54\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 26[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 28[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 30[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 33[s] | 손실 1.50\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 35[s] | 손실 1.49\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 37[s] | 손실 1.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 108 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 648 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 138 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 448 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1373\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 348 \n",
      "---\n",
      "검증 정확도 0.560%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 2[s] | 손실 1.46\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 4[s] | 손실 1.44\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 6[s] | 손실 1.43\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 8[s] | 손실 1.42\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 11[s] | 손실 1.41\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 13[s] | 손실 1.40\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 15[s] | 손실 1.40\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 17[s] | 손실 1.38\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 19[s] | 손실 1.38\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 22[s] | 손실 1.37\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 24[s] | 손실 1.35\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 26[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 28[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 31[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 33[s] | 손실 1.32\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 35[s] | 손실 1.31\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 37[s] | 손실 1.30\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 146 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1189\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1002\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1406\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 202 \n",
      "---\n",
      "검증 정확도 1.060%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 2[s] | 손실 1.29\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 4[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 7[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 9[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 11[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 13[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 15[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 18[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 20[s] | 손실 1.25\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 22[s] | 손실 1.23\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 24[s] | 손실 1.22\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 26[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 29[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 31[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 33[s] | 손실 1.20\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 35[s] | 손실 1.19\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 37[s] | 손실 1.18\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 145 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1168\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 192 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 431 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 895 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1015\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1493\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 891 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 221 \n",
      "---\n",
      "검증 정확도 2.260%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 2[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 4[s] | 손실 1.18\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 6[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 8[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 11[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 13[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 15[s] | 손실 1.14\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 17[s] | 손실 1.14\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 19[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 22[s] | 손실 1.15\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 24[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 26[s] | 손실 1.12\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 28[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 30[s] | 손실 1.12\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 33[s] | 손실 1.11\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 35[s] | 손실 1.11\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 37[s] | 손실 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1169\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 199 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 441 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1412\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 256 \n",
      "---\n",
      "검증 정확도 2.980%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 3[s] | 손실 1.12\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 5[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 8[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 10[s] | 손실 1.09\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 13[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 15[s] | 손실 1.11\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 17[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 20[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 22[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 25[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 27[s] | 손실 1.07\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 30[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 32[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 35[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 37[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 39[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 42[s] | 손실 1.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1166\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 430 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 893 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1058\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1445\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 228 \n",
      "---\n",
      "검증 정확도 3.560%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 1.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 8 |  반복 21 / 351 | 시간 2[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 4[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 7[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 9[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 11[s] | 손실 1.08\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 13[s] | 손실 1.07\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 15[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 18[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 20[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 22[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 24[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 26[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 29[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 31[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 33[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 35[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 37[s] | 손실 1.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 156 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 411 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1410\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 227 \n",
      "---\n",
      "검증 정확도 4.420%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 2[s] | 손실 1.02\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 5[s] | 손실 1.01\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 8[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 11[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 13[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 16[s] | 손실 1.01\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 18[s] | 손실 1.01\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 20[s] | 손실 1.00\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 22[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 25[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 221 / 351 | 시간 27[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 241 / 351 | 시간 30[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 261 / 351 | 시간 33[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 281 / 351 | 시간 36[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 38[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 321 / 351 | 시간 40[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 341 / 351 | 시간 42[s] | 손실 0.99\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 173 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 418 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 870 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1470\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 875 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 228 \n",
      "---\n",
      "검증 정확도 4.240%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 21 / 351 | 시간 2[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 41 / 351 | 시간 4[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 61 / 351 | 시간 7[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 81 / 351 | 시간 9[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 101 / 351 | 시간 11[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 121 / 351 | 시간 14[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 141 / 351 | 시간 16[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 161 / 351 | 시간 18[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 181 / 351 | 시간 20[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 201 / 351 | 시간 22[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 221 / 351 | 시간 25[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 241 / 351 | 시간 27[s] | 손실 0.95\n",
      "| 에폭 10 |  반복 261 / 351 | 시간 30[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 281 / 351 | 시간 33[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 36[s] | 손실 0.95\n",
      "| 에폭 10 |  반복 321 / 351 | 시간 38[s] | 손실 0.99\n",
      "| 에폭 10 |  반복 341 / 351 | 시간 41[s] | 손실 0.99\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 663 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1444\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "검증 정확도 7.260%\n",
      "| 에폭 11 |  반복 1 / 351 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 11 |  반복 21 / 351 | 시간 2[s] | 손실 0.95\n",
      "| 에폭 11 |  반복 41 / 351 | 시간 4[s] | 손실 0.94\n",
      "| 에폭 11 |  반복 61 / 351 | 시간 6[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 81 / 351 | 시간 9[s] | 손실 0.95\n",
      "| 에폭 11 |  반복 101 / 351 | 시간 11[s] | 손실 0.97\n",
      "| 에폭 11 |  반복 121 / 351 | 시간 13[s] | 손실 0.96\n",
      "| 에폭 11 |  반복 141 / 351 | 시간 15[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 161 / 351 | 시간 18[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 181 / 351 | 시간 20[s] | 손실 0.97\n",
      "| 에폭 11 |  반복 201 / 351 | 시간 24[s] | 손실 0.98\n",
      "| 에폭 11 |  반복 221 / 351 | 시간 27[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 241 / 351 | 시간 31[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 261 / 351 | 시간 34[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 281 / 351 | 시간 38[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 301 / 351 | 시간 41[s] | 손실 0.92\n",
      "| 에폭 11 |  반복 321 / 351 | 시간 43[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 341 / 351 | 시간 46[s] | 손실 0.94\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1121\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 428 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 890 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1421\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 875 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 251 \n",
      "---\n",
      "검증 정확도 4.060%\n",
      "| 에폭 12 |  반복 1 / 351 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 12 |  반복 21 / 351 | 시간 2[s] | 손실 0.93\n",
      "| 에폭 12 |  반복 41 / 351 | 시간 5[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 61 / 351 | 시간 7[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 81 / 351 | 시간 9[s] | 손실 0.95\n",
      "| 에폭 12 |  반복 101 / 351 | 시간 11[s] | 손실 0.97\n",
      "| 에폭 12 |  반복 121 / 351 | 시간 13[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 141 / 351 | 시간 15[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 161 / 351 | 시간 18[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 181 / 351 | 시간 20[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 201 / 351 | 시간 22[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 221 / 351 | 시간 24[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 241 / 351 | 시간 27[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 261 / 351 | 시간 29[s] | 손실 0.90\n",
      "| 에폭 12 |  반복 281 / 351 | 시간 31[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 301 / 351 | 시간 33[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 321 / 351 | 시간 36[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 341 / 351 | 시간 39[s] | 손실 0.91\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 671 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 871 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.700%\n",
      "| 에폭 13 |  반복 1 / 351 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 21 / 351 | 시간 2[s] | 손실 0.90\n",
      "| 에폭 13 |  반복 41 / 351 | 시간 4[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 61 / 351 | 시간 6[s] | 손실 0.93\n",
      "| 에폭 13 |  반복 81 / 351 | 시간 8[s] | 손실 0.94\n",
      "| 에폭 13 |  반복 101 / 351 | 시간 11[s] | 손실 0.93\n",
      "| 에폭 13 |  반복 121 / 351 | 시간 13[s] | 손실 0.94\n",
      "| 에폭 13 |  반복 141 / 351 | 시간 15[s] | 손실 0.90\n",
      "| 에폭 13 |  반복 161 / 351 | 시간 18[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 181 / 351 | 시간 20[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 201 / 351 | 시간 22[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 221 / 351 | 시간 25[s] | 손실 0.94\n",
      "| 에폭 13 |  반복 241 / 351 | 시간 28[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 261 / 351 | 시간 31[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 281 / 351 | 시간 35[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 301 / 351 | 시간 37[s] | 손실 0.88\n",
      "| 에폭 13 |  반복 321 / 351 | 시간 40[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 341 / 351 | 시간 42[s] | 손실 0.92\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 434 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 869 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.400%\n",
      "| 에폭 14 |  반복 1 / 351 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 21 / 351 | 시간 2[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 41 / 351 | 시간 5[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 61 / 351 | 시간 7[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 81 / 351 | 시간 9[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 101 / 351 | 시간 12[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 121 / 351 | 시간 14[s] | 손실 0.88\n",
      "| 에폭 14 |  반복 141 / 351 | 시간 16[s] | 손실 0.89\n",
      "| 에폭 14 |  반복 161 / 351 | 시간 19[s] | 손실 0.92\n",
      "| 에폭 14 |  반복 181 / 351 | 시간 21[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 201 / 351 | 시간 23[s] | 손실 0.93\n",
      "| 에폭 14 |  반복 221 / 351 | 시간 25[s] | 손실 0.88\n",
      "| 에폭 14 |  반복 241 / 351 | 시간 27[s] | 손실 0.89\n",
      "| 에폭 14 |  반복 261 / 351 | 시간 30[s] | 손실 0.92\n",
      "| 에폭 14 |  반복 281 / 351 | 시간 32[s] | 손실 0.90\n",
      "| 에폭 14 |  반복 301 / 351 | 시간 34[s] | 손실 0.87\n",
      "| 에폭 14 |  반복 321 / 351 | 시간 36[s] | 손실 0.87\n",
      "| 에폭 14 |  반복 341 / 351 | 시간 39[s] | 손실 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 658 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1072\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.940%\n",
      "| 에폭 15 |  반복 1 / 351 | 시간 0[s] | 손실 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 15 |  반복 21 / 351 | 시간 2[s] | 손실 0.86\n",
      "| 에폭 15 |  반복 41 / 351 | 시간 4[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 61 / 351 | 시간 6[s] | 손실 0.91\n",
      "| 에폭 15 |  반복 81 / 351 | 시간 8[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 101 / 351 | 시간 11[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 121 / 351 | 시간 13[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 141 / 351 | 시간 15[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 161 / 351 | 시간 17[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 181 / 351 | 시간 20[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 201 / 351 | 시간 22[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 221 / 351 | 시간 24[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 241 / 351 | 시간 26[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 261 / 351 | 시간 29[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 281 / 351 | 시간 31[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 301 / 351 | 시간 33[s] | 손실 0.88\n",
      "| 에폭 15 |  반복 321 / 351 | 시간 35[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 341 / 351 | 시간 38[s] | 손실 0.90\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 412 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1441\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 227 \n",
      "---\n",
      "검증 정확도 6.940%\n",
      "| 에폭 16 |  반복 1 / 351 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 21 / 351 | 시간 2[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 41 / 351 | 시간 4[s] | 손실 0.87\n",
      "| 에폭 16 |  반복 61 / 351 | 시간 7[s] | 손실 0.89\n",
      "| 에폭 16 |  반복 81 / 351 | 시간 9[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 101 / 351 | 시간 12[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 121 / 351 | 시간 14[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 141 / 351 | 시간 17[s] | 손실 0.87\n",
      "| 에폭 16 |  반복 161 / 351 | 시간 19[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 181 / 351 | 시간 21[s] | 손실 0.91\n",
      "| 에폭 16 |  반복 201 / 351 | 시간 23[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 221 / 351 | 시간 25[s] | 손실 0.84\n",
      "| 에폭 16 |  반복 241 / 351 | 시간 27[s] | 손실 0.85\n",
      "| 에폭 16 |  반복 261 / 351 | 시간 30[s] | 손실 0.85\n",
      "| 에폭 16 |  반복 281 / 351 | 시간 32[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 301 / 351 | 시간 34[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 321 / 351 | 시간 37[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 341 / 351 | 시간 39[s] | 손실 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1107\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 852 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.320%\n",
      "| 에폭 17 |  반복 1 / 351 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 21 / 351 | 시간 2[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 41 / 351 | 시간 4[s] | 손실 0.89\n",
      "| 에폭 17 |  반복 61 / 351 | 시간 7[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 81 / 351 | 시간 9[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 101 / 351 | 시간 11[s] | 손실 0.87\n",
      "| 에폭 17 |  반복 121 / 351 | 시간 14[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 141 / 351 | 시간 16[s] | 손실 0.87\n",
      "| 에폭 17 |  반복 161 / 351 | 시간 18[s] | 손실 0.87\n",
      "| 에폭 17 |  반복 181 / 351 | 시간 20[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 201 / 351 | 시간 23[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 221 / 351 | 시간 25[s] | 손실 0.83\n",
      "| 에폭 17 |  반복 241 / 351 | 시간 27[s] | 손실 0.84\n",
      "| 에폭 17 |  반복 261 / 351 | 시간 29[s] | 손실 0.86\n",
      "| 에폭 17 |  반복 281 / 351 | 시간 31[s] | 손실 0.86\n",
      "| 에폭 17 |  반복 301 / 351 | 시간 34[s] | 손실 0.84\n",
      "| 에폭 17 |  반복 321 / 351 | 시간 36[s] | 손실 0.84\n",
      "| 에폭 17 |  반복 341 / 351 | 시간 38[s] | 손실 0.84\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1161\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 659 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 155 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1071\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 10.500%\n",
      "| 에폭 18 |  반복 1 / 351 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 18 |  반복 21 / 351 | 시간 2[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 41 / 351 | 시간 4[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 61 / 351 | 시간 7[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 81 / 351 | 시간 9[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 101 / 351 | 시간 12[s] | 손실 0.86\n",
      "| 에폭 18 |  반복 121 / 351 | 시간 14[s] | 손실 0.88\n",
      "| 에폭 18 |  반복 141 / 351 | 시간 17[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 161 / 351 | 시간 19[s] | 손실 0.82\n",
      "| 에폭 18 |  반복 181 / 351 | 시간 22[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 201 / 351 | 시간 25[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 221 / 351 | 시간 28[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 241 / 351 | 시간 31[s] | 손실 0.85\n",
      "| 에폭 18 |  반복 261 / 351 | 시간 33[s] | 손실 0.85\n",
      "| 에폭 18 |  반복 281 / 351 | 시간 36[s] | 손실 0.85\n",
      "| 에폭 18 |  반복 301 / 351 | 시간 38[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 321 / 351 | 시간 40[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 341 / 351 | 시간 43[s] | 손실 0.85\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 159 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1414\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 9.260%\n",
      "| 에폭 19 |  반복 1 / 351 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 19 |  반복 21 / 351 | 시간 2[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 41 / 351 | 시간 4[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 61 / 351 | 시간 6[s] | 손실 0.91\n",
      "| 에폭 19 |  반복 81 / 351 | 시간 9[s] | 손실 0.94\n",
      "| 에폭 19 |  반복 101 / 351 | 시간 11[s] | 손실 0.86\n",
      "| 에폭 19 |  반복 121 / 351 | 시간 13[s] | 손실 0.84\n",
      "| 에폭 19 |  반복 141 / 351 | 시간 16[s] | 손실 0.84\n",
      "| 에폭 19 |  반복 161 / 351 | 시간 18[s] | 손실 0.83\n",
      "| 에폭 19 |  반복 181 / 351 | 시간 21[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 201 / 351 | 시간 23[s] | 손실 0.81\n",
      "| 에폭 19 |  반복 221 / 351 | 시간 25[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 241 / 351 | 시간 28[s] | 손실 0.83\n",
      "| 에폭 19 |  반복 261 / 351 | 시간 30[s] | 손실 0.84\n",
      "| 에폭 19 |  반복 281 / 351 | 시간 32[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 301 / 351 | 시간 34[s] | 손실 0.81\n",
      "| 에폭 19 |  반복 321 / 351 | 시간 36[s] | 손실 0.81\n",
      "| 에폭 19 |  반복 341 / 351 | 시간 39[s] | 손실 0.81\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 171 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 846 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1414\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 8.600%\n",
      "| 에폭 20 |  반복 1 / 351 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 21 / 351 | 시간 2[s] | 손실 0.81\n",
      "| 에폭 20 |  반복 41 / 351 | 시간 4[s] | 손실 0.86\n",
      "| 에폭 20 |  반복 61 / 351 | 시간 7[s] | 손실 0.82\n",
      "| 에폭 20 |  반복 81 / 351 | 시간 9[s] | 손실 0.81\n",
      "| 에폭 20 |  반복 101 / 351 | 시간 11[s] | 손실 0.85\n",
      "| 에폭 20 |  반복 121 / 351 | 시간 14[s] | 손실 0.94\n",
      "| 에폭 20 |  반복 141 / 351 | 시간 16[s] | 손실 0.82\n",
      "| 에폭 20 |  반복 161 / 351 | 시간 18[s] | 손실 0.84\n",
      "| 에폭 20 |  반복 181 / 351 | 시간 21[s] | 손실 0.84\n",
      "| 에폭 20 |  반복 201 / 351 | 시간 23[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 221 / 351 | 시간 25[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 241 / 351 | 시간 27[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 261 / 351 | 시간 30[s] | 손실 0.81\n",
      "| 에폭 20 |  반복 281 / 351 | 시간 32[s] | 손실 0.82\n",
      "| 에폭 20 |  반복 301 / 351 | 시간 34[s] | 손실 0.84\n",
      "| 에폭 20 |  반복 321 / 351 | 시간 36[s] | 손실 0.88\n",
      "| 에폭 20 |  반복 341 / 351 | 시간 39[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 232 \n",
      "---\n",
      "검증 정확도 10.560%\n",
      "| 에폭 21 |  반복 1 / 351 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 21 |  반복 21 / 351 | 시간 2[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 41 / 351 | 시간 4[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 61 / 351 | 시간 6[s] | 손실 0.83\n",
      "| 에폭 21 |  반복 81 / 351 | 시간 9[s] | 손실 0.84\n",
      "| 에폭 21 |  반복 101 / 351 | 시간 11[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 121 / 351 | 시간 13[s] | 손실 0.84\n",
      "| 에폭 21 |  반복 141 / 351 | 시간 15[s] | 손실 0.82\n",
      "| 에폭 21 |  반복 161 / 351 | 시간 17[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 181 / 351 | 시간 20[s] | 손실 0.78\n",
      "| 에폭 21 |  반복 201 / 351 | 시간 22[s] | 손실 0.77\n",
      "| 에폭 21 |  반복 221 / 351 | 시간 24[s] | 손실 0.83\n",
      "| 에폭 21 |  반복 241 / 351 | 시간 26[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 261 / 351 | 시간 29[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 281 / 351 | 시간 31[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 301 / 351 | 시간 33[s] | 손실 0.81\n",
      "| 에폭 21 |  반복 321 / 351 | 시간 35[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 341 / 351 | 시간 38[s] | 손실 0.81\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 417 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1404\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 정확도 11.580%\n",
      "| 에폭 22 |  반복 1 / 351 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 21 / 351 | 시간 2[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 41 / 351 | 시간 4[s] | 손실 0.84\n",
      "| 에폭 22 |  반복 61 / 351 | 시간 6[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 81 / 351 | 시간 8[s] | 손실 0.81\n",
      "| 에폭 22 |  반복 101 / 351 | 시간 10[s] | 손실 0.78\n",
      "| 에폭 22 |  반복 121 / 351 | 시간 13[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 141 / 351 | 시간 15[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 161 / 351 | 시간 17[s] | 손실 0.81\n",
      "| 에폭 22 |  반복 181 / 351 | 시간 19[s] | 손실 0.84\n",
      "| 에폭 22 |  반복 201 / 351 | 시간 21[s] | 손실 0.84\n",
      "| 에폭 22 |  반복 221 / 351 | 시간 23[s] | 손실 0.82\n",
      "| 에폭 22 |  반복 241 / 351 | 시간 26[s] | 손실 0.82\n",
      "| 에폭 22 |  반복 261 / 351 | 시간 28[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 281 / 351 | 시간 30[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 301 / 351 | 시간 32[s] | 손실 0.78\n",
      "| 에폭 22 |  반복 321 / 351 | 시간 34[s] | 손실 0.78\n",
      "| 에폭 22 |  반복 341 / 351 | 시간 37[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1059\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 242 \n",
      "---\n",
      "검증 정확도 8.660%\n",
      "| 에폭 23 |  반복 1 / 351 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 21 / 351 | 시간 2[s] | 손실 0.81\n",
      "| 에폭 23 |  반복 41 / 351 | 시간 4[s] | 손실 0.82\n",
      "| 에폭 23 |  반복 61 / 351 | 시간 6[s] | 손실 0.89\n",
      "| 에폭 23 |  반복 81 / 351 | 시간 8[s] | 손실 0.82\n",
      "| 에폭 23 |  반복 101 / 351 | 시간 10[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 121 / 351 | 시간 12[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 141 / 351 | 시간 14[s] | 손실 0.76\n",
      "| 에폭 23 |  반복 161 / 351 | 시간 16[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 181 / 351 | 시간 19[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 201 / 351 | 시간 21[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 221 / 351 | 시간 23[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 241 / 351 | 시간 25[s] | 손실 0.79\n",
      "| 에폭 23 |  반복 261 / 351 | 시간 27[s] | 손실 0.81\n",
      "| 에폭 23 |  반복 281 / 351 | 시간 29[s] | 손실 0.83\n",
      "| 에폭 23 |  반복 301 / 351 | 시간 31[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 321 / 351 | 시간 33[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 341 / 351 | 시간 36[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1130\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 415 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "검증 정확도 6.140%\n",
      "| 에폭 24 |  반복 1 / 351 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 24 |  반복 21 / 351 | 시간 2[s] | 손실 0.81\n",
      "| 에폭 24 |  반복 41 / 351 | 시간 4[s] | 손실 0.78\n",
      "| 에폭 24 |  반복 61 / 351 | 시간 6[s] | 손실 0.81\n",
      "| 에폭 24 |  반복 81 / 351 | 시간 8[s] | 손실 0.79\n",
      "| 에폭 24 |  반복 101 / 351 | 시간 10[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 121 / 351 | 시간 12[s] | 손실 0.79\n",
      "| 에폭 24 |  반복 141 / 351 | 시간 14[s] | 손실 0.80\n",
      "| 에폭 24 |  반복 161 / 351 | 시간 16[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 181 / 351 | 시간 18[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 201 / 351 | 시간 20[s] | 손실 0.79\n",
      "| 에폭 24 |  반복 221 / 351 | 시간 22[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 241 / 351 | 시간 25[s] | 손실 0.76\n",
      "| 에폭 24 |  반복 261 / 351 | 시간 27[s] | 손실 0.78\n",
      "| 에폭 24 |  반복 281 / 351 | 시간 29[s] | 손실 0.78\n",
      "| 에폭 24 |  반복 301 / 351 | 시간 31[s] | 손실 0.76\n",
      "| 에폭 24 |  반복 321 / 351 | 시간 33[s] | 손실 0.76\n",
      "| 에폭 24 |  반복 341 / 351 | 시간 35[s] | 손실 0.77\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1061\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "검증 정확도 10.000%\n",
      "| 에폭 25 |  반복 1 / 351 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 25 |  반복 21 / 351 | 시간 2[s] | 손실 0.78\n",
      "| 에폭 25 |  반복 41 / 351 | 시간 4[s] | 손실 0.82\n",
      "| 에폭 25 |  반복 61 / 351 | 시간 6[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 81 / 351 | 시간 9[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 101 / 351 | 시간 13[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 121 / 351 | 시간 16[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 141 / 351 | 시간 19[s] | 손실 0.75\n",
      "| 에폭 25 |  반복 161 / 351 | 시간 21[s] | 손실 0.74\n",
      "| 에폭 25 |  반복 181 / 351 | 시간 23[s] | 손실 0.74\n",
      "| 에폭 25 |  반복 201 / 351 | 시간 25[s] | 손실 0.75\n",
      "| 에폭 25 |  반복 221 / 351 | 시간 28[s] | 손실 0.78\n",
      "| 에폭 25 |  반복 241 / 351 | 시간 30[s] | 손실 0.76\n",
      "| 에폭 25 |  반복 261 / 351 | 시간 32[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 281 / 351 | 시간 34[s] | 손실 0.78\n",
      "| 에폭 25 |  반복 301 / 351 | 시간 36[s] | 손실 0.77\n",
      "| 에폭 25 |  반복 321 / 351 | 시간 38[s] | 손실 0.80\n",
      "| 에폭 25 |  반복 341 / 351 | 시간 40[s] | 손실 0.78\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1129\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 429 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 874 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 242 \n",
      "---\n",
      "검증 정확도 8.220%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from ch07.seq2seq import Seq2seq\n",
    "from ch07.peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 seq2seq 개선\n",
    "\n",
    "이번에는 앞 절의 seq2seq를 세분화하여 학습 '속도'를 개선하고자 한다. 두 가지 기법을 소개하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 입력 데이터 반전(Reverse)\n",
    "\n",
    "첫 번째로 말 그대로 입력 데이터의 순서를 반전시키는 것이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-23.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "이 트릭을 사용하면 많은 경우 학습 진행이 빨라져서, 결과적으로 최종 정확도도 좋아진다고 합니다. \n",
    "\n",
    "그러면 왜 입력 데이터를 반전시키는 것만으로 학습의 진행이 빨라지고 정확도가 향상되는 걸까? \n",
    "\n",
    "정확하진 않지만 직관적으로 기울기 전파가 원활해지기 때문이라고 생각된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 2[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 4[s] | 손실 2.17\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 6[s] | 손실 1.96\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 8[s] | 손실 1.92\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 10[s] | 손실 1.87\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 12[s] | 손실 1.85\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 14[s] | 손실 1.83\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 16[s] | 손실 1.79\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 18[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 20[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 24[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 27[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 30[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 33[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 35[s] | 손실 1.74\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 37[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 40[s] | 손실 1.74\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "검증 정확도 0.180%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 2[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 4[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 6[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 8[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 10[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 12[s] | 손실 1.72\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 14[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 16[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 18[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 20[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 23[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 26[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 28[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 30[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 32[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 34[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 37[s] | 손실 1.67\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 994 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1544\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "검증 정확도 0.220%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 2[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 4[s] | 손실 1.65\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 6[s] | 손실 1.63\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 9[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 11[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 13[s] | 손실 1.60\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 15[s] | 손실 1.59\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 18[s] | 손실 1.57\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 20[s] | 손실 1.57\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 22[s] | 손실 1.56\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 24[s] | 손실 1.54\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 26[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 30[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 32[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 35[s] | 손실 1.50\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 37[s] | 손실 1.49\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 39[s] | 손실 1.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 108 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 648 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 138 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 448 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1373\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 348 \n",
      "---\n",
      "검증 정확도 0.560%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 2[s] | 손실 1.46\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 5[s] | 손실 1.44\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 8[s] | 손실 1.43\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 11[s] | 손실 1.42\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 14[s] | 손실 1.41\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 17[s] | 손실 1.40\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 20[s] | 손실 1.40\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 23[s] | 손실 1.38\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 26[s] | 손실 1.38\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 30[s] | 손실 1.37\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 33[s] | 손실 1.35\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 36[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 39[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 42[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 45[s] | 손실 1.32\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 48[s] | 손실 1.31\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 50[s] | 손실 1.30\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 146 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1189\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1002\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1406\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 202 \n",
      "---\n",
      "검증 정확도 1.060%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 3[s] | 손실 1.29\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 5[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 7[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 10[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 12[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 14[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 17[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 20[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 22[s] | 손실 1.25\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 24[s] | 손실 1.23\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 26[s] | 손실 1.22\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 29[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 31[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 33[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 36[s] | 손실 1.20\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 40[s] | 손실 1.19\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 43[s] | 손실 1.18\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 145 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1168\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 192 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 431 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 895 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1015\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1493\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 891 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 221 \n",
      "---\n",
      "검증 정확도 2.260%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 2[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 4[s] | 손실 1.18\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 7[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 9[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 11[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 13[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 16[s] | 손실 1.14\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 19[s] | 손실 1.14\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 22[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 24[s] | 손실 1.15\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 27[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 30[s] | 손실 1.12\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 32[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 35[s] | 손실 1.12\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 38[s] | 손실 1.11\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 40[s] | 손실 1.11\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 43[s] | 손실 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1169\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 199 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 441 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1412\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 256 \n",
      "---\n",
      "검증 정확도 2.980%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 2[s] | 손실 1.12\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 5[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 8[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 11[s] | 손실 1.09\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 13[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 16[s] | 손실 1.11\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 19[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 21[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 23[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 26[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 28[s] | 손실 1.07\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 31[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 33[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 35[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 37[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 40[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 42[s] | 손실 1.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1166\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 430 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 893 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1058\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1445\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 228 \n",
      "---\n",
      "검증 정확도 3.560%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 1.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 8 |  반복 21 / 351 | 시간 2[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 4[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 6[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 8[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 11[s] | 손실 1.08\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 13[s] | 손실 1.07\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 15[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 17[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 19[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 21[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 24[s] | 손실 1.03\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 26[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 28[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 30[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 33[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 36[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 38[s] | 손실 1.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 156 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 411 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1410\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 227 \n",
      "---\n",
      "검증 정확도 4.420%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 2[s] | 손실 1.02\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 4[s] | 손실 1.01\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 7[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 9[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 11[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 13[s] | 손실 1.01\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 15[s] | 손실 1.01\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 17[s] | 손실 1.00\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 19[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 22[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 221 / 351 | 시간 24[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 241 / 351 | 시간 26[s] | 손실 0.99\n",
      "| 에폭 9 |  반복 261 / 351 | 시간 29[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 281 / 351 | 시간 31[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 34[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 321 / 351 | 시간 37[s] | 손실 0.98\n",
      "| 에폭 9 |  반복 341 / 351 | 시간 40[s] | 손실 0.99\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 173 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 418 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 870 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1470\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 875 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 228 \n",
      "---\n",
      "검증 정확도 4.240%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 21 / 351 | 시간 2[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 41 / 351 | 시간 4[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 61 / 351 | 시간 6[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 81 / 351 | 시간 9[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 101 / 351 | 시간 12[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 121 / 351 | 시간 16[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 141 / 351 | 시간 19[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 161 / 351 | 시간 21[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 181 / 351 | 시간 24[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 201 / 351 | 시간 27[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 221 / 351 | 시간 29[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 241 / 351 | 시간 31[s] | 손실 0.95\n",
      "| 에폭 10 |  반복 261 / 351 | 시간 33[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 281 / 351 | 시간 36[s] | 손실 0.96\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 40[s] | 손실 0.95\n",
      "| 에폭 10 |  반복 321 / 351 | 시간 42[s] | 손실 0.99\n",
      "| 에폭 10 |  반복 341 / 351 | 시간 45[s] | 손실 0.99\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 663 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1444\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "검증 정확도 7.260%\n",
      "| 에폭 11 |  반복 1 / 351 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 11 |  반복 21 / 351 | 시간 2[s] | 손실 0.95\n",
      "| 에폭 11 |  반복 41 / 351 | 시간 5[s] | 손실 0.94\n",
      "| 에폭 11 |  반복 61 / 351 | 시간 7[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 81 / 351 | 시간 10[s] | 손실 0.95\n",
      "| 에폭 11 |  반복 101 / 351 | 시간 13[s] | 손실 0.97\n",
      "| 에폭 11 |  반복 121 / 351 | 시간 16[s] | 손실 0.96\n",
      "| 에폭 11 |  반복 141 / 351 | 시간 18[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 161 / 351 | 시간 20[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 181 / 351 | 시간 22[s] | 손실 0.97\n",
      "| 에폭 11 |  반복 201 / 351 | 시간 25[s] | 손실 0.98\n",
      "| 에폭 11 |  반복 221 / 351 | 시간 27[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 241 / 351 | 시간 29[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 261 / 351 | 시간 31[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 281 / 351 | 시간 33[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 301 / 351 | 시간 36[s] | 손실 0.92\n",
      "| 에폭 11 |  반복 321 / 351 | 시간 38[s] | 손실 0.93\n",
      "| 에폭 11 |  반복 341 / 351 | 시간 40[s] | 손실 0.94\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1121\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 428 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 890 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1421\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 875 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 251 \n",
      "---\n",
      "검증 정확도 4.060%\n",
      "| 에폭 12 |  반복 1 / 351 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 12 |  반복 21 / 351 | 시간 2[s] | 손실 0.93\n",
      "| 에폭 12 |  반복 41 / 351 | 시간 5[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 61 / 351 | 시간 8[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 81 / 351 | 시간 10[s] | 손실 0.95\n",
      "| 에폭 12 |  반복 101 / 351 | 시간 14[s] | 손실 0.97\n",
      "| 에폭 12 |  반복 121 / 351 | 시간 16[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 141 / 351 | 시간 18[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 161 / 351 | 시간 21[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 181 / 351 | 시간 24[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 201 / 351 | 시간 27[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 221 / 351 | 시간 30[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 241 / 351 | 시간 32[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 261 / 351 | 시간 35[s] | 손실 0.90\n",
      "| 에폭 12 |  반복 281 / 351 | 시간 37[s] | 손실 0.92\n",
      "| 에폭 12 |  반복 301 / 351 | 시간 39[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 321 / 351 | 시간 41[s] | 손실 0.91\n",
      "| 에폭 12 |  반복 341 / 351 | 시간 44[s] | 손실 0.91\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 671 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 871 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.700%\n",
      "| 에폭 13 |  반복 1 / 351 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 21 / 351 | 시간 2[s] | 손실 0.90\n",
      "| 에폭 13 |  반복 41 / 351 | 시간 6[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 61 / 351 | 시간 8[s] | 손실 0.93\n",
      "| 에폭 13 |  반복 81 / 351 | 시간 11[s] | 손실 0.94\n",
      "| 에폭 13 |  반복 101 / 351 | 시간 14[s] | 손실 0.93\n",
      "| 에폭 13 |  반복 121 / 351 | 시간 17[s] | 손실 0.94\n",
      "| 에폭 13 |  반복 141 / 351 | 시간 19[s] | 손실 0.90\n",
      "| 에폭 13 |  반복 161 / 351 | 시간 22[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 181 / 351 | 시간 25[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 201 / 351 | 시간 28[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 221 / 351 | 시간 31[s] | 손실 0.94\n",
      "| 에폭 13 |  반복 241 / 351 | 시간 34[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 261 / 351 | 시간 37[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 281 / 351 | 시간 39[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 301 / 351 | 시간 42[s] | 손실 0.88\n",
      "| 에폭 13 |  반복 321 / 351 | 시간 45[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 341 / 351 | 시간 47[s] | 손실 0.92\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 434 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 869 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.400%\n",
      "| 에폭 14 |  반복 1 / 351 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 21 / 351 | 시간 2[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 41 / 351 | 시간 4[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 61 / 351 | 시간 6[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 81 / 351 | 시간 9[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 101 / 351 | 시간 11[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 121 / 351 | 시간 13[s] | 손실 0.88\n",
      "| 에폭 14 |  반복 141 / 351 | 시간 15[s] | 손실 0.89\n",
      "| 에폭 14 |  반복 161 / 351 | 시간 17[s] | 손실 0.92\n",
      "| 에폭 14 |  반복 181 / 351 | 시간 20[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 201 / 351 | 시간 22[s] | 손실 0.93\n",
      "| 에폭 14 |  반복 221 / 351 | 시간 24[s] | 손실 0.88\n",
      "| 에폭 14 |  반복 241 / 351 | 시간 26[s] | 손실 0.89\n",
      "| 에폭 14 |  반복 261 / 351 | 시간 29[s] | 손실 0.92\n",
      "| 에폭 14 |  반복 281 / 351 | 시간 31[s] | 손실 0.90\n",
      "| 에폭 14 |  반복 301 / 351 | 시간 33[s] | 손실 0.87\n",
      "| 에폭 14 |  반복 321 / 351 | 시간 35[s] | 손실 0.87\n",
      "| 에폭 14 |  반복 341 / 351 | 시간 38[s] | 손실 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 658 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1072\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 정확도 6.940%\n",
      "| 에폭 15 |  반복 1 / 351 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 15 |  반복 21 / 351 | 시간 3[s] | 손실 0.86\n",
      "| 에폭 15 |  반복 41 / 351 | 시간 5[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 61 / 351 | 시간 9[s] | 손실 0.91\n",
      "| 에폭 15 |  반복 81 / 351 | 시간 11[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 101 / 351 | 시간 14[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 121 / 351 | 시간 17[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 141 / 351 | 시간 20[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 161 / 351 | 시간 23[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 181 / 351 | 시간 25[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 201 / 351 | 시간 28[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 221 / 351 | 시간 32[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 241 / 351 | 시간 36[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 261 / 351 | 시간 39[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 281 / 351 | 시간 42[s] | 손실 0.90\n",
      "| 에폭 15 |  반복 301 / 351 | 시간 45[s] | 손실 0.88\n",
      "| 에폭 15 |  반복 321 / 351 | 시간 47[s] | 손실 0.89\n",
      "| 에폭 15 |  반복 341 / 351 | 시간 50[s] | 손실 0.90\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 412 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1441\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 227 \n",
      "---\n",
      "검증 정확도 6.940%\n",
      "| 에폭 16 |  반복 1 / 351 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 21 / 351 | 시간 3[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 41 / 351 | 시간 6[s] | 손실 0.87\n",
      "| 에폭 16 |  반복 61 / 351 | 시간 9[s] | 손실 0.89\n",
      "| 에폭 16 |  반복 81 / 351 | 시간 11[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 101 / 351 | 시간 14[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 121 / 351 | 시간 17[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 141 / 351 | 시간 19[s] | 손실 0.87\n",
      "| 에폭 16 |  반복 161 / 351 | 시간 22[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 181 / 351 | 시간 26[s] | 손실 0.91\n",
      "| 에폭 16 |  반복 201 / 351 | 시간 29[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 221 / 351 | 시간 31[s] | 손실 0.84\n",
      "| 에폭 16 |  반복 241 / 351 | 시간 34[s] | 손실 0.85\n",
      "| 에폭 16 |  반복 261 / 351 | 시간 37[s] | 손실 0.85\n",
      "| 에폭 16 |  반복 281 / 351 | 시간 40[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 301 / 351 | 시간 42[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 321 / 351 | 시간 44[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 341 / 351 | 시간 47[s] | 손실 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1107\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 852 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 6.320%\n",
      "| 에폭 17 |  반복 1 / 351 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 21 / 351 | 시간 2[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 41 / 351 | 시간 4[s] | 손실 0.89\n",
      "| 에폭 17 |  반복 61 / 351 | 시간 6[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 81 / 351 | 시간 8[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 101 / 351 | 시간 10[s] | 손실 0.87\n",
      "| 에폭 17 |  반복 121 / 351 | 시간 12[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 141 / 351 | 시간 14[s] | 손실 0.87\n",
      "| 에폭 17 |  반복 161 / 351 | 시간 16[s] | 손실 0.87\n",
      "| 에폭 17 |  반복 181 / 351 | 시간 18[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 201 / 351 | 시간 20[s] | 손실 0.88\n",
      "| 에폭 17 |  반복 221 / 351 | 시간 22[s] | 손실 0.83\n",
      "| 에폭 17 |  반복 241 / 351 | 시간 25[s] | 손실 0.84\n",
      "| 에폭 17 |  반복 261 / 351 | 시간 27[s] | 손실 0.86\n",
      "| 에폭 17 |  반복 281 / 351 | 시간 29[s] | 손실 0.86\n",
      "| 에폭 17 |  반복 301 / 351 | 시간 31[s] | 손실 0.84\n",
      "| 에폭 17 |  반복 321 / 351 | 시간 33[s] | 손실 0.84\n",
      "| 에폭 17 |  반복 341 / 351 | 시간 35[s] | 손실 0.84\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1161\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 659 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 155 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1071\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 10.500%\n",
      "| 에폭 18 |  반복 1 / 351 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 18 |  반복 21 / 351 | 시간 2[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 41 / 351 | 시간 4[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 61 / 351 | 시간 6[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 81 / 351 | 시간 9[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 101 / 351 | 시간 11[s] | 손실 0.86\n",
      "| 에폭 18 |  반복 121 / 351 | 시간 13[s] | 손실 0.88\n",
      "| 에폭 18 |  반복 141 / 351 | 시간 15[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 161 / 351 | 시간 18[s] | 손실 0.82\n",
      "| 에폭 18 |  반복 181 / 351 | 시간 20[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 201 / 351 | 시간 22[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 221 / 351 | 시간 24[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 241 / 351 | 시간 26[s] | 손실 0.85\n",
      "| 에폭 18 |  반복 261 / 351 | 시간 28[s] | 손실 0.85\n",
      "| 에폭 18 |  반복 281 / 351 | 시간 31[s] | 손실 0.85\n",
      "| 에폭 18 |  반복 301 / 351 | 시간 33[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 321 / 351 | 시간 35[s] | 손실 0.83\n",
      "| 에폭 18 |  반복 341 / 351 | 시간 37[s] | 손실 0.85\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 159 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1414\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 9.260%\n",
      "| 에폭 19 |  반복 1 / 351 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 19 |  반복 21 / 351 | 시간 2[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 41 / 351 | 시간 4[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 61 / 351 | 시간 6[s] | 손실 0.91\n",
      "| 에폭 19 |  반복 81 / 351 | 시간 8[s] | 손실 0.94\n",
      "| 에폭 19 |  반복 101 / 351 | 시간 10[s] | 손실 0.86\n",
      "| 에폭 19 |  반복 121 / 351 | 시간 12[s] | 손실 0.84\n",
      "| 에폭 19 |  반복 141 / 351 | 시간 14[s] | 손실 0.84\n",
      "| 에폭 19 |  반복 161 / 351 | 시간 16[s] | 손실 0.83\n",
      "| 에폭 19 |  반복 181 / 351 | 시간 18[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 201 / 351 | 시간 20[s] | 손실 0.81\n",
      "| 에폭 19 |  반복 221 / 351 | 시간 22[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 241 / 351 | 시간 25[s] | 손실 0.83\n",
      "| 에폭 19 |  반복 261 / 351 | 시간 27[s] | 손실 0.84\n",
      "| 에폭 19 |  반복 281 / 351 | 시간 29[s] | 손실 0.82\n",
      "| 에폭 19 |  반복 301 / 351 | 시간 31[s] | 손실 0.81\n",
      "| 에폭 19 |  반복 321 / 351 | 시간 33[s] | 손실 0.81\n",
      "| 에폭 19 |  반복 341 / 351 | 시간 36[s] | 손실 0.81\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 171 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 846 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1414\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "검증 정확도 8.600%\n",
      "| 에폭 20 |  반복 1 / 351 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 21 / 351 | 시간 2[s] | 손실 0.81\n",
      "| 에폭 20 |  반복 41 / 351 | 시간 4[s] | 손실 0.86\n",
      "| 에폭 20 |  반복 61 / 351 | 시간 6[s] | 손실 0.82\n",
      "| 에폭 20 |  반복 81 / 351 | 시간 8[s] | 손실 0.81\n",
      "| 에폭 20 |  반복 101 / 351 | 시간 10[s] | 손실 0.85\n",
      "| 에폭 20 |  반복 121 / 351 | 시간 12[s] | 손실 0.94\n",
      "| 에폭 20 |  반복 141 / 351 | 시간 14[s] | 손실 0.82\n",
      "| 에폭 20 |  반복 161 / 351 | 시간 16[s] | 손실 0.84\n",
      "| 에폭 20 |  반복 181 / 351 | 시간 18[s] | 손실 0.84\n",
      "| 에폭 20 |  반복 201 / 351 | 시간 20[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 221 / 351 | 시간 22[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 241 / 351 | 시간 24[s] | 손실 0.80\n",
      "| 에폭 20 |  반복 261 / 351 | 시간 26[s] | 손실 0.81\n",
      "| 에폭 20 |  반복 281 / 351 | 시간 28[s] | 손실 0.82\n",
      "| 에폭 20 |  반복 301 / 351 | 시간 30[s] | 손실 0.84\n",
      "| 에폭 20 |  반복 321 / 351 | 시간 32[s] | 손실 0.88\n",
      "| 에폭 20 |  반복 341 / 351 | 시간 34[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 232 \n",
      "---\n",
      "검증 정확도 10.560%\n",
      "| 에폭 21 |  반복 1 / 351 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 21 |  반복 21 / 351 | 시간 3[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 41 / 351 | 시간 5[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 61 / 351 | 시간 8[s] | 손실 0.83\n",
      "| 에폭 21 |  반복 81 / 351 | 시간 12[s] | 손실 0.84\n",
      "| 에폭 21 |  반복 101 / 351 | 시간 17[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 121 / 351 | 시간 21[s] | 손실 0.84\n",
      "| 에폭 21 |  반복 141 / 351 | 시간 24[s] | 손실 0.82\n",
      "| 에폭 21 |  반복 161 / 351 | 시간 28[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 181 / 351 | 시간 33[s] | 손실 0.78\n",
      "| 에폭 21 |  반복 201 / 351 | 시간 35[s] | 손실 0.77\n",
      "| 에폭 21 |  반복 221 / 351 | 시간 38[s] | 손실 0.83\n",
      "| 에폭 21 |  반복 241 / 351 | 시간 42[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 261 / 351 | 시간 44[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 281 / 351 | 시간 47[s] | 손실 0.79\n",
      "| 에폭 21 |  반복 301 / 351 | 시간 52[s] | 손실 0.81\n",
      "| 에폭 21 |  반복 321 / 351 | 시간 56[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 341 / 351 | 시간 58[s] | 손실 0.81\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 417 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1404\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 정확도 11.580%\n",
      "| 에폭 22 |  반복 1 / 351 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 21 / 351 | 시간 2[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 41 / 351 | 시간 4[s] | 손실 0.84\n",
      "| 에폭 22 |  반복 61 / 351 | 시간 6[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 81 / 351 | 시간 8[s] | 손실 0.81\n",
      "| 에폭 22 |  반복 101 / 351 | 시간 10[s] | 손실 0.78\n",
      "| 에폭 22 |  반복 121 / 351 | 시간 12[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 141 / 351 | 시간 14[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 161 / 351 | 시간 16[s] | 손실 0.81\n",
      "| 에폭 22 |  반복 181 / 351 | 시간 18[s] | 손실 0.84\n",
      "| 에폭 22 |  반복 201 / 351 | 시간 21[s] | 손실 0.84\n",
      "| 에폭 22 |  반복 221 / 351 | 시간 23[s] | 손실 0.82\n",
      "| 에폭 22 |  반복 241 / 351 | 시간 25[s] | 손실 0.82\n",
      "| 에폭 22 |  반복 261 / 351 | 시간 27[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 281 / 351 | 시간 29[s] | 손실 0.79\n",
      "| 에폭 22 |  반복 301 / 351 | 시간 31[s] | 손실 0.78\n",
      "| 에폭 22 |  반복 321 / 351 | 시간 34[s] | 손실 0.78\n",
      "| 에폭 22 |  반복 341 / 351 | 시간 36[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1059\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 242 \n",
      "---\n",
      "검증 정확도 8.660%\n",
      "| 에폭 23 |  반복 1 / 351 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 21 / 351 | 시간 2[s] | 손실 0.81\n",
      "| 에폭 23 |  반복 41 / 351 | 시간 4[s] | 손실 0.82\n",
      "| 에폭 23 |  반복 61 / 351 | 시간 6[s] | 손실 0.89\n",
      "| 에폭 23 |  반복 81 / 351 | 시간 8[s] | 손실 0.82\n",
      "| 에폭 23 |  반복 101 / 351 | 시간 10[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 121 / 351 | 시간 13[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 141 / 351 | 시간 15[s] | 손실 0.76\n",
      "| 에폭 23 |  반복 161 / 351 | 시간 17[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 181 / 351 | 시간 19[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 201 / 351 | 시간 21[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 221 / 351 | 시간 24[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 241 / 351 | 시간 26[s] | 손실 0.79\n",
      "| 에폭 23 |  반복 261 / 351 | 시간 28[s] | 손실 0.81\n",
      "| 에폭 23 |  반복 281 / 351 | 시간 30[s] | 손실 0.83\n",
      "| 에폭 23 |  반복 301 / 351 | 시간 32[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 321 / 351 | 시간 34[s] | 손실 0.78\n",
      "| 에폭 23 |  반복 341 / 351 | 시간 37[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1130\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 415 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 855 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "검증 정확도 6.140%\n",
      "| 에폭 24 |  반복 1 / 351 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 24 |  반복 21 / 351 | 시간 2[s] | 손실 0.81\n",
      "| 에폭 24 |  반복 41 / 351 | 시간 4[s] | 손실 0.78\n",
      "| 에폭 24 |  반복 61 / 351 | 시간 6[s] | 손실 0.81\n",
      "| 에폭 24 |  반복 81 / 351 | 시간 8[s] | 손실 0.79\n",
      "| 에폭 24 |  반복 101 / 351 | 시간 10[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 121 / 351 | 시간 12[s] | 손실 0.79\n",
      "| 에폭 24 |  반복 141 / 351 | 시간 15[s] | 손실 0.80\n",
      "| 에폭 24 |  반복 161 / 351 | 시간 17[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 181 / 351 | 시간 19[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 201 / 351 | 시간 21[s] | 손실 0.79\n",
      "| 에폭 24 |  반복 221 / 351 | 시간 23[s] | 손실 0.77\n",
      "| 에폭 24 |  반복 241 / 351 | 시간 25[s] | 손실 0.76\n",
      "| 에폭 24 |  반복 261 / 351 | 시간 28[s] | 손실 0.78\n",
      "| 에폭 24 |  반복 281 / 351 | 시간 30[s] | 손실 0.78\n",
      "| 에폭 24 |  반복 301 / 351 | 시간 33[s] | 손실 0.76\n",
      "| 에폭 24 |  반복 321 / 351 | 시간 35[s] | 손실 0.76\n",
      "| 에폭 24 |  반복 341 / 351 | 시간 37[s] | 손실 0.77\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1061\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "검증 정확도 10.000%\n",
      "| 에폭 25 |  반복 1 / 351 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 25 |  반복 21 / 351 | 시간 2[s] | 손실 0.78\n",
      "| 에폭 25 |  반복 41 / 351 | 시간 4[s] | 손실 0.82\n",
      "| 에폭 25 |  반복 61 / 351 | 시간 7[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 81 / 351 | 시간 9[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 101 / 351 | 시간 11[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 121 / 351 | 시간 14[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 141 / 351 | 시간 16[s] | 손실 0.75\n",
      "| 에폭 25 |  반복 161 / 351 | 시간 18[s] | 손실 0.74\n",
      "| 에폭 25 |  반복 181 / 351 | 시간 20[s] | 손실 0.74\n",
      "| 에폭 25 |  반복 201 / 351 | 시간 23[s] | 손실 0.75\n",
      "| 에폭 25 |  반복 221 / 351 | 시간 25[s] | 손실 0.78\n",
      "| 에폭 25 |  반복 241 / 351 | 시간 27[s] | 손실 0.76\n",
      "| 에폭 25 |  반복 261 / 351 | 시간 30[s] | 손실 0.79\n",
      "| 에폭 25 |  반복 281 / 351 | 시간 32[s] | 손실 0.78\n",
      "| 에폭 25 |  반복 301 / 351 | 시간 34[s] | 손실 0.77\n",
      "| 에폭 25 |  반복 321 / 351 | 시간 37[s] | 손실 0.80\n",
      "| 에폭 25 |  반복 341 / 351 | 시간 39[s] | 손실 0.78\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1129\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 429 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 874 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 242 \n",
      "---\n",
      "검증 정확도 8.220%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from ch07.seq2seq import Seq2seq\n",
    "from ch07.peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 반전 여부 설정 =============================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 엿보기(Peeky)\n",
    "\n",
    "두 번째 개선을 알아보자.\n",
    "\n",
    "중요한 정보가 담긴 Encoder의 출력 __h__를 decoder의 다른 계층에게도 전해주는 것이다. \n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-26.png\" width=\"50%\" height=\"30%\">\n",
    "\n",
    "위에서와 같이 모든 시각의 Affine 계층과 LSTM 계층에 Encoder의 출력 __h__를 전해준다.\n",
    "\n",
    "기존에는 하나의 LSTM만이 소유하던 중요 정보 __h__를 여러 계층이 공유함을 알 수 있다.\n",
    "\n",
    "h를 입력 받는 계층이 2개(LSTM, Affine)가 되었다. 이는 실제로 두 벡터가 연결된 것을 의미한다. \n",
    "\n",
    "따라서 다음 그림은 두 벡터를 연결시키는 concat노드를 이용해 그린 계산 그래프이다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-27.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "peeky decoder 클래스를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from ch07.seq2seq import Seq2seq, Encoder\n",
    "\n",
    "\n",
    "class PeekyDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        N, T = xs.shape\n",
    "        N, H = h.shape\n",
    "\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        hs = np.repeat(h, T, axis=0).reshape(N, T, H)\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        out = self.lstm.forward(out)\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        score = self.affine.forward(out)\n",
    "        self.cache = H\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        H = self.cache\n",
    "\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H]\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H]\n",
    "        self.embed.backward(dembed)\n",
    "\n",
    "        dhs = dhs0 + dhs1\n",
    "        dh = self.lstm.dh + np.sum(dhs, axis=1)\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        char_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        H = h.shape[1]\n",
    "        peeky_h = h.reshape(1, 1, H)\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([char_id]).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            out = self.lstm.forward(out)\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            char_id = np.argmax(score.flatten())\n",
    "            sampled.append(char_id)\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 peekyseq2seq 클래스이다. 앞 절의 seq2seq 클래스와 거의 같고 유일한 차이는 decoder 계층이다.\n",
    "\n",
    "앞 절의 seq2seq 클래스가 decoder 클래스를 사용한 반면 이번에는 peekydecoder를 사용한다.\n",
    "\n",
    "다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보다시피 peeky와 reverse를 적용시킨 결과는 엄청나게 향상된걸 알 수 있다.\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-28.png\" width=\"60%\" height=\"30%\">\n",
    "\n",
    "그러나 주의해야 할 점이 peeky를 사용하게 되면 매개변수의 증가로 계산량이 커진다는 것이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 seq2seq를 이용하는 애플리케이션\n",
    "\n",
    "입출력이 시계열 데이터인 경우 사용할 수 있는 예시들 다음과 같은 경우들이 있다.\n",
    "\n",
    "    * 기계 번역 : 한 언어의 문장을 다른 언어의 문장으로 변환\n",
    "    \n",
    "    \n",
    "    * 자동 요약 : 긴 문장을 짧게 요약한 문장으로 변환\n",
    "    \n",
    "    \n",
    "    * 질의응답 : 질문을 응답으로 변환\n",
    "    \n",
    "    \n",
    "    * 메일 자동 응답 : 받은 메일의 문장을 답변 글로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1 챗봇\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-29.png\" width=\"50%\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2  알고리즘 학습\n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-30.png\" width=\"60%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.3 이미지 캡셔닝\n",
    "\n",
    "이미지 캡셔닝은 이미지를 문장으로 변환하는 방법이다. \n",
    "\n",
    "<img src=\"deep_learning_2_images/fig 7-32.png\" width=\"50%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 이번 장에서 배운 내용\n",
    "\n",
    "    * RNN을 이용한 언어 모델은 새로운 문장을 생성할 수 있다.\n",
    "    \n",
    "    * 문장을 생성할 때는 하나의 단어(혹은 문자)를 주고 모델의 출력(확률분포)에서 샘플링하는 과정을 반복한다.\n",
    "    \n",
    "    * RNN을 2개 조합으로써 시계열 데이터를 다른 시계열 데이터로 변환할 수 있다.\n",
    "    \n",
    "    * seq2seq는 encoder가 출발어 입력문을 인코딩하고, 인코딩된 정보를 decoder가 받아 디코딩항 도착어 출력문을 얻는다.\n",
    "    \n",
    "    * 입력문을 반전시키는 기법(reverse), 또는 인코딩된 정보를 decoder의 여러 계층에 전달하는 기법(peeky)은 seq2seq의 정확도 항샹에 효과적이다.\n",
    "    \n",
    "    * 기계번역, 챗봇, 이미지 캡셔닝 등 seq2seq는 다양한 애플리케이션에 이용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
