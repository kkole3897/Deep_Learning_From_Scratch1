{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Hello David!\n",
      "Good-bye David!\n"
     ]
    }
   ],
   "source": [
    "# class 연습하기\n",
    "\n",
    "class Man:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        print ('Initialized!')\n",
    "        \n",
    "    def hello(self):\n",
    "        print ('Hello ' + self.name + '!')\n",
    "        \n",
    "    def goodbye(self):\n",
    "        print ('Good-bye ' + self.name + '!')\n",
    "        \n",
    "m = Man('David')\n",
    "m.hello()\n",
    "m.goodbye()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.0, 2.0, 3.0])\n",
    "print (x)\n",
    "print (type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5. 7.]\n",
      "[-1. -1. -1.]\n",
      "[ 2.  6. 12.]\n",
      "[0.5        0.66666667 0.75      ]\n",
      "[0.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.0, 2.0, 3.0])\n",
    "y = np.array([2.0, 3.0, 4.0])\n",
    "print (x+y)\n",
    "print (x-y)\n",
    "print (x*y)\n",
    "print (x/y)\n",
    "print (x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "(2, 2)\n",
      "int64\n",
      "[[ 4  2]\n",
      " [ 3 10]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2], [3,4]])\n",
    "print (A)\n",
    "print (A.shape)\n",
    "print (A.dtype)\n",
    "\n",
    "B = np.array([[3, 0], [0, 6]])\n",
    "print (A+B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 20]\n",
      " [30 40]]\n"
     ]
    }
   ],
   "source": [
    "print (A*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, 6, 0.1)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "\n",
    "plt.plot(x, y1, label='sin')\n",
    "plt.plot(x, y2, linestyle='--', label='cos')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('sin & cos')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "img=imread('test.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 퍼셉트론\n",
    "\n",
    "---\n",
    "\n",
    "__퍼셉트론__(perceptron)이란 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 고안한 알고리즘이다.\n",
    "\n",
    "퍼셉트론은 딥러닝의 기원이 되는 알고리즘이기 때문에 배워야 한다.\n",
    "\n",
    "### 목표\n",
    "\n",
    " 1. 퍼셉트론을 이용하여 기본적인 AND, OR, NAND gate 만들기. \n",
    " 2. 1에서 만든 회로을 조합하여 XOR를 만들기\n",
    "\n",
    "\n",
    "### 퍼셉트론이란?\n",
    "퍼셉트론의 작동방식은 상당히 직관적이기 때문에 사진과 수식을 보면 바로 이해가 될 것이다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$y = \n",
    " \\begin{cases} \n",
    "    0 \\quad(w_1x_1 + w_2x_2 \\leq \\theta)\\\\\n",
    "    1 \\quad(w_1x_1 + w_2x_2 > \\theta) \\qquad 식[1]\\\\\n",
    "  \\end{cases}  \n",
    "$$ \n",
    "\n",
    "\n",
    "$$y = \n",
    " \\begin{cases} \n",
    "    0 \\quad(b + w_1x_1 + w_2x_2 \\leq 0)\\\\\n",
    "    1 \\quad(b + w_1x_1 + w_2x_2 > 0)\\qquad 식[2]\\\\ \n",
    "  \\end{cases}  \n",
    "$$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론에서 AND, OR, NAND gate의 구조적 차이는 없고 가중치 $w_i,\\, b$차이이다.\n",
    "\n",
    "그래서 가중치와 임계값에 따라 gate가 달라질 수 있다. \n",
    "\n",
    "### AND, NAND, OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([.5, .5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(w*x)+b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([-.5, -.5])\n",
    "    b = .7\n",
    "    tmp = np.sum(w*x)+b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([.5, .5])\n",
    "    b = -.2\n",
    "    tmp = np.sum(w*x)+b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND(0,0) : 0, NAND(0,0) : 1, OR(0,0) : 0\n",
      "AND(1,0) : 0, NAND(1,0) : 1, OR(1,0) : 1\n",
      "AND(0,1) : 0, NAND(0,1) : 1, OR(0,1) : 1\n",
      "AND(1,1) : 1, NAND(1,1) : 0, OR(1,1) : 1\n"
     ]
    }
   ],
   "source": [
    "print (\"AND(0,0) : {0}, NAND(0,0) : {1}, OR(0,0) : {2}\".format(AND(0,0), NAND(0,0), OR(0,0)))\n",
    "print (\"AND(1,0) : {0}, NAND(1,0) : {1}, OR(1,0) : {2}\".format(AND(1,0), NAND(1,0), OR(1,0)))\n",
    "print (\"AND(0,1) : {0}, NAND(0,1) : {1}, OR(0,1) : {2}\".format(AND(0,1), NAND(0,1), OR(0,1)))\n",
    "print (\"AND(1,1) : {0}, NAND(1,1) : {1}, OR(1,1) : {2}\".format(AND(1,1), NAND(1,1), OR(1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR gate\n",
    "\n",
    "<img src=\"../deep_learning_images/XOR.png\"  width=\"30%\" height=\"30%\" />\n",
    "\n",
    "AND, NAND, ORgate는 선형영역만 나눌 수 있는데 XORgate는 위와 같이 비선형영역도 나눌 수 있다.\n",
    "\n",
    "<img src=\"../deep_learning_images/XORgate.png\"  width=\"30%\" height=\"30%\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1, x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR(0,0) :  0\n",
      "XOR(1,0) :  1\n",
      "XOR(0,1) :  1\n",
      "XOR(1,1) :  0\n"
     ]
    }
   ],
   "source": [
    "print ('XOR(0,0) : ', XOR(0,0))\n",
    "print ('XOR(1,0) : ', XOR(1,0))\n",
    "print ('XOR(0,1) : ', XOR(0,1))\n",
    "print ('XOR(1,1) : ', XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 신경망\n",
    "\n",
    "---\n",
    "\n",
    "__신경망__(neural network)이란 여러개의 퍼셉트론이 층을 이룬 구조이다. \n",
    "\n",
    "일반적으로 3개의 층으로 구성되어 있다. 첫 번째 층을 입력층, 두 번째 층을 은닉층, 마지막 층을 출력층이라고 한다.\n",
    "\n",
    "<img src=\"../deep_learning_images/ann.png\"  width=\"30%\" height=\"30%\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활성화 함수\n",
    "\n",
    "중간에 은닉층을 보면 여러 입력층의 값을 받아 출력층으로 내보내는 것을 볼 수 있다. \n",
    "\n",
    "이때 입력 신호의 총합을 출력 신호로 변환해주는 함수를 활성화 함수라고 한다.\n",
    "\n",
    "앞으로 입력 신호의 총합을 $ a = b + w_1x_1 + w_2x_2 $, 활성화 함수를 $ h(a) $라고 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시그모이드 함수  \n",
    "\n",
    "<img src=\"../deep_learning_images/sigmoid.png\"  width=\"30%\" height=\"30%\" />\n",
    "\n",
    "$$ h(a) = {{1} \\over {1+\\exp(-a)}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1) #y축 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계단 함수\n",
    "\n",
    "<img src=\"../deep_learning_images/step_func.png\"  width=\"30%\" height=\"30%\" />\n",
    "\n",
    "$$ h(a) = \n",
    "\\begin{cases} \n",
    "    1 \\quad(a > 0) \\\\\n",
    "    0 \\quad(a \\leq 0)\\\\\n",
    "  \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True]\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 방법 1\n",
    "def step_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int)    \n",
    "\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "y = x > 0\n",
    "print (y)\n",
    "\n",
    "y = y.astype(np.int)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 방법 2\n",
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step_function(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1) # y축의 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU함수\n",
    "\n",
    "<img src=\"../deep_learning_images/relu.png\"  width=\"30%\" height=\"30%\" />\n",
    "\n",
    "$$ h(a) = \n",
    "\\begin{cases} \n",
    "    a \\quad(a > 0) \\\\\n",
    "    0 \\quad(a \\leq 0)\\\\\n",
    "  \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = relu(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 5.0) # y축의 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다차원 배열\n",
    "\n",
    "수 많은 데이터를 효율적으로 계산하기 위해 다차원 배열의 계산은 필수적이다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬곱\n",
    "\n",
    "행렬 곱셈을 위해 numpy.dot() 함수를 이용한다.\n",
    "\n",
    "$ A \\times B = C $라는 행렬 계산을 할 때 반드시 A의 열 크기와 B의 행 크기가 일치해야 한다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../deep_learning_images/dot.png\"  width=\"30%\" height=\"30%\" />\n",
    "\n",
    "$$ A \\in M^{3\\times2}, B \\in M^{2\\times1}, C \\in M^{3\\times1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(2,)\n",
      "[23 53 83]\n"
     ]
    }
   ],
   "source": [
    "A =  np.array([[1,2], [3,4], [5,6]])\n",
    "print (A.shape)\n",
    "\n",
    "B = np.array([7, 8])\n",
    "print (B.shape)\n",
    "print (np.dot(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 행렬 곱\n",
    "\n",
    "<img src=\"../deep_learning_images/ann_dot.png\"  width=\"70%\" height=\"30%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[[1 3 5]\n",
      " [2 4 6]]\n",
      "(2, 3)\n",
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2])\n",
    "print (X.shape)\n",
    "\n",
    "W = np.array([[1, 3, 5], [2, 4, 6]])\n",
    "print (W)\n",
    "print (W.shape)\n",
    "\n",
    "Y = np.dot(X, W)\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3층 신경망 구현하기\n",
    "\n",
    "입력층 2개, 첫 번째 은닉층은 3개, 두 번째 은닞층은 2개, 출력층은 2개의 뉴런으로 구성된 3층 신경망을 만들어보자!\n",
    "\n",
    "<img src=\"../deep_learning_images/3_layer.png\"  width=\"50%\" height=\"30%\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 층의 신호 전달 구현하기\n",
    "\n",
    "입력층에서 첫 번째 은닉층으로!\n",
    "\n",
    "<img src=\"../deep_learning_images/input2hidden.png\"  width=\"50%\" height=\"30%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n",
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "#입력층에서 1층으로\n",
    "\n",
    "X = np.array([1.0 , 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "B1= np.array([.1, .2, .3])\n",
    "\n",
    "print (W1.shape)\n",
    "print (X.shape)\n",
    "print (B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1\n",
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print (A1)\n",
    "print (Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번쨰 은닉층에서 두 번째 은닉층으로!\n",
    "\n",
    "<img src=\"../deep_learning_images/hidden2hidden.png\"  width=\"50%\" height=\"30%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[0.51615984 1.21402696]\n",
      "[0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "#1층에서 2층으로\n",
    "\n",
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [.3, .6]])\n",
    "B2= np.array([.1, .2])\n",
    "\n",
    "print (Z1.shape)\n",
    "print (W2.shape)\n",
    "print (B2.shape)\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)\n",
    "\n",
    "print (A2)\n",
    "print (Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 은닉층에서 출력층으로!!\n",
    "\n",
    "<img src=\"../deep_learning_images/hidden2out.png\"  width=\"50%\" height=\"30%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층의 활성화 함수로 항등 함수를 사용했다.\n",
    "def identify_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[.1, .3], [.2, .4]])\n",
    "B3 = np.array([.1, .2])\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identify_function(A3) # 혹은 Y = A3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([.1, .2, .3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [.3, .6]])\n",
    "    network['b2'] = np.array([.1, .2])\n",
    "    network['W3'] = np.array([[.1, .3], [.2, .4]])\n",
    "    network['b3'] = np.array([.1, .2])\n",
    "    \n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identify_function(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, .5])\n",
    "y = forward(network, x)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출력층 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 항등 함수와 소프트맥스 함수 구현하기(항등함수는 생략)\n",
    "\n",
    "$$y_k = {{\\exp(a_k)} \\over {\\sum_{i=1}^{n} \\exp(a_i)}}$$\n",
    "\n",
    "<img src=\"../deep_learning_images/softmax.png\" width=\"20%\" height=\"20%\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소프트맥스 함수 구현 시 주의점\n",
    "\n",
    "큰 값을 그대로 지수로 넘겨버리면 컴퓨터가 표현할 수 있는 수를 넘어버리기 때문에 임의의 상수(입력값 중 최댓값)를 빼준 다음 지수로 넘겨준다.\n",
    "\n",
    "$$\\begin{align*}y_k = {\\exp(a_k) \\over \\sum_{i=1}^n \\exp(a_i)} &=  {C\\exp(a_k) \\over C\\sum_{i=1}^n \\exp(a_i)} \\\\ &=  {\\exp(a_k + \\log C) \\over \\sum_{i=1}^n \\exp(a_i + \\log C)} \\\\ &=  {\\exp(a_k + C') \\over \\sum_{i=1}^n \\exp(a_i + C')}\\end{align*}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[  0 -10 -20]\n",
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiho8732/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a = np.array([1010, 1000, 990])\n",
    "print (np.exp(a) / np.sum(np.exp(a)))\n",
    "\n",
    "c = np.max(a)\n",
    "print (a-c)\n",
    "print (np.exp(a-c) / np.sum(np.exp(a-c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손글씨 숫자 인식\n",
    "\n",
    "### MNIST 데이터셋\n",
    "\n",
    "load_mnist함수는 읽은 MNIST 데이터를 (__훈련 이미지, 훈련 레이블__), (__시험 이미지, 시험 레이블__) 형식으로 반환합니다.\n",
    "\n",
    "파라미터로는 normalize, flatten, one_hot_label이 있습니다.\n",
    "\n",
    "    * normalize     : 입력 이미지의 픽셀값을 0.0~1.0 사이의 값으로 정규화\n",
    "    * flatten       : 입력 이미지를 1차원 배열로 만듬\n",
    "    * one_hot_label : 원핫인코딩 형태로 저장\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "파이썬에는 __pickle__이라는 편리한 기능이 있다. 프로그램 실행 중에 특정 객체를 파일로 저장한다. 저장해둔 pickle 파일을 로드하면 실행 당시 객체를 즉시 복원할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)   # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# 처음 한 번은 몇 분 정도 걸립니다.\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "# 각 데이터의 형상 출력\n",
    "print (x_train.shape) # (60000, 784)\n",
    "print (t_train.shape) # (60000,)\n",
    "print (x_test.shape)  # (10000, 784)\n",
    "print (t_test.shape)  # (10000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망의 추론 처리\n",
    "\n",
    "입력층 뉴런 : 784개            # 이미지 크기가 28$\\times$28\n",
    "\n",
    "출력층 뉴런 : 10개             # 구분해야 되는 숫자가 0~9\n",
    "\n",
    "\n",
    "첫 번째 은닉층 뉴런 : 50개\n",
    "\n",
    "두 번쨰 은닉층 뉴런 : 100개     # 임의로 정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9352\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def get_data():\n",
    "    # 정규화를 했고 1차원 배열로 만들었다.\n",
    "    (x_train, t_train), (x_test, t_test) = \\\n",
    "        load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open('sample_weight.pkl', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    \n",
    "    return y\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "        \n",
    "\n",
    "print ('Accuracy : ' + str(float(accuracy_cnt) / len(x)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 처리\n",
    "\n",
    "효율적을 계산하기 위해 100개의 데이터를 한 묶음로 설정해 학습시킨다. 이때 묶음을 __배치__라 부른다.\n",
    "\n",
    "<img src=\"../deep_learning_images/matsizeflow.png\" width=\"50%\" height=\"50%\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(784,)\n",
      "(784, 50)\n",
      "(50, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "x, _ = get_data()\n",
    "x = x[:100]\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "print (x.shape)\n",
    "print (x[0].shape)\n",
    "print (W1.shape)\n",
    "print (W2.shape)\n",
    "print (W3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "    \n",
    "print ('Accuracy : ' + str(float(accuracy_cnt) / len(x)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "<argmax에 대한 예시>\n",
    "argmax함수 파라미터'axis'를 기준으로 값이 가장 큰 값의 인덱스를 반환한다.\n",
    "'''\n",
    "x = np.array([[.1, .8, .1], [.3, .1, .6], [.2, .5, .3], [.8, .1, .1]])\n",
    "y = np.argmax(x, axis=1)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 2, 1, 0])\n",
    "t = np.array([1, 2, 0, 0])\n",
    "print (y==t)\n",
    "print (np.sum(y==t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번 장에서 배운 내용\n",
    "\n",
    "    * 신경망에서는 활성화 함수로 시그모이드 함수와 ReLU함수 같은 매끄럽게 변화하는 함수를 이용한다.\n",
    "    * 넘파이의 다차원 배열을 잘 사용하면 신경망을 효율적으로 구현할 수 있다.\n",
    "    * 기계학습 문제는 크게 회귀와 분류로 나눌 수 있다.\n",
    "    * 출력층의 활성화 함수로는 회귀에서는 주로 항등 함수를, 분류에서는 주로 소프트맥스 함수를 이용한다.\n",
    "    * 분류에서는 출력층을 뉴런 수를 분류하려는 클래스 수와 같게 설정한다.\n",
    "    * 입력 데이터를 묶은 것을 배치라 하며, 추론 처리를 이 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 학습\n",
    "\n",
    "__학습__이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻한다.\n",
    "\n",
    "이번 장에서는 신경망이 학습할 수 있도록 해주는 __지표__인 손실 함수를 다룰 것이다.\n",
    "\n",
    "손실 함수의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾아라!!\n",
    "\n",
    "가장 작게 만들기 위해 함수의 기울기를 활용하는 경사법을 사용하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수\n",
    "\n",
    "### 평균 제곱 오차(Mean Square Error, MSE)\n",
    "\n",
    "$$ E = {1 \\over 2} \\sum_{k}(y_k-t_k)^2 $$\n",
    "\n",
    "$y_k$는 신경망의 출력값\n",
    "\n",
    "$t_k$는 정답 레이블\n",
    "\n",
    "k는 데이터의 차원 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "\n",
    "# 정답은 2\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1 : '2'일 확률이 가장 높다고 추정함 (0.6)\n",
    "y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0]\n",
    "print (mean_squared_error(np.array(y), np.array(t)))\n",
    "\n",
    "# 예2 : '7'일 확률이 가장 높다고 추정함 (.6)\n",
    "y = [.1, .05, .1, 0, .05, .1, 0, .6, 0, 0]\n",
    "print (mean_squared_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차(Cross Entropy Error, CEE)\n",
    "\n",
    "$$ E=-\\sum_{k}t_k\\log y_k$$\n",
    "\n",
    "이 문제에선 $y_k$는 신경망의 출력, $t_k$는 주어진 정답 레이블\n",
    "\n",
    "<질문>\n",
    "\n",
    "$t_k$가 원핫인코딩형태로 출력이 된다면 CEE는 실질적으로 그냥 $E= -\\sum_{k}\\log y_k$ 아닌가...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    #미소량 delta를 더해준 이유는 만약 y=0이라면 log값이 음의 무한대로 가버리는 것을 방지하기 위함이다/\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y + delta))\n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0]\n",
    "print (cross_entropy_error(np.array(y), np.array(t)))\n",
    "\n",
    "y = [.1, .05, .1, 0, .05, .1, 0, .6, 0, 0]\n",
    "print (cross_entropy_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습\n",
    "\n",
    "$$ E = -{1 \\over N}\\sum_{n}\\sum_{k}t_{nk}logy_{nk}$$\n",
    "\n",
    "총 데이터가 $N$개, $t_{nk}$는 $n$ 번째 데이터의 $k$ 번째 값을 의미한다. \n",
    "\n",
    "미니배치 사이즈가 100일 때 $t_{21}$은 전체 데이터에서 201번째 데이터를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print (x_train.shape) # (60000, 784)\n",
    "print (t_train.shape) # (60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24820 23343 43869 51255 12025 29077 45538  2650 39743 25787]\n"
     ]
    }
   ],
   "source": [
    "# np.random.choice()\n",
    "# 지정한 범위의 수 중에서 무작위로 원하는 개수의 인덱스를 반환한다.\n",
    "\n",
    "print (np.random.choice(60000, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답레이블이 원핫인코딩인 경우\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]    \n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<y[np.arange(batch_size), t] 설명>\\n\\n예를 들어 batch_size=5이면 np.arange(batch_size)=[0, 1, 2, 3, 4] 이 때의 t=[2, 7, 0, 9, 4]이다.\\ny[np.arange(batch_size), t]=[y[0, 2], y[1, 7], y[2, 0], y[3, 9], y[4, 4]]인 numpy배열\\n\\n<질문>\\n그런데 위의 함수를 보면 shape이 (1,y.size)이다. y[0,2]는 존재할 수 있어도 y[1,7], y[2,0] 같은 위치가 존재할 수 있나??\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답레이블이 숫자레이블로 주어진 경우\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]    \n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "'''\n",
    "<y[np.arange(batch_size), t] 설명>\n",
    "\n",
    "예를 들어 batch_size=5이면 np.arange(batch_size)=[0, 1, 2, 3, 4] 이 때의 t=[2, 7, 0, 9, 4]이다.\n",
    "y[np.arange(batch_size), t]=[y[0, 2], y[1, 7], y[2, 0], y[3, 9], y[4, 4]]인 numpy배열\n",
    "\n",
    "<질문>\n",
    "그런데 위의 함수를 보면 shape이 (1,y.size)이다. y[0,2]는 존재할 수 있어도 y[1,7], y[2,0] 같은 위치가 존재할 수 있나??\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 손실 함수를 설정하는가?\n",
    "\n",
    "높은 정확도를 원한다면 정확도를 올리면 되는데 왜 굳이 '손실 함수의 값'을 주목하는 걸까?\n",
    "\n",
    "최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾는다.\n",
    "\n",
    "이때 매개변수의 미분을 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복하기 때문이다.\n",
    "\n",
    "그리고 정확도를 지표로 삼을 수 없는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분\n",
    "\n",
    "### 미분\n",
    "\n",
    "$${df(x) \\over dx} = \\lim_{h\\to0} {f(x+h)-f(x) \\over h}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "# h값이 너무 작아 컴퓨터가 0으로 인식한다.\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e-50\n",
    "    return (f(x+h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 구현 예\n",
    "#(x+h)와ㅏ (x-h)일 때의 함수f의 차분을 계산해 오차를 줄인다.\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4    # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, 20, .1) # 0에서 20까지 0.1 간격의 배열 x를 만든다(20은 미포함)\n",
    "y = function_1(x)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print (numerical_diff(function_1, 5))\n",
    "print (numerical_diff(function_1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "    # 또는 return np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.00000000000378\n",
      "7.999999999999119\n"
     ]
    }
   ],
   "source": [
    "# 문제1 x_0 = 3, x_1 = 4일 때, x_0에 대한 편미분을 구하라.\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2\n",
    "print (numerical_diff(function_tmp1, 3.0))\n",
    "\n",
    "def function_tmp2(x1):\n",
    "    return 3**2 + x1*x1\n",
    "print (numerical_diff(function_tmp2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4  # 0.0001\n",
    "    grad = np.zeros_like(x)  # x와 형상이 같은 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[0. 4.]\n",
      "[6. 0.]\n"
     ]
    }
   ],
   "source": [
    "print (numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
    "print (numerical_gradient(function_2, np.array([0, 2.0])))\n",
    "print (numerical_gradient(function_2, np.array([3.0, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사법(경사 하강법)\n",
    "\n",
    "각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기이다.\n",
    "\n",
    "그러나 기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지는 보장할 수 없다.\n",
    "\n",
    "실제로 복잡한 함수에서는 기울기가 가리키는 방향에 최솟값이 없는 경우가 대부분이다.\n",
    "\n",
    "$$x_0 = x_0 - \\eta{\\partial f \\over \\partial x_0}$$\n",
    "$$x_1 = x_1 - \\eta{\\partial f \\over \\partial x_1}$$\n",
    "$\\eta$는 __학습률__(learning rate)라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.11110793e-10  8.14814391e-10]\n"
     ]
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print (gradient_descent(function_2, init_x = init_x, lr=0.1, step_num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.58983747e+13 -1.29524862e+12]\n",
      "[-2.99999994  3.99999992]\n"
     ]
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예 : lr=10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print (gradient_descent(function_2, init_x=init_x, lr=10, step_num=100))\n",
    "\n",
    "# 학습률이 너무 작은 예 : lr=1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print (gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 기울기\n",
    "\n",
    "사이즈가 $2\\times3$, 가중치가 __W__, 손실 함수가 __L__로 예를 들어 보자.\n",
    "\n",
    "이때 경사는 ${\\partial L \\over \\partial \\textbf{W}}$이다. 수식은 다음과 같다.\n",
    "\n",
    "$$ \\textbf{W} = \\begin{pmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\end{pmatrix}$$\n",
    "$$ {\\partial L \\over \\partial \\textbf{W}} = \\begin{pmatrix} {\\partial L \\over \\partial w_{11}} & {\\partial L \\over \\partial w_{12}} & {\\partial L \\over \\partial w_{13}} \\\\ {\\partial L \\over \\partial w_{21}} & {\\partial L \\over \\partial w_{22}} & {\\partial L \\over \\partial w_{23}} \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3) # 정규분포로 초기화\n",
    "        \n",
    "    def predict(self, x)    :\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79119826 -1.36844391 -0.22465247]\n",
      " [ 0.67290516  1.20115419  0.97860445]]\n",
      "[1.0803336  0.25997243 0.74595253]\n",
      "0\n",
      "1.1026602755641617\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print (net.W)\n",
    "\n",
    "x = np.array([.6, .9])\n",
    "p = net.predict(x)\n",
    "print (p)\n",
    "print (np.argmax(p))\n",
    "\n",
    "t = np.array([0, 0, 1])\n",
    "print (net.loss(x, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.27828614  0.12252176 -0.4008079 ]\n",
      " [ 0.4174292   0.18378265 -0.60121185]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n더 쉬운 방법\\nf = lambda W : net.loss(x, t)\\ndW = numerical_gradient(f, net.W)\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print (dW)\n",
    "\n",
    "'''\n",
    "더 쉬운 방법\n",
    "f = lambda W : net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 구현하기\n",
    "\n",
    "1. 미니배치\n",
    "   \n",
    "   훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표\n",
    "   \n",
    "   (이때 데이터를 미니배치로 무작위로 선정하기 때문에 __확률적 경사 하강법__(Stochastic gradient descent. aka __SGD__)라고 한다.)\n",
    "\n",
    "\n",
    "2. 기울기 산출\n",
    "   \n",
    "   미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.\n",
    " \n",
    "\n",
    "3. 매개변수 갱신\n",
    "   \n",
    "   가중치 매개변수를 기울기 방향으로 아주 조금 갱신합니다.\n",
    "   \n",
    "\n",
    "4. 반복\n",
    "   \n",
    "   1~3단계를 반복한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=.01):\n",
    "        # 가충치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "    \n",
    "        return y\n",
    "\n",
    "\n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "    \n",
    "        return cross_entropy_error(y, t)\n",
    "\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "    \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "    \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "    \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print (net.params['W1'].shape) # (784, 100)\n",
    "print (net.params['b1'].shape) # (100,)\n",
    "print (net.params['W2'].shape) # (100, 10)\n",
    "print (net.params['b2'].shape) # (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터 (100장 분량)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터 (100장 분량)\n",
    "t = np.random.rand(100, 10)  # 더미 정답 레이블 (100장 분량)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 기울기 계산\n",
    "\n",
    "print (grads['W1'].shape) # (784, 100)\n",
    "print (grads['b1'].shape) # (100,)\n",
    "print (grads['W2'].shape) # (100, 10)\n",
    "print (grads['b2'].shape) # (10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000 # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 비니배치 크기\n",
    "learning_rate = .1\n",
    "\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    #기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch) # 성능 개선판!!\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../deep_learning_images/miniloss.png\" width=\"80%\" height=\"50%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
    "\n",
    "iters_num = 10000 # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 비니배치 크기\n",
    "learning_rate = .1\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_bathc, t_batch) # 성능 개선판!\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for ket in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print (('train acc, test acc : ' + str(train_acc) + ', ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../deep_learning_images/trainNtest_acc.png\" width=\"50%\" height=\"20%\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번 장에서 배운 내용\n",
    "\n",
    "    * 기계학습에서 사용하는 데이터셋은 훈련 데이터와 실험 데이터로 나눠 사용한다.\n",
    "    * 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가한다.\n",
    "    * 신경망 학습은 손실 함수를 지표로 손실\n",
    "    * 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신한다.\n",
    "    * 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을\n",
    "      갱신하는 작업을 반복ㅎ나다.\n",
    "    * 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 한다.\n",
    "    * 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다.\n",
    "    * 수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단하다. 한편, 다음 장에서 구현하는 (다소 복잡한)\n",
    "      오차역전파법은 기울기를 고속으로 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 오차역전파법\n",
    "\n",
    "앞 장에서는 수치 미분을 통해 가중치의 매개변수의 기울기를 구했는데 시간이 오래 걸린다는 단점이 있다.\n",
    "\n",
    "이번 장에서 __오차역전파법__을 통해 매개변수의 기울기를 효율적으로 계산해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계산 그래프\n",
    "\n",
    "__계산 그래프__는 계산 과정을 그래프로 나타낸 것이다.\n",
    "\n",
    "여기서 그래프는 그래프 자료구조로, __노드__와 __에지__로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 곱셈 노드의 역전파\n",
    "\n",
    "$ z = xy $라는 식을 생각해보자.\n",
    "\n",
    "$${\\partial z \\over \\partial x} = y$$\n",
    "$${\\partial z \\over \\partial y} = x$$\n",
    "\n",
    "<img src=\"../deep_learning_images/backprop.png\" width=\"70%\" height=\"50%\" /> \n",
    "\n",
    "곱셈 노트 역전파는 상류의 값에 순전파 때의 입력 신호들을 바꿔 곱해서 하류로 보낸다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 곱셈 계층\n",
    "\n",
    "흐음...그냥 대충 이해하자면 알겠는데 왜 다시 생각해보면 뭔가 찝찝하네...\n",
    "\n",
    "뭐 떄문에 그렇지??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y  # x와 y를 바꾼다.\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print (price) # 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print (dapple, dapple_num, dtax) # 2.2 110 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def  backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들 \n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num) # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) # (3)\n",
    "price = mul_tax_layer.forward(all_price_tax) # (4)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice) # (4)\n",
    "dapple_price, dorange_price = add_apple_range_layer.backward(dall_price) # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price) # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price) # (1)\n",
    "\n",
    "print (price) # 715\n",
    "print (dapple_num, dapple, dorange, dorange_num, dtax) # 110 2.2 3.3 165 650\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활성화 삼수 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU 계층\n",
    "\n",
    "ReLU 수식의 미분은 다음과 같다.\n",
    "\n",
    "$$ {\\partial y \\over \\partial x} = \n",
    "\\begin{cases} \n",
    "    1 \\quad(x > 0) \\\\\n",
    "    0 \\quad(x \\leq 0)\\\\\n",
    "  \\end{cases}$$\n",
    "  \n",
    "<img src=\"../deep_learning_images/reluback.png\" width=\"70%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backwar(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print (x)\n",
    "\n",
    "mask = (x <= 0)\n",
    "print (mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 계층\n",
    "\n",
    "Sigmoid 계층의 순전파 계산 그래프는 다음과 같다.\n",
    "\n",
    "<img src=\"../deep_learning_images/sigmoidforward.png\" width=\"70%\" height=\"50%\" />\n",
    "\n",
    "### 1단계\n",
    "\n",
    "'/' 노드, 즉 $y={1 \\over x}$을 미분하면 다음과 같다.\n",
    "\n",
    "$$\\begin{align*}{\\partial y \\over \\partial x} &= -{1 \\over x^2} \\\\\n",
    "&= -y^2\\end{align*}$$\n",
    "\n",
    "<img src=\"../deep_learning_images/sigmoidforward2.png\" width=\"70%\" height=\"50%\" />\n",
    "\n",
    "### 2단계\n",
    "\n",
    "'+'노드는 상류의 값을 여과 없이 하루로 내보내는게 끝이다.\n",
    "\n",
    "<img src=\"../deep_learning_images/sigmoidforward3.png\" width=\"70%\" height=\"50%\" />\n",
    "\n",
    "\n",
    "### 3단계\n",
    "\n",
    "'exp'노드는 $y=\\exp(x)$ 연산을 수행하여, 미분은 다음과 같다.\n",
    "\n",
    "$${\\partial y \\over \\partial x} = \\exp (x)$$\n",
    "\n",
    "<img src=\"../deep_learning_images/sigmoidforward4.png\" width=\"70%\" height=\"50%\" />\n",
    "\n",
    "### 4단계\n",
    "\n",
    "'$\\times$'노드는 순전파 때의 값을 '서로 바꿔' 곱합니다.\n",
    "\n",
    "<img src=\"../deep_learning_images/sigmoidforward5.png\" width=\"70%\" height=\"50%\" />\n",
    "\n",
    "\n",
    "$$\\begin{align*}{\\partial \\textbf {L} \\over \\partial y}y^2 \\exp(-x) &= {\\partial \\textbf {L} \\over \\partial y}\n",
    "{1 \\over (1+\\exp(-x))^2} \\exp(-x) \\\\ \n",
    "&= {\\partial \\textbf {L} \\over \\partial y}\n",
    "{1 \\over 1+\\exp(-x)} {\\exp(-x) \\over 1+\\exp(-x)} \\\\\n",
    "&= {\\partial \\textbf {L} \\over \\partial y}y(1-y) \\end{align*}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 +np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1 - self.out) * self.out\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine/Softmax 계층 구현하기\n",
    "\n",
    "###  배치용 Affine 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# 순전파 편향 덧셈\n",
    "X_dot_W = np.array([[0, 0, 0], [10, 10, 10]])\n",
    "B = np.array([1, 2, 3])\n",
    "\n",
    "print (X_dot_W)\n",
    "print (X_dot_W + B)\n",
    "\n",
    "# 역전파 편향 덧셈\n",
    "dY = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print (dY)\n",
    "dB = np.sum(dY, axis=0)\n",
    "print (dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax-with-Loss 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __inti__(self):\n",
    "        self.loss = None # 손실\n",
    "        self.y = None # softmax의 출력\n",
    "        self.t = None # 정답 레이블(원핫벡터)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backwar(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오차역전파법 구현하기\n",
    "\n",
    "### 신경망 학습의 전체 그림\n",
    "\n",
    "1. 미니배치\n",
    "   \n",
    "   훈련 데이터 중 일부를 무작위로 가져옵니다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표입니다.\n",
    "   \n",
    "\n",
    "2. 기울기 산출\n",
    "\n",
    "   미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 궇바니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시합니다.\n",
    "   \n",
    "\n",
    "3. 매개변수 갱신\n",
    "    \n",
    "   가중치 매개변수를 기울기 방향으로 아주 조금 갱신합니다.\n",
    "   \n",
    "\n",
    "4. 반복\n",
    "    \n",
    "   1~3 단계를 반복합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차역전파법을 적용한 신경망 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-c6fc610684f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight__init__std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-c6fc610684f5>\u001b[0m in \u001b[0;36mTwoLayerNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 계층 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Affine1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Relu1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight__init__std=.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "    \n",
    "    # 계층 생성\n",
    "    self.layers = OrderedDict()\n",
    "    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "    self.layers['Relu1'] = Relu()\n",
    "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "    \n",
    "    self.lastlayer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x    \n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "    \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "    \n",
    "        return grads            \n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layer.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 결과 저장    \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine11'].db\n",
    "        grads['W2'] = self.layers['Affine12'].dW\n",
    "        grads['b2'] = self.layers['Affine13'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차역전파법으로 구한 기울기 검증하기\n",
    "\n",
    "해석적 방법은 오차역전파법을 이용하여 매개변수가 많아도 효율적으로 계산할 수 있다.\n",
    "\n",
    "그러면 수치 미분은 쓸모가 없는 것일까?\n",
    "\n",
    "아니다. 수치 미분은 구현이 오차역전파법보다 쉽기 때문에 정확히 구현했는지 확인하기 위해 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_backrprop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-c7f675c5b8bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 각 가중치의 차이의 절대값을 구한 후, 그 절댓값들의 평균을 낸다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad_numerical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_backrprop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_numerical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_backrprop' is not defined"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNetdd\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.numerical_gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 차이의 절대값을 구한 후, 그 절댓값들의 평균을 낸다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backrprop[key] - grad_numerical[key]))\n",
    "    print (key + ':' + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차역전파법을 사용한 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
    "\n",
    "iters_num = 10000 # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = .1\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 오차역전파법으로 기울기 계산\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "        \n",
    "    # 매개변수 갱신\n",
    "    for ket in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print (('train acc, test acc : ' + str(train_acc) + ', ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번 장에서 배운 내용\n",
    "\n",
    "    * 계산 그래프를 이용하면 계산 과정을 시각적으로 파악할 수 있다.\n",
    "    * 계산 그래프의 노드는 국소적 계산으로 구성된다. 국소적 계산을 조합해 전체 계산을 구성한다.\n",
    "    * 계산 그래프의 순전파는 통상의 계산을 수행한디. 한편 계산 그래프의 역전파로는 각 노드의 미분을 구할 수 있다.\n",
    "    * 신경망의 구성 요소를 계층으로 구현하여 기울기를 효율적으로 계산할 수 있다(오차역전파법).\n",
    "    * 수치 미분과 오차역전파법의 결과를 비교하면 오차역전파법의 구현에 잘못이 없는지 확인할 수 있다(기울기 확인)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 . 학습 관련 기술들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 매개변수 갱신\n",
    "\n",
    "### 확률적 경사 하강법(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD의 단점\n",
    "\n",
    "함수(__비등방성 함수__)에 따라 x방향의 기울기가 작아서 빠르게 최솟값이 되는 점으로 수렴하지 않는다.\n",
    "\n",
    "함수 $f(x,y) = {1 \\over 20}x^2+y^2$를 보자.\n",
    "\n",
    "이 함수의 기울기 벡터장은 다음과 같다.\n",
    "\n",
    "<img src=\"../deep_learning_images/SGDvector.png\" width=\"30%\" height=\"30%\" />\n",
    "\n",
    "이때의 최적화 경로는 다음과 같다.\n",
    "\n",
    "<img src=\"../deep_learning_images/SGD.png\" width=\"30%\" height=\"30%\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모멘텀\n",
    "\n",
    "모멘텀 기법의 수식은 다음과 같다.\n",
    "\n",
    "<img src=\"../deep_learning_images/momentum.png\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "다음은 최적화 경로이다.\n",
    "\n",
    "<img src=\"../deep_learning_images/momentum2.png\" width=\"20%\" height=\"20%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=.01, momentum=.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def upate(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "            for key in params.keys():\n",
    "                self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "                params [key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AdaGrad\n",
    "\n",
    "다음은 AdaGrad기법의 수식이다.\n",
    "\n",
    "<img src=\"../deep_learning_images/ada1.png\" width=\"20%\" height=\"20%\" />\n",
    "<img src=\"../deep_learning_images/ada2.png\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "그 때의 최적화 경로이다.\n",
    "\n",
    "<img src=\"../deep_learning_images/ada3.png\" width=\"40%\" height=\"40%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "                \n",
    "            for key in params.keys():\n",
    "                self.h[key] += grads[key] * grads[key]\n",
    "                params[key] -= self.lr * grads[key] / (np.sqry(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "\n",
    "모멘텀기법과 AdaGrad기법을 섞은 것이다. common폴더의 optimizer.py참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 은닉층의 활성화값 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "x = np.random.randn(1000, 100) # 1000개의 데이터\n",
    "node_num = 100         # 각 은닉층의 노드(뉴런) 수\n",
    "hidden_layers_size = 5 # 은닉층이 5개\n",
    "activations = {}       # 이곳에 활성화 결과(활성화값)를 저장\n",
    "\n",
    "for i in range(hidden_layers_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "        \n",
    "    w = np.random.randn(node_num, node_num) * 1\n",
    "    # w = np.random.randn(node_num, node_num) * .01 -- 표준편차가 0.01인 정규분포의 경우 각 층의 활성화값 분포\n",
    "    # w = np.random.randn(node_num, node_num) / np.sqrt(node_num) -- Xavier초깃값\n",
    "    a = np.dot(x, w)\n",
    "    z = sigmoid(a)\n",
    "    # z = relu(a) # He초깃값\n",
    "    activations[i] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 히스토그램 그리기\n",
    "for i,a in activations.items():\n",
    "    plt.subplot(1, len(activations), i+1)\n",
    "    plt.title(str(i+1) + '-layer')\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버피팅\n",
    "\n",
    "오버피팅은 주로 다음과 같은 경우에 일어난다.\n",
    "    \n",
    "    * 매개변수가 많고 표현력이 높은 모델\n",
    "    * 훈련 데이터가 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 훈련\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\n",
    "optimizer = SGD(lr=.01) # 학습률이 .01인 SGD로 매개변수 갱신\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size) \n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "    \n",
    "if i % iter_per_epoch == 0:\n",
    "    train_acc = network.accuracy(x_train, t_train)\n",
    "    test_acc = network.accuracy(x_test, t_test)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    \n",
    "    epoch_cnt += 1\n",
    "    if epoch_cnt >= max_epochs:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../deep_learning_images/over.png\" width=\"50%\" height=\"20%\" />\n",
    "\n",
    "이런 오버피팅을 방지하기 위해 가중치 감소와 드롭아웃이라는 방법이 있다.\n",
    "\n",
    "### 드롭아웃\n",
    "\n",
    "뉴런을 임의로 삭제하면서 학습하는 방법이다.\n",
    "\n",
    "<img src=\"../deep_learning_images/dropout.png\" width=\"50%\" height=\"20%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio=.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.rando.rand(*x.shape) > self.dropout_ratio\n",
    "            return x *self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왼쪽이 드롭아웃을 적용 안해준 결과고 오른쪽은 적용해준 결과이다. 오버피팅이 해결된 걸 볼 수 있다.\n",
    "\n",
    "<img src=\"../deep_learning_images/dropout2.png\" width=\"70%\" height=\"20%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검증 데이터\n",
    "\n",
    "하이퍼파라미터의 성능을 평가할 떄는 시험 데이터를 절대로 사용하면 안된다.\n",
    "\n",
    "그래서 하이퍼파라미터를 조정할 때는 하이퍼파라미터 전용 확인 데이터가 필요하다.\n",
    "\n",
    "일반적으로 전용 확인 데이터를 검증 데이터라 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffle_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-27226fc569ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 훈련 데이터를 뒤섞는다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 20%를 검증 데이터로 분할\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffle_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist()\n",
    "\n",
    "# 훈련 데이터를 뒤섞는다.\n",
    "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
    "\n",
    "# 20%를 검증 데이터로 분할\n",
    "validation_rate = .2\n",
    "validation_num = int(x_train.shape[0] * validation_rate)\n",
    "\n",
    "x_val = x_train[:validation_num]\n",
    "t_val = t_train[:validation_num]\n",
    "x_train = x_train[validation_num:]\n",
    "t_train = t_train[validation_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화\n",
    "\n",
    "0. 하이퍼파라미터 값의 범위를 설정합니다.\n",
    "\n",
    "\n",
    "1. 설정된 범위에서 하이퍼파라미터 값을 무작위로 추출합니다.\n",
    "\n",
    "\n",
    "2. 1단계에서 샘플링한 하이퍼파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가합니다.(단, 에폭은 작게 설정)\n",
    "\n",
    "\n",
    "3. 1단계와 2단계를 특정횟수(100회 등) 반복하여, 그 정확도의 결과를 보고 하이퍼파라미터 범위를 좁힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  하이퍼파라미터 최적화 구현하기 \n",
    "\n",
    "폴더 ch06에서 hyperparameter_optimization.py 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번 장에서 배운 내용\n",
    "    \n",
    "    * 매개변수 갱신 방법에는 확률적 경사 강하법(SGD) 외에도 모멘텀, AdaGrad, Adam 등이 있다.\n",
    "    * 가중치 초깃값을 정하는 방법은 올바른 학습을 하는 데 매우 중요하다.\n",
    "    * 가중치의 초깃값으로는 'Xavier 초깃값'과 'He 초깃값'이 효과적이다.\n",
    "    * 배치 정규화를 이용하면 학습을 빠르게 진행할 수 있으며, 초깃값에 영향을 덜 받게 된다.\n",
    "    * 오버피팅을 억제하는 정규화 기술로는 가중치 감소와 드롭아웃이 있다.\n",
    "    * 하이퍼파라미터 값 탐색은 최적 값이 존재할 법한 범위를 점차 좁히면서 하는 것이 효과적이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
