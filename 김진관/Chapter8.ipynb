{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 더 깊은 신경망으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![deeper_cnn](./fig%208-1.png)\n",
    "\n",
    "손글씨 숫자를 인식하는 심층 CNN(VGG 참고)\n",
    "- 3X3 필터\n",
    "- 층이 깊어질수록 채널 수 증가(16, 16, 32, 32, 64, 64)\n",
    "- 풀링 계층으로 중간 데이터의 공간 크기가 점차 감소\n",
    "- 활성화 함수는 ReLU\n",
    "- 완전연결 계층 뒤에 드롭아웃\n",
    "- Adam optimizer\n",
    "- He 초깃값\n",
    "\n",
    "학습 결과\n",
    "- 정확도 매우 높음\n",
    "- 인식하지 못한 이미지는 대부분 인간도 판단하기 어려운 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 정확도를 더 높이려면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<What is the class of this image?>](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html): 다양한 데이터셋을 대상으로 다양한 기법들의 정확도 순위 정리\n",
    "\n",
    "MNIST 데이터셋\n",
    "- 상위는 대부분 CNN 기반\n",
    "- 그다지 깊지 않은 네트워크\n",
    "- MNIST 문제는 비교적 단순하기 때문\n",
    "\n",
    "정확도를 높일 수 있는 기술의 예\n",
    "- 앙상블\n",
    "- 학습률 감소\n",
    "- 데이터 확장 등등\n",
    "\n",
    "데이터 확장(data augmentation)\n",
    "- 손쉽고 확실한 방법\n",
    "- 훈련 이미지를 인위적으로 확장하는 방법\n",
    "    - 회전\n",
    "    - 이동\n",
    "    - crop: 이미지 일부를 잘라내는 방법\n",
    "    - flip: 좌우 반전(대칭성을 고려하지 않아도 되는 경우에만 사용)\n",
    "    - 외형 변화: 밝기 조절 등\n",
    "    - 스케일 변화: 확대, 축소\n",
    "- 데이터가 부족할 때 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3 깊게 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 매개변수의 수 감소\n",
    "\n",
    "5X5 합성곱 연산 vs 3X3 합성곱 2회 반복\n",
    "\n",
    "<img src=\"./fig 8-5.png\" width=65%>\n",
    "<img src=\"./fig 8-6.png\">\n",
    "\n",
    "- 5X5 합성곱 연산은 3X3 합성곱 연산 2회로 대체 가능\n",
    "- 매개 변수의 수\n",
    "    - 5X5 합성곱: 25개(5X5)\n",
    "    - 3X3 합성곱 2회: 18개(2X3X3)\n",
    "- 매개 변수 차이는 층이 깊어질수록 더욱 커진다.\n",
    "\n",
    "더욱 자세한 설명\n",
    "- 수용 영역(receptive field): 뉴런에 변화를 일으키는 국소적인 공간 영역\n",
    "- 작은 필터를 겹쳐 매개 변수 수를 줄여 넓은 수용 영역 소화 가능\n",
    "- 층을 거듭할 수록 비선형인 활성화 함수를 통해 표현력 증가\n",
    "\n",
    "#### 2. 학습의 효율성\n",
    "\n",
    "- 층을 거듭할 수록 학습 데이터의 양이 줄어 고속으로 학습 가능\n",
    "- 층을 거듭할 수록 점차 복잡한 것에 반응하는 것을 통해 알 수 있다.\n",
    "- 층을 깊게 하면 학습해야 할 문제를 계층적을 분해할 수 있다. 즉, 각 층에서는 더욱 단순화된 문제를 풀게 된다.\n",
    "\n",
    "#### 3. 정보를 계층적으로 전달할 수 있다.\n",
    "\n",
    "초반에는 단순한 정보를 학습하고, 그 정보를 다음 층으로 넘겨 점차 고차원적인 패턴을 학습할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 딥러닝의 초기 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC 2012년 AlexNet을 통해 딥러닝 주목"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 이미지넷(ImageNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 설명\n",
    "- 100만 장이 넘는 이미지\n",
    "- 각 이미지에 레이블이 붙어 있다.\n",
    "- ILSVRC에서 사용되는 데이터\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/38211dc39e41273c0007889202c69f841e02248a/2-Figure1-1.png\">\n",
    "\n",
    "#### ILSVRC 분류(classification) 부문\n",
    "- 1000개의 클래스 분류\n",
    "- 채점 방식은 톱-5 오류(top-5 error): 예측 후보 클래스 5개 안에 정답이 포함되지 않을 비율\n",
    "- 최우수 팀 성적 추이\n",
    "![ILSVRC_winner](./fig%208-8.png)\n",
    "- 2012년 이후 딥러닝이 선두\n",
    "- AlexNet이 오류 크게 개선\n",
    "- ResNet\n",
    "    - 150층이 넘는 신경망 사용\n",
    "    - 일반적인 인간의 인식 능력 넘어섰다고 인정(오류율 3.5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱 계층과 풀링 계층으로 구성된 기본적인 CNN  \n",
    "- VGG16(16층), VGG19(19층)으로 깊은 신경망으로 심화\n",
    "- 3X3 필터 2~4회 연속 이후 풀링 계층으로 크기를 절반으로 줄이는 과정 반복\n",
    "- 마지막 층은 완전연결 계층\n",
    "- 구성이 간단해서 응용하기 좋음\n",
    "\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1750/0*rbWRzjKvoGt9W3Mf.png\">\n",
    "\n",
    "- 인셉션 구조 사용\n",
    "    - 크기가 다른 필터와 풀링 여러 개 적용해서 결합\n",
    "<img src=\"http://i.imgur.com/MqoQtOS.png\" width=500>\n",
    "- 1X1 합성곱 연산: 채널 쪽의 크기를 줄이는 역할, 매개변수 제거와 고속 처리에 기여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.4 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 층을 너무 깊게 했을 때 성능이 오히려 떨어지는 문제 해결\n",
    "- 스킵 연결(skip connection)\n",
    "<img src=\"https://i.stack.imgur.com/gSxcB.png\">\n",
    "- 입력 x를 연속한 두 합성곱 계층 건너뛰어 출력에 바로 연결\n",
    "- 역전파 때 신호 감쇠를 막아준다\n",
    "- 스킵 연결은 입력 데이터를 그대로 흐르게 해서 역전파 때 상류의 기울기를 그대로 하류로 보낸다.\n",
    "- 기울기 소실 문제를 줄여준다.\n",
    "- ResNet 전체 구조: VGG + skip connection\n",
    "<img src=\"https://mblogthumb-phinf.pstatic.net/20160822_167/laonple_1471852138956ogYDD_PNG/resnet_p7_11.png?type=w2\">\n",
    "\n",
    "#### 전이 학습(transfer learning)\n",
    "- 이미 학습된 가중치를 다른 신경망에 복사한 다음 그 상태로 새로운 데이터셋을 대상으로 재학습(fine tuning)을 수행해서 사용하는 것\n",
    "- 데이터셋이 적을 때 유용\n",
    "- ex) 이미지넷 데이터셋으로 학습한 가중치 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 더 빠르게(딥러닝 고속화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 풀어야 할 숙제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet forward 처리 각 층 시간 비율: GPU(좌), CPU(우)\n",
    "<img src=\"./fig 8-14.png\">\n",
    "\n",
    "- 합성곱 계층에서 대부분 소요\n",
    "- 단일 곱셈-누산 고속화 처리 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 GPU를 활용한 고속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU 컴퓨팅의 목적\n",
    "- 병렬 수치 연산 고속 처리\n",
    "- CPU는 연속적인 복잡한 계속 처리 용이\n",
    "\n",
    "#### 딥러닝 CPU와 GPU 학습 비교\n",
    "- GPU를 사용했을 때가 훨씬 빠르다\n",
    "- 딥러닝 최적화 라이브러리 사용하면 더욱 빨라진다.\n",
    "- 엔비디아의 CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 분산 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다수의 GPU와 기기로 계산 분산\n",
    "- CNTK(computational network toolkit): 분산 학습 지원 라이브러리\n",
    "- 거대한 데이터센터의 저지연, 고처리량 네트워크에서 학습 시 성능 크게 향상\n",
    "\n",
    "어려움\n",
    "- 컴퓨터 사이의 통신과 데이터 동기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4 연산 정밀도와 비트 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 메모리 용량과 버스 대역폭 등이 병목이 될 수 있다.\n",
    "    - 메모리 문제: 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 함\n",
    "    - 버스 대역폭 문제: 버스를 흐르는 데이터가 많아져 한계를 넘어서면 병목. 데이터의 비트 수 최소화 하는 것이 바람직\n",
    "- 비트 수는 계산 정확도 vs 계산 비용, 메모리 사용량, 버스 대역폭 사이의 trade-off\n",
    "- 신경망의 견고성: 입력 데이터가 조금 달라져도 출력 데이터는 잘 달라지지 않는 강건함을 보이는 성질\n",
    "- 16비트 반정밀도만 사용해도 문제가 없다.(높은 수치 정밀도 요구 x)\n",
    "    - 파스칼 아키텍쳐에서 지원\n",
    "    - 파이썬: 64비트, 넘파이: 16비트도 지원\n",
    "    - Binarized Neural Networks: 가중치와 중간 데이터를 1비트로 표현하는 방법 연구 \n",
    "\n",
    "컴퓨터의 실수 표현 방식\n",
    "- 32비트 단정밀도\n",
    "- 64비트 배정밀도\n",
    "- 16비트 반정밀도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 딥러닝의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1 사물 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAxODA3MDFfMzAw/MDAxNTMwNDU2OTEyNzEz.N3nj4DtudgW9SQoQGXv7hTvUQqY8CQgKAejziILXpe8g.HXnr16aCPHZbMr8YXBSLYfIy8Wmvp14bGxlVt0ShyHcg.JPEG.linuxand/%EC%82%AC%EB%AC%BC%EA%B2%80%EC%B6%9C.jpg?type=w800\">\n",
    "\n",
    "- 이미지 속에 담긴 사물의 위치와 종류를 알아내는 기술\n",
    "- 하나의 이미지에 여러 사물 존재할 수 있다.\n",
    "- R-CNN(regions with convolutional neural networks)\n",
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2017/06/0sdj6skdrqyzpo6oh.png?w=625\">\n",
    "- 후보 영역 추출과 CNN 특징 계산이 가장 큰 특징\n",
    "    - 후보 영역 추출: Selective Search 기법 사용\n",
    "    - 후보 영역 추출까지 CNN으로 처리하는 Faster R-CNN 등장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.2 분할(segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 픽셀 수준으로 분류\n",
    "- 픽셀 단위로 객체마다 채색된 지도 데이터를 사용해 학습\n",
    "- 추론: 입력 이미지의 모든 픽셀 분류\n",
    "<img src=\"http://vladlen.info/wp-content/uploads/FSO-1.jpg\">\n",
    "- 모든 픽셀 대상으로 추론하면 픽셀 수만큼 forward 처리해야 되서 비효율적\n",
    "\n",
    "#### FCN(fully convolutional network)\n",
    "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAxNzAzMTRfNzkg/MDAxNDg5NDkwNjAxMjY3.UEJzb5nzWcN94UErndLiJp7pf6ljxA6Neh5-AcOMk40g.inO_1esH3LRHew6JNPDd8-NQp-5qu7VNMxpxmHFfQ1wg.PNG.laonple/%EC%9D%B4%EB%AF%B8%EC%A7%80_16.png?type=w2\">\n",
    "\n",
    "- 한번의 forward 처리로 모든 픽셀의 클래스를 분류해주는 기법\n",
    "- 완전연결 계층을 같은 기능을 하는 합성곱 계층으로 바꾼다.\n",
    "- 공간 볼륨을 유지한 채 마지막 출력 처리 가능\n",
    "- FCN의 마지막 층: 공간의 크기 확대\n",
    "    - 이중 선형 보간(bilinear interpolation)에 의한 선형 확대\n",
    "    - 역합성곱(deconvolution) 연산으로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.3 사진 캡션 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.techfrontier.kr/wp-content/uploads/2014/11/Screen-Shot-2014-11-17-at-2.11.11-PM-550x355.png\">\n",
    "\n",
    "- 사진을 주면 그 사진을 설명하는 글을 자동으로 생성\n",
    "- NIC(neural image caption) 모델\n",
    "    - 심층 CNN + 순환 신경망(recurrent neural network, RNN)\n",
    "    - CNN으로 사진 특징 추출\n",
    "    - 특징을 RNN에 넘겨 특징을 추깃값으로 텍스트를 순환적으로 생성\n",
    "- 멀티모달 처리(multimodal processing): 여러 종류의 정보르 조합, 처리\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99DA9B405B596D2F0B\">\n",
    "\n",
    "RNN 간단 설명\n",
    "- 순환적 네트워크 구조\n",
    "- 과거의 정보를 기억하는 특징\n",
    "- 연속성 있는 데이터 다룰 때 주로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 딥러닝의 미래"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1 이미지 스타일(화풍) 변환\n",
    "\n",
    "<img src=\"https://bloglunit.files.wordpress.com/2017/04/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2017-05-16-e1848be185a9e18492e185ae-1-56-54.png?w=520&h=392\">\n",
    "\n",
    "- 두 이미지를 입력해서 새로운 그림 생성\n",
    "    - 콘텐츠 이미지\n",
    "    - 스타일 이미지\n",
    "- A Neural Algorithm of Artistic Style 논문\n",
    "\n",
    "학습 방식\n",
    "- 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습\n",
    "- 스타일 행렬의 오차를 줄이도록 학습해서 스타일 이미지의 화풍을 흡수하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.2 이미지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대량의 이미지를 학습한 후 입력 이미지 없이 새로운 이미지 생성\n",
    "- DCGAN(deep convolutional generative adversarial network)\n",
    "- 생성자(generator): 진짜와 똑같은 이미지를 생성\n",
    "- 식별자(discriminator): 생성자가 생성한 이미지를 판별\n",
    "- 생성자와 식별자를 겨루도록 학습해서 정교한 가짜 이미지를 생성해내도록 한다.\n",
    "\n",
    "지도학습(supervised learning)과 자율학습(unsupervised learning)\n",
    "- 지도학습: 입력 데이터와 정답 레이블을 짝지은 데이터셋을 이용해서 학습\n",
    "- 자율학습: 지도용 데이터 없이 스스로 학습\n",
    "    - Deep Belief Network, Deep Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.3 자율 주행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 안전한 주행 영역을 인식하는 것이 중요\n",
    "- SegNet: 주변 환경 인식하는 CNN 기반 신경망\n",
    "    - 픽셀 수준에서 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.4 Deep Q-Network(강화 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화학습\n",
    "- 에이전트: 주어진 환경에서 행동을 선택하는 주체\n",
    "- 환경: 에이전트의 행동에 영향을 주는 조건\n",
    "- 보상: 에이전트가 환경을 변화시키는 행동을 했을 때 에이전트에게 보상이 주어지고, 더 나은 보상을 받는 쪽으로 에이전트를 학습시킨다.\n",
    "\n",
    "Deep Q-Network(DQN)\n",
    "- 딥러닝을 사용한 강화학습\n",
    "- Q학습에 기초\n",
    "    - 최적 행동 가치 함수로 최적 행동 정한다.\n",
    "- 최적 가치 함수를 CNN으로 비슷하게 흉내내어 사용\n",
    "- 입력 데이터로 게임 영상만 주면 된다.\n",
    "    - 기존의 학습에선 게임의 상태를 미리 출력해야 했다.\n",
    "- 구성을 변경하지 않고 적용 가능\n",
    "- 게임 영상 프레임을 입력해서 게임을 제어하는 움직임에 대햐여 각 동작의 가치를 출력\n",
    "- 알파고, 팩맨, 아타리 등 많은 게임에서 사람보다 뛰어난 성적\n",
    "<img src=\"https://curt-park.github.io/images/dqn/architecture.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
