{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 합성곱 신경망(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 전체 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN에서 등장하는 새로운 layer\n",
    "- 합성곱 계층(convolutional layer)\n",
    "- 풀링 계층(pooling layer)\n",
    "\n",
    "현재까지 봤던 신경망을 완전연결(fully-connected)라고 하며 Affine 계층으로 구현했다. Affine 계층 뒤에는 활성화 함수로 ReLU 혹은 Sigmoid를 사용했다.\n",
    "\n",
    "CNN의 구조는 새로운 합성곱 계층(Conv)과 풀링 계층(pooling)이 추가된다. Conv-ReLU-(Pooling)의 흐름이다. 출력층과 가까운 층의 경우에는 Affine-ReLU, 출력층은 Affine-Softmax 조합을 그대로 사용한다.\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/2409463658F46CAD1F\">\n",
    "<center><small>▲ 완전연결 계층(위), CNN(아래)</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 합성곱 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 패딩(padding)\n",
    "- 스트라이드(stride)\n",
    "- 입체적인 데이터 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 완전연결 계층의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 형상이 무시된다.\n",
    "- 완전연결 계층의 입력은 평탄화 필요\n",
    "- 본래 다차원인 데이터의 경우 다차원에서 특별한 정보가 담겨있을 가능성이 있다.\n",
    "- 이미지의 경우\n",
    "    - 가로, 세로, 색상의 3차원 데이터\n",
    "    - 공간적 정보\n",
    "    \n",
    "반면, 합성곱 계층은 형상을 유지한다.\n",
    "- 입력 데이터가 형상 그대로 들어온다.\n",
    "- 다음 계층으로 전달될 때도 그대로 전달\n",
    "- 다차원의 형상을 가진 데이터를 올바르게 이해할 수 있다.\n",
    "- 특징 맵(feature map): 합성곱 계층의 입출력 데이터\n",
    "    - 입력 특징 맵(input feature map)\n",
    "    - 출력 특징 맵(output feature map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 연산 = 필터 연산\n",
    "\n",
    "\n",
    "합성곱 연산 예제\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/2764173558F475B42C\">\n",
    "\n",
    "데이터 설명\n",
    "- 입력 데이터: (4,4)의 높이와 너비를 가진 형상\n",
    "- 필터: (3,3)의 높이와 너비를 가진 형상\n",
    "    - 커널이라고도 한다.\n",
    "- 출력: (2,2)의 놆이와 너비를 가진 형상\n",
    "\n",
    "연산 과정\n",
    "1. 필터의 **윈도우(window)**를 일정 간격으로 이동하면서 입력 데이터에 적용\n",
    "2. 단일 곱셈-누산(fused multiply-add, FMA): 대응하는 원소기리 곱한 후 모두 더함\n",
    "3. 결과를 출력의 해당 장소에 저장\n",
    "4. 모든 장소에서 수행\n",
    "\n",
    "가중치와 편향\n",
    "- 가중치: 필터의 매개변수\n",
    "- 편향: 필터를 적용한 후 데이터에 더해진다. 항상 하나(1X1)만 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패딩(padding)\n",
    "- 입력 데이터 주변을 특정 값으로 채우는 것\n",
    "- 예를 들어 0으로\n",
    "\n",
    "패딩의 예\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/2527FA3758F4785B13\">\n",
    "\n",
    "- 입력데이터: 4X4\n",
    "- 패딩 후: 6X6\n",
    "- 3X3 필터 적용 후: 4X4\n",
    "\n",
    "패딩을 하는 이유\n",
    "- 출력 크기를 조정하는 목적\n",
    "- 합성곱 신경망에서 그냥 필터를 적용하면 계속해서 크기가 줄어든다. 신경망이 깊어지면 어느 순간 크기가 1이 되어버린다. 이는 더이상 합성곱을 할 수 없는 상태이기 때문에 문제가 된다.\n",
    "- 풀링을 하면 출력 크기를 유지시켜 줄 수 있어서, 입력 데이터의 공간적 크기를 고정해서 다음 층으로 넘겨줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 스트라이드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스트라이드\n",
    "- 필터를 적용하는 위치 간격\n",
    "- 스트라이드를 키우면 출력 크기가 작아진다.\n",
    "\n",
    "<img src=\"https://2.bp.blogspot.com/-vtZW1-cBQGg/WYJrUnBjRiI/AAAAAAAALNY/GhTnu5QDi3M4NHB_FiyOJAjy58mTkzlYwCK4BGAYYCw/s320/o9.PNG\">\n",
    "<center><small>▲ 스트라이드가 2인 합성곱 신경망</small></center>\n",
    "\n",
    "패딩, 스트라이드, 출력 크기 계산\n",
    "- 입력 크기: $(H, W)$\n",
    "- 필터 크기: $(FH, FW)$\n",
    "- 출력 크기: $(OH, OW)$\n",
    "- 패딩: $P$\n",
    "- 스트라이드: $S$\n",
    "\n",
    "$$OH = \\frac {H + 2P - FH} S + 1$$\n",
    "\n",
    "$$OW = \\frac {W + 2P - FW} S + 1$$\n",
    "\n",
    "주의\n",
    "- 계산 결과가 정수로 나누어 떨어져야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 3차원 데이터의 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 데이터의 합성곱 연산 예\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99C185405BC97F4D1E\">\n",
    "\n",
    "- 입력 데이터의 채널 수 = 필터의 채널 수\n",
    "- 필터의 크기는 원하는 크기로(모든 채널의 필터 크기는 같아야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 블록으로 생각하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/998CE7355BC97F632E\">\n",
    "\n",
    "- 데이터와 필터의 형상: (채널, 높이, 너비)\n",
    "- 출력: 채널이 1개인 특징 맵\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99CDF2395BC97F7C2D\">\n",
    "\n",
    "- 필터를 여러 개 사용하면 출력의 채널 수도 늘어남\n",
    "- 이 출력을 다음 층으로 넘겨준다.\n",
    "- 필터의 가중치 데이터는 4차원: (출력 채널 수, 입력 채널 수, 높이, 너비)\n",
    "- 편향: 채널당 하나의 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7 배치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99E4C84E5C4D31B728\">\n",
    "\n",
    "- 4차원으로 데이터 저장: (데이터 수, 채널 수, 높이, 너비)\n",
    "- 가장 앞쪽에 배치용 차원을 추가\n",
    "- 각 흐름마다 N번의 합성곱 연산을 수행\n",
    "- 배치 처리의 효과는 완전연결 신경망과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 풀링 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링 계층\n",
    "- 가로, 세로 방향의 공간을 줄이는 연산\n",
    "\n",
    "풀링의 예\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/993A5B465C4D32D32C\">\n",
    "\n",
    "- 최대 풀링(max pooling)\n",
    "    - 대상 영역 내에서 최대값을 구하는 연산\n",
    "- 평균 풀링(average pooling)\n",
    "    - 대상 영역의 평균을 계산\n",
    "- 이미지 인식 분야에서는 최대 풀링을 사용\n",
    "- 윈도우 크기와 스트라이드는 동일한 값으로 하는 것이 일반적\n",
    "    - 위의 예: 윈도우 2X2, 스트라이드 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 풀링 계층의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습해야 할 매개변수가 없다.\n",
    "\n",
    "채널 수가 변하지 않는다.\n",
    "- 채널마다 독립적으로 계산하기 때문\n",
    "\n",
    "입력의 변화에 영향을 적게 받는다(강건하다).\n",
    "- 입력 데이터가 조금 변해도 풀링 결과는 잘 변하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 합성곱/풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 4차원 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN에서 흐르는 데이터는 4차원이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터에 접근\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 데이터에 접근\n",
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.44322204e-01, 1.61725959e-01, 4.97299575e-01, 4.90849763e-01,\n",
       "        2.69806956e-01, 4.80739959e-01, 5.33766630e-01, 3.52483845e-01,\n",
       "        5.90821168e-01, 5.07826272e-01, 6.40826973e-01, 4.59954326e-01,\n",
       "        5.82373841e-01, 6.52799925e-02, 3.35695899e-01, 4.61650460e-01,\n",
       "        8.95937799e-01, 6.28431996e-02, 6.36711673e-01, 5.50039978e-01,\n",
       "        8.44648519e-01, 4.38516371e-01, 5.49044826e-01, 8.53925508e-01,\n",
       "        1.25532691e-01, 9.38128354e-01, 3.10436399e-01, 6.31229430e-02],\n",
       "       [5.89551509e-01, 8.42634111e-01, 2.77916824e-01, 5.08458502e-01,\n",
       "        7.81895554e-01, 6.73924304e-01, 4.29696956e-01, 5.30719806e-01,\n",
       "        6.09772891e-01, 3.90477187e-01, 8.94129112e-01, 6.94847332e-01,\n",
       "        1.84154758e-01, 4.93814150e-01, 3.00257947e-01, 7.88172803e-01,\n",
       "        6.69589655e-01, 2.98000065e-01, 3.52254697e-01, 7.12158128e-01,\n",
       "        7.26263155e-01, 2.44904846e-02, 8.39847862e-01, 8.55460753e-01,\n",
       "        6.19307563e-01, 3.10795281e-02, 4.46509670e-01, 7.73360195e-01],\n",
       "       [6.95797316e-03, 8.71904210e-01, 8.26879870e-01, 8.25834490e-01,\n",
       "        5.03450685e-01, 4.70763754e-01, 1.41256549e-01, 4.26441358e-01,\n",
       "        5.40604305e-01, 9.73025969e-01, 4.58829601e-01, 4.12817390e-01,\n",
       "        7.46487246e-01, 5.98487101e-01, 8.36644233e-03, 9.00706184e-01,\n",
       "        1.15325528e-01, 9.73692788e-01, 6.91551907e-01, 6.90474328e-01,\n",
       "        5.66117910e-02, 4.35728490e-01, 1.40072546e-01, 4.63566762e-01,\n",
       "        8.61794604e-01, 8.49598864e-01, 4.82154128e-01, 2.04750250e-01],\n",
       "       [9.54277362e-01, 9.17095740e-01, 3.60644674e-01, 2.83619429e-01,\n",
       "        3.60714677e-02, 7.36337932e-01, 8.01804676e-01, 8.91061539e-01,\n",
       "        5.99113991e-02, 9.19933648e-01, 2.06868476e-01, 8.46249861e-01,\n",
       "        5.88067849e-01, 9.60176659e-01, 4.03544159e-01, 7.50288727e-01,\n",
       "        7.82991771e-01, 2.50970050e-03, 2.66821606e-01, 7.19443555e-01,\n",
       "        4.32849331e-01, 3.21785710e-01, 2.69511602e-01, 5.92882920e-01,\n",
       "        4.23956485e-01, 8.34781527e-01, 4.92431310e-01, 9.65676126e-01],\n",
       "       [2.37586846e-01, 8.30691965e-01, 4.65680354e-01, 4.75110936e-01,\n",
       "        1.64320780e-01, 4.20147729e-01, 8.07335347e-01, 7.20201954e-01,\n",
       "        8.66400169e-01, 8.02156755e-01, 2.09098777e-01, 1.25821017e-02,\n",
       "        6.79460437e-02, 7.52839657e-01, 5.70712989e-01, 8.79533362e-02,\n",
       "        8.27782389e-01, 9.81931191e-01, 3.48324382e-01, 3.72640955e-01,\n",
       "        2.60615286e-01, 1.37443841e-01, 3.37857715e-02, 7.67442485e-01,\n",
       "        2.26610070e-01, 5.30818299e-01, 1.19416480e-01, 4.43167617e-01],\n",
       "       [7.27076721e-01, 5.24660666e-01, 8.34325307e-01, 3.23525255e-01,\n",
       "        8.09954316e-01, 8.95685298e-01, 6.88385294e-01, 7.92886787e-01,\n",
       "        1.85356326e-01, 4.33435458e-01, 4.50557835e-01, 1.29103777e-01,\n",
       "        6.15763078e-01, 5.57861503e-01, 2.43151587e-01, 3.79967973e-01,\n",
       "        7.22209051e-01, 2.60297390e-01, 1.45701352e-01, 9.77616827e-01,\n",
       "        7.30723314e-01, 2.63024286e-01, 7.77942823e-01, 4.27157691e-01,\n",
       "        2.60404120e-01, 5.31547257e-01, 7.30562090e-01, 7.47855503e-01],\n",
       "       [9.11270393e-01, 4.65204595e-01, 2.44398018e-02, 8.24489951e-01,\n",
       "        5.91946646e-01, 5.03378579e-01, 4.64901646e-01, 1.19234543e-01,\n",
       "        5.40456073e-01, 6.78487438e-01, 7.92823539e-01, 7.12974826e-01,\n",
       "        6.37751567e-01, 4.46638755e-01, 4.08379329e-01, 6.18685751e-01,\n",
       "        2.89768247e-01, 6.20360201e-01, 1.37078001e-01, 7.71715969e-01,\n",
       "        1.91255852e-01, 2.29250067e-01, 1.48905724e-01, 6.59868902e-01,\n",
       "        5.50295289e-01, 4.17253785e-01, 9.78514904e-01, 2.42452628e-01],\n",
       "       [3.69407095e-01, 6.81245619e-01, 2.41021868e-02, 7.24787816e-01,\n",
       "        1.03283749e-01, 6.00084579e-01, 4.03745932e-02, 7.64877793e-02,\n",
       "        9.53509515e-01, 2.96316846e-02, 7.97551929e-01, 2.59515608e-02,\n",
       "        2.50164020e-01, 5.99526538e-01, 4.36074086e-01, 8.63679752e-01,\n",
       "        9.04783700e-01, 7.80262700e-01, 3.40798867e-01, 1.40770957e-01,\n",
       "        1.15880812e-01, 2.91628830e-01, 8.76857822e-01, 7.02087140e-01,\n",
       "        1.26669974e-01, 6.92635999e-02, 4.65772435e-02, 8.21255157e-01],\n",
       "       [9.82265904e-01, 5.98472504e-01, 9.42418947e-01, 8.21170567e-02,\n",
       "        3.97740112e-01, 1.50570416e-01, 3.25314510e-01, 3.06803352e-01,\n",
       "        7.47637808e-01, 7.26807469e-01, 8.49161565e-01, 1.82868479e-01,\n",
       "        8.50285651e-01, 4.35983644e-01, 4.59471987e-01, 7.18489459e-02,\n",
       "        9.81194928e-01, 1.10838595e-01, 8.26363420e-01, 2.27339441e-01,\n",
       "        5.01670242e-01, 9.63345113e-01, 9.91464391e-01, 1.14211745e-01,\n",
       "        3.51433289e-01, 2.30519204e-01, 3.35550050e-01, 2.66083227e-01],\n",
       "       [9.48811553e-01, 4.62467107e-01, 8.35206330e-01, 4.17720850e-01,\n",
       "        4.16821302e-01, 7.85922047e-01, 7.48324353e-01, 6.59322809e-01,\n",
       "        3.34031502e-01, 8.77749364e-01, 2.12292482e-01, 8.79940828e-02,\n",
       "        2.02695792e-02, 1.85303533e-01, 7.93685525e-01, 4.70934343e-01,\n",
       "        6.54130527e-01, 5.50779198e-01, 6.33818338e-01, 1.37733829e-01,\n",
       "        4.83707977e-01, 6.39252084e-01, 7.43120770e-01, 2.57055630e-02,\n",
       "        7.64043730e-01, 4.98023592e-01, 5.48067894e-01, 5.73935466e-02],\n",
       "       [4.72858176e-01, 8.16462002e-02, 7.69245798e-01, 3.89634858e-02,\n",
       "        7.43173643e-02, 2.33797369e-02, 7.64783523e-01, 2.59452220e-01,\n",
       "        5.43234174e-02, 7.53985391e-01, 2.18770545e-01, 2.63472856e-02,\n",
       "        4.53290945e-01, 9.89255096e-01, 4.65940490e-02, 2.91118896e-01,\n",
       "        6.08112829e-01, 6.21471192e-01, 8.29422949e-01, 5.13951186e-01,\n",
       "        7.11699818e-01, 4.96965262e-02, 2.68280847e-01, 4.66599324e-01,\n",
       "        5.22148972e-01, 8.99347238e-01, 7.88145364e-01, 6.56260463e-01],\n",
       "       [4.05092062e-01, 8.68064889e-01, 4.52183033e-01, 6.07691992e-01,\n",
       "        8.32838449e-02, 4.99072725e-01, 3.73122282e-01, 9.39421570e-01,\n",
       "        7.89753267e-01, 3.72688145e-02, 1.40699303e-02, 5.16406513e-01,\n",
       "        7.05385475e-01, 4.52610378e-01, 6.60925566e-01, 9.29365548e-01,\n",
       "        3.05314984e-01, 8.63337863e-01, 8.40635704e-01, 7.58396254e-01,\n",
       "        6.93563345e-01, 3.14148005e-01, 2.60845897e-01, 7.75130597e-01,\n",
       "        3.74229501e-01, 8.85721580e-01, 7.09216160e-01, 3.29600650e-01],\n",
       "       [3.18555138e-02, 4.76143745e-01, 5.19555802e-01, 8.57852092e-02,\n",
       "        4.08204297e-01, 6.63528267e-03, 1.87757576e-01, 7.06521388e-01,\n",
       "        6.91129211e-01, 6.03931228e-01, 9.77032310e-01, 3.89120031e-01,\n",
       "        4.05480433e-01, 3.02010717e-02, 9.84014240e-01, 4.09390446e-02,\n",
       "        5.11372204e-01, 4.91196302e-01, 3.30486685e-01, 1.13695817e-01,\n",
       "        3.44809869e-01, 4.89415670e-01, 5.40492023e-01, 1.02908769e-01,\n",
       "        7.10592737e-02, 6.75267170e-01, 6.40052147e-01, 7.99335225e-01],\n",
       "       [5.16833322e-01, 8.08107560e-01, 8.73835453e-01, 7.29477815e-01,\n",
       "        6.65287484e-01, 7.53776050e-01, 8.72636173e-01, 6.93410037e-01,\n",
       "        2.97355467e-01, 2.29703654e-01, 6.97310416e-01, 2.08130964e-01,\n",
       "        1.19694056e-01, 5.03314860e-01, 1.58096745e-01, 7.81303373e-01,\n",
       "        1.74630083e-01, 1.87060044e-01, 7.72314270e-01, 1.55206407e-01,\n",
       "        3.23746054e-01, 5.55815042e-01, 1.72577438e-01, 6.80314300e-01,\n",
       "        2.77997495e-04, 9.22679410e-01, 3.83925657e-01, 5.04835045e-01],\n",
       "       [7.01661234e-01, 3.82933734e-02, 2.59376363e-02, 9.01346218e-03,\n",
       "        5.66616196e-01, 3.46446269e-01, 7.47197509e-01, 7.00662398e-01,\n",
       "        1.44650667e-01, 2.35609885e-02, 4.48398617e-02, 2.61083116e-01,\n",
       "        3.10078433e-01, 9.40103055e-01, 4.01208811e-01, 2.44246075e-02,\n",
       "        9.68666377e-01, 2.31241428e-01, 7.34001839e-02, 9.85609476e-01,\n",
       "        2.89628223e-01, 5.21802877e-03, 9.92704257e-01, 2.29273325e-01,\n",
       "        6.48796608e-01, 9.15041401e-01, 9.99898802e-01, 5.10338975e-01],\n",
       "       [3.02588483e-01, 7.09980422e-01, 1.24986410e-01, 4.41756864e-02,\n",
       "        1.91370463e-01, 4.27011469e-01, 7.16334864e-01, 2.55706436e-01,\n",
       "        2.50246884e-01, 7.52649151e-01, 7.51730661e-01, 3.21016726e-01,\n",
       "        1.72770176e-01, 5.47256418e-02, 4.90172543e-01, 1.85901620e-02,\n",
       "        8.98904635e-01, 8.05347499e-01, 2.12324840e-01, 3.18526013e-01,\n",
       "        8.55290434e-01, 6.35582338e-01, 4.92100909e-01, 6.50953201e-01,\n",
       "        2.92912651e-01, 6.50370264e-01, 6.58403400e-01, 2.50523225e-01],\n",
       "       [7.19595365e-01, 7.18228836e-01, 3.97713312e-01, 5.58233684e-01,\n",
       "        4.40628582e-01, 8.36433683e-01, 2.82605219e-02, 8.76237306e-01,\n",
       "        9.37561281e-01, 4.72425783e-01, 8.65162763e-01, 3.85994055e-01,\n",
       "        9.45746360e-01, 5.01933405e-01, 2.68467613e-01, 6.52233957e-01,\n",
       "        4.47129531e-01, 6.80003235e-01, 7.26194026e-01, 4.29620981e-01,\n",
       "        4.88066420e-01, 8.35379422e-01, 2.15137589e-01, 9.68256914e-01,\n",
       "        1.50971877e-01, 5.85622493e-01, 2.95820166e-01, 9.47461596e-01],\n",
       "       [4.53284159e-01, 1.66102882e-01, 3.23648870e-01, 7.14359598e-01,\n",
       "        7.13542277e-01, 1.94131885e-01, 1.02854197e-01, 9.06383653e-01,\n",
       "        1.30086140e-01, 8.87184067e-01, 5.99457320e-01, 3.49252109e-01,\n",
       "        6.76952862e-01, 6.36226701e-01, 7.10871114e-01, 2.31526523e-01,\n",
       "        8.29645880e-01, 8.95422147e-01, 7.43106629e-01, 7.70331777e-01,\n",
       "        4.92023310e-01, 6.90804275e-01, 8.99447455e-01, 3.34726127e-01,\n",
       "        4.60863529e-02, 6.35106558e-01, 8.49719476e-01, 3.33409642e-01],\n",
       "       [7.84524652e-01, 5.66549770e-01, 9.29173618e-01, 9.66488917e-01,\n",
       "        4.13735909e-01, 1.28810509e-01, 5.80822505e-01, 5.18604339e-01,\n",
       "        9.28478455e-02, 9.44543447e-01, 2.65564569e-01, 7.24320024e-02,\n",
       "        4.43001201e-01, 8.59547203e-01, 5.05686220e-01, 4.68072328e-01,\n",
       "        5.19730425e-01, 7.69089312e-01, 4.15952734e-01, 8.17574680e-01,\n",
       "        7.90194255e-01, 3.54683700e-01, 4.46041685e-02, 3.73609676e-01,\n",
       "        5.90203838e-01, 1.56067831e-01, 2.02008732e-01, 5.60961128e-01],\n",
       "       [3.71717737e-01, 8.57004962e-01, 9.99722265e-01, 5.42378804e-02,\n",
       "        7.43279814e-01, 7.16216760e-01, 4.93901945e-01, 4.94226785e-01,\n",
       "        8.02367143e-01, 2.45979106e-01, 1.99280166e-01, 4.59873552e-02,\n",
       "        9.44237867e-01, 2.61833778e-01, 5.71426193e-01, 2.72927673e-01,\n",
       "        7.43644483e-02, 8.19202802e-01, 8.10022217e-01, 6.66556932e-01,\n",
       "        3.80844482e-01, 6.21938532e-02, 5.18239412e-01, 5.15295781e-01,\n",
       "        9.98846471e-01, 8.37953673e-01, 5.29660568e-01, 8.19826212e-01],\n",
       "       [8.88944705e-02, 9.33986728e-01, 5.86752044e-01, 6.63165808e-01,\n",
       "        1.43969553e-01, 7.28462524e-01, 8.32994638e-01, 2.27409662e-01,\n",
       "        2.40778889e-01, 3.08324872e-01, 6.94931208e-01, 3.75992940e-01,\n",
       "        5.89783622e-01, 7.88645679e-01, 4.95920506e-01, 9.06149742e-01,\n",
       "        4.43178193e-01, 4.32506845e-01, 8.35414074e-01, 8.01521455e-01,\n",
       "        5.56889776e-01, 8.61586210e-01, 9.28155003e-01, 6.95346055e-01,\n",
       "        1.51231174e-01, 1.44476935e-01, 6.45077481e-01, 6.72508646e-02],\n",
       "       [1.59026281e-01, 9.07346128e-01, 9.61723116e-01, 5.49790873e-01,\n",
       "        6.89785994e-01, 6.84654453e-01, 3.72906013e-01, 1.29316959e-02,\n",
       "        9.15349325e-01, 7.79456494e-01, 9.85130419e-01, 8.65690068e-01,\n",
       "        7.18784356e-01, 1.40894739e-01, 2.40278809e-01, 7.17108833e-01,\n",
       "        5.79743802e-01, 7.06696680e-01, 2.29825964e-01, 7.90395735e-01,\n",
       "        9.61767035e-01, 4.58622731e-01, 4.46111833e-01, 4.40946870e-01,\n",
       "        8.83648135e-01, 8.54020754e-01, 6.80913106e-01, 7.43508933e-01],\n",
       "       [7.09880255e-01, 2.32080493e-01, 4.56420612e-01, 6.60358800e-01,\n",
       "        4.56644884e-01, 3.01486151e-01, 1.73227117e-01, 9.54017078e-02,\n",
       "        3.82679418e-01, 2.10524155e-01, 4.09067192e-01, 3.97137511e-01,\n",
       "        3.49689097e-01, 7.83984723e-01, 8.88567000e-01, 3.56685642e-01,\n",
       "        1.40252329e-01, 9.26684145e-01, 2.35448794e-01, 6.00724269e-01,\n",
       "        7.47464850e-01, 8.73320726e-01, 2.58681244e-01, 3.30777332e-01,\n",
       "        1.32235363e-01, 4.99462363e-01, 7.15924618e-01, 2.05071733e-01],\n",
       "       [9.27193201e-01, 9.99764785e-01, 4.26059975e-01, 7.49660027e-01,\n",
       "        4.27314120e-01, 4.87672929e-01, 6.15266106e-02, 9.54985760e-01,\n",
       "        6.49617585e-01, 7.74568305e-01, 8.37162779e-01, 8.78330967e-01,\n",
       "        4.48977692e-01, 3.91146511e-01, 3.45973860e-01, 5.01526749e-01,\n",
       "        1.20895242e-01, 4.68692809e-01, 3.87160274e-01, 2.49005134e-01,\n",
       "        3.50393161e-01, 6.17785113e-01, 2.28932045e-01, 8.42817682e-02,\n",
       "        8.87498065e-02, 4.48810640e-01, 8.61913882e-01, 5.06262305e-01],\n",
       "       [1.58352297e-01, 9.51999651e-01, 3.45029746e-01, 5.46352753e-01,\n",
       "        1.34105922e-01, 9.45875398e-01, 3.29416585e-01, 2.14377579e-01,\n",
       "        9.60057414e-01, 1.92853493e-01, 5.27213532e-01, 7.70550950e-01,\n",
       "        2.84397419e-01, 9.86566380e-01, 4.77296793e-01, 7.53401285e-01,\n",
       "        3.10311419e-01, 2.60764665e-01, 8.69934159e-01, 8.01069013e-02,\n",
       "        3.70399510e-01, 7.17237452e-01, 9.58743199e-01, 4.98375740e-01,\n",
       "        4.62474038e-01, 3.36516115e-01, 3.57344948e-01, 7.82175313e-01],\n",
       "       [7.68523972e-01, 7.92043278e-01, 7.55184307e-01, 4.21296460e-01,\n",
       "        6.84144142e-01, 9.54319825e-01, 3.62999559e-01, 1.96570922e-01,\n",
       "        7.70720291e-01, 4.61685096e-02, 3.26968468e-01, 3.99600219e-01,\n",
       "        2.10673521e-01, 8.83962196e-02, 6.46553942e-01, 6.50727348e-01,\n",
       "        4.67889616e-01, 5.15228256e-01, 1.44804800e-01, 2.80096307e-02,\n",
       "        2.72000772e-01, 7.29664456e-01, 3.84733824e-01, 1.97600474e-02,\n",
       "        9.03225515e-01, 6.79560710e-01, 1.54889549e-01, 5.98460988e-01],\n",
       "       [4.73354847e-01, 8.24074141e-01, 2.38618569e-02, 4.46466786e-02,\n",
       "        3.54920375e-01, 7.70869694e-01, 8.27987417e-01, 4.43021350e-01,\n",
       "        7.20859976e-01, 8.98150567e-01, 7.82259862e-01, 4.08443976e-01,\n",
       "        4.66130084e-01, 6.50788480e-01, 4.41881818e-01, 2.64648727e-01,\n",
       "        6.45413113e-01, 3.85903245e-01, 1.89578732e-02, 9.33956647e-02,\n",
       "        7.45392127e-01, 3.31706066e-01, 3.48437093e-01, 4.72818742e-01,\n",
       "        4.56232640e-01, 2.60097911e-01, 1.04678785e-01, 2.47295954e-01],\n",
       "       [1.09660007e-01, 3.29975706e-01, 6.27062235e-01, 2.80376880e-02,\n",
       "        3.70181133e-01, 2.82339621e-01, 2.81632554e-01, 1.34358950e-01,\n",
       "        5.66760294e-01, 2.94240600e-01, 5.15104998e-01, 1.93230444e-02,\n",
       "        5.47469657e-01, 2.10305031e-01, 3.66689889e-02, 5.87465571e-01,\n",
       "        3.07306557e-01, 8.89560760e-01, 5.15682357e-01, 8.76126342e-01,\n",
       "        7.75768722e-01, 9.25446546e-01, 3.85371285e-01, 7.81498205e-01,\n",
       "        1.90269789e-01, 9.38474719e-01, 1.95191469e-01, 8.50734947e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 첫 채널에 접근\n",
    "x[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 im2col로 데이터 전개하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이에서 원소를 접근할 때 for 문을 사용하지 않는 것이 바람직하다.\n",
    "\n",
    "im2col 함수\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99F49B495BA49CE71C\">\n",
    "\n",
    "- 입력 데이터를 필터링(가중치 계산)하기 좋게 펼치는 함수\n",
    "- 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어 놓는다.\n",
    "- 필터를 적용하는 영역이 겹쳐서 메모리를 더 많이 사용하지만, 선형 대수 라이브러리가 행렬 계산을 매우 빠르게 처리해줘서 속도에서는 이점이 있다.\n",
    "- Affine 계층에서 한 것과 유사한 계산\n",
    "- 마지막에 2차원 출력 데이터를 4차원으로 변형(reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터 크기, 스트라이드, 패딩을 고려해서 입력 데이터를 2차원 배열로 전개\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    # np.pad(array, pad_width, mode, **kwargs)\n",
    "    # array: 패딩할 배열\n",
    "    # pad_width: 각 축마다 패딩할 값의 수\n",
    "    # mode: 패딩 방식\n",
    "    # default로 0으로 패딩\n",
    "    # 신경망에서 패딩을 하게 되면 이미지와 채널 수에 해당되는 차원은 하지 않기 때문에 pad_width에 해당되는\n",
    "    # 인수의 처음과 두번째 원소가 (0,0)인 것이다. 즉, 해당 차원은 패딩하지 않는다.\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    # Q. for 문 이해 안됨\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    \n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.shape(FN, -1). T\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역전파에서는 im2col을 반대로 처리하는 col2im을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : 2차원 배열(입력 데이터)\n",
    "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : 변환된 이미지들\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.4 풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/992F044B5C4D422B02\">\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99C888485C4D425402\">\n",
    "\n",
    "합성곱 계층과 마찬가지로 im2col 함수를 이용한다. 다만, 다른 점은 채널마다 독립적으로 전개한다는 점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    \n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 (1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 최댓값 (2)\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 성형 (3)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 CNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 숫자 인식하는 CNN 구현\n",
    "- 구조: conv-relu-pooling-affine-relu-affine-softmax\n",
    "\n",
    "SimpleConvNet 클래스\n",
    "- \\_\\_init\\_\\_\n",
    "    - 인수\n",
    "        - input_dim: 입력 데이터(채널 수, 높이, 너비)의 차원\n",
    "        - conv_param: 합성곱 계층의 하이퍼파라미터(딕셔너리)\n",
    "            - filter_num: 필터 수\n",
    "            - filter_size: 필터 크기\n",
    "            - stride: 스트라이드\n",
    "            - pad: 패딩\n",
    "            - hidden_size: 은닉층의 뉴런 수\n",
    "            - output_size: 출력층의 뉴런 수\n",
    "            - weight_init_std: 초기화 때의 가중치 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    \n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                conv_param={'filter_num':30, 'filter_size':5,\n",
    "                           'pad':0, 'stride':1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int((filter_num * (conv_output_size/2) * (conv_output_size/2)))\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                          conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.parmas['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.laeyrs['Affine2'] = Affine(self.params['W3'], self.parmas['b3'])\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layers.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2995260237545354\n",
      "=== epoch:1, train acc:0.131, test acc:0.118 ===\n",
      "train loss:2.2975321648494162\n",
      "train loss:2.294610007994603\n",
      "train loss:2.287643742679368\n",
      "train loss:2.277571750143067\n",
      "train loss:2.273888829395921\n",
      "train loss:2.25138555721259\n",
      "train loss:2.231636338533291\n",
      "train loss:2.2079077665456355\n",
      "train loss:2.186551637701792\n",
      "train loss:2.1616765062348984\n",
      "train loss:2.1258431776119435\n",
      "train loss:2.0802510670359355\n",
      "train loss:2.0478870692285334\n",
      "train loss:1.9635052471656693\n",
      "train loss:1.8957273113262747\n",
      "train loss:1.8494475870518925\n",
      "train loss:1.7978324885763615\n",
      "train loss:1.6324522810836712\n",
      "train loss:1.5907326038955918\n",
      "train loss:1.5663289527905015\n",
      "train loss:1.4060911914933985\n",
      "train loss:1.3127782218226942\n",
      "train loss:1.4009014144730845\n",
      "train loss:1.244594319090214\n",
      "train loss:1.1313555473927368\n",
      "train loss:1.1168677312278112\n",
      "train loss:0.9926726162914339\n",
      "train loss:0.9378282038798514\n",
      "train loss:1.015293655641714\n",
      "train loss:0.8153562964995578\n",
      "train loss:0.7767883218664912\n",
      "train loss:0.8343574498549732\n",
      "train loss:0.7845039178139628\n",
      "train loss:0.8331606602397506\n",
      "train loss:0.7293928024111136\n",
      "train loss:0.7302166792623954\n",
      "train loss:0.7142349462782376\n",
      "train loss:0.6589037929855196\n",
      "train loss:0.597870772751726\n",
      "train loss:0.7389194921412661\n",
      "train loss:0.8425985031858483\n",
      "train loss:0.5343018995230805\n",
      "train loss:0.5372497001208134\n",
      "train loss:0.5939929708525262\n",
      "train loss:0.4424492294030838\n",
      "train loss:0.5901476304850038\n",
      "train loss:0.6916884803307022\n",
      "train loss:0.5051114465798987\n",
      "train loss:0.4808547597858692\n",
      "train loss:0.5214787055447627\n",
      "train loss:0.6546691531036615\n",
      "train loss:0.5015226400373246\n",
      "train loss:0.4070523527328971\n",
      "train loss:0.4546788550253605\n",
      "train loss:0.44035193530031946\n",
      "train loss:0.8022430524280584\n",
      "train loss:0.533696938950011\n",
      "train loss:0.5071430798182432\n",
      "train loss:0.45704587074165987\n",
      "train loss:0.471387070755422\n",
      "train loss:0.4553019090127928\n",
      "train loss:0.41257352402073516\n",
      "train loss:0.5378462265435145\n",
      "train loss:0.5091642062846236\n",
      "train loss:0.6109070902487553\n",
      "train loss:0.5222512354062152\n",
      "train loss:0.4177100234374614\n",
      "train loss:0.4592051104653866\n",
      "train loss:0.5178386405898523\n",
      "train loss:0.5292905745933173\n",
      "train loss:0.37230574978115555\n",
      "train loss:0.3127846085791221\n",
      "train loss:0.45169722190616474\n",
      "train loss:0.5666833519297083\n",
      "train loss:0.5205912747825981\n",
      "train loss:0.43936561336536234\n",
      "train loss:0.4078561270587124\n",
      "train loss:0.44687964569131133\n",
      "train loss:0.3320302467002822\n",
      "train loss:0.606094658688638\n",
      "train loss:0.37466916087719787\n",
      "train loss:0.3642995456791938\n",
      "train loss:0.2539767941607304\n",
      "train loss:0.6893476510620279\n",
      "train loss:0.4559064759276608\n",
      "train loss:0.4205125810973921\n",
      "train loss:0.3635716951632586\n",
      "train loss:0.5380757934249744\n",
      "train loss:0.3860749811885292\n",
      "train loss:0.5702173396160013\n",
      "train loss:0.43642581850684353\n",
      "train loss:0.5903466118818909\n",
      "train loss:0.43124926667523683\n",
      "train loss:0.422995136083623\n",
      "train loss:0.494663626524474\n",
      "train loss:0.23928327799518997\n",
      "train loss:0.4389386733938829\n",
      "train loss:0.4975613754140479\n",
      "train loss:0.29989153269028324\n",
      "train loss:0.5340865689757501\n",
      "train loss:0.515921579880619\n",
      "train loss:0.49372802392657095\n",
      "train loss:0.3741816973066016\n",
      "train loss:0.5325722980611891\n",
      "train loss:0.5777707363203446\n",
      "train loss:0.28452116770943553\n",
      "train loss:0.3792662741706853\n",
      "train loss:0.512781116645195\n",
      "train loss:0.4651413552918575\n",
      "train loss:0.4573989296554567\n",
      "train loss:0.38245671909206863\n",
      "train loss:0.3935923118369902\n",
      "train loss:0.3896646328152438\n",
      "train loss:0.37314023489603765\n",
      "train loss:0.3546617717083005\n",
      "train loss:0.4259613372022178\n",
      "train loss:0.3019329786734807\n",
      "train loss:0.47499193513246096\n",
      "train loss:0.36832017194815597\n",
      "train loss:0.33899129847707143\n",
      "train loss:0.5352389347327497\n",
      "train loss:0.4213659868346926\n",
      "train loss:0.5227045888286187\n",
      "train loss:0.41044568571983997\n",
      "train loss:0.4505768460878686\n",
      "train loss:0.5185190678765808\n",
      "train loss:0.41683611854619124\n",
      "train loss:0.3336401036609646\n",
      "train loss:0.31668664593208895\n",
      "train loss:0.19225298697700097\n",
      "train loss:0.48029680795295016\n",
      "train loss:0.35035007992943357\n",
      "train loss:0.37813176274536475\n",
      "train loss:0.33029887974658156\n",
      "train loss:0.36016211537256465\n",
      "train loss:0.24354817057800254\n",
      "train loss:0.35702854089916636\n",
      "train loss:0.3385868498183969\n",
      "train loss:0.41086469564974293\n",
      "train loss:0.28300843620623767\n",
      "train loss:0.35857457710578167\n",
      "train loss:0.4039282883962908\n",
      "train loss:0.3634430800041794\n",
      "train loss:0.3509379393977368\n",
      "train loss:0.41995069418829367\n",
      "train loss:0.3353411910767167\n",
      "train loss:0.2985137615581245\n",
      "train loss:0.24590903251217924\n",
      "train loss:0.32055106703825537\n",
      "train loss:0.32863412763144473\n",
      "train loss:0.2840248146451457\n",
      "train loss:0.26189301937033976\n",
      "train loss:0.41787080664027043\n",
      "train loss:0.1454880008378565\n",
      "train loss:0.34426942098500335\n",
      "train loss:0.39450547736616726\n",
      "train loss:0.28241774869455105\n",
      "train loss:0.26777546760623044\n",
      "train loss:0.3526921711224171\n",
      "train loss:0.23795047775636216\n",
      "train loss:0.45058150240973865\n",
      "train loss:0.24805663640747358\n",
      "train loss:0.3627811897901896\n",
      "train loss:0.4189282134165242\n",
      "train loss:0.189975040380211\n",
      "train loss:0.42773058373279743\n",
      "train loss:0.2090652076316316\n",
      "train loss:0.29939223667026016\n",
      "train loss:0.24497849788237594\n",
      "train loss:0.2277190408232572\n",
      "train loss:0.417478641253075\n",
      "train loss:0.3770938299681978\n",
      "train loss:0.29597095336285856\n",
      "train loss:0.38070843368181284\n",
      "train loss:0.17263244320255602\n",
      "train loss:0.3426275965090877\n",
      "train loss:0.25464300984058197\n",
      "train loss:0.25622213849906406\n",
      "train loss:0.2853450105601708\n",
      "train loss:0.27563467329252545\n",
      "train loss:0.31926690613941044\n",
      "train loss:0.19317477335686953\n",
      "train loss:0.3186918968786634\n",
      "train loss:0.31330194013261575\n",
      "train loss:0.1850334495467983\n",
      "train loss:0.16960401202858272\n",
      "train loss:0.30454723361769026\n",
      "train loss:0.25482989938226563\n",
      "train loss:0.29046575783204376\n",
      "train loss:0.2955420010388532\n",
      "train loss:0.3131590536871947\n",
      "train loss:0.26530615329826046\n",
      "train loss:0.32003361055147783\n",
      "train loss:0.3581532876000314\n",
      "train loss:0.2540557917079185\n",
      "train loss:0.34266555332705834\n",
      "train loss:0.26386260490308566\n",
      "train loss:0.21216390427118728\n",
      "train loss:0.28210937375066875\n",
      "train loss:0.21563940808495047\n",
      "train loss:0.3461989482598296\n",
      "train loss:0.5728373640928606\n",
      "train loss:0.18695121239308313\n",
      "train loss:0.32354828178393935\n",
      "train loss:0.45776952244707514\n",
      "train loss:0.44820270023914327\n",
      "train loss:0.29656596326731194\n",
      "train loss:0.36265299182314076\n",
      "train loss:0.31268178970432675\n",
      "train loss:0.48630718313194515\n",
      "train loss:0.24585982543459392\n",
      "train loss:0.25374418226525486\n",
      "train loss:0.3760461713042173\n",
      "train loss:0.2356054476516752\n",
      "train loss:0.14885146053688458\n",
      "train loss:0.24010574233661455\n",
      "train loss:0.24076153485568771\n",
      "train loss:0.43950183348596794\n",
      "train loss:0.4435571351466645\n",
      "train loss:0.36973978468986446\n",
      "train loss:0.27441228376388854\n",
      "train loss:0.26387085268234045\n",
      "train loss:0.47002519620825056\n",
      "train loss:0.20094167305128097\n",
      "train loss:0.2633714848782178\n",
      "train loss:0.16023173206421223\n",
      "train loss:0.3394660837629373\n",
      "train loss:0.26079024136315687\n",
      "train loss:0.22253466492508775\n",
      "train loss:0.24450292859548953\n",
      "train loss:0.25841485357366656\n",
      "train loss:0.3740506619194383\n",
      "train loss:0.2483533308067488\n",
      "train loss:0.3772990820951604\n",
      "train loss:0.3034689043380898\n",
      "train loss:0.21357226141804436\n",
      "train loss:0.3482272986975883\n",
      "train loss:0.15474420385892423\n",
      "train loss:0.2864995033055231\n",
      "train loss:0.35609093718410684\n",
      "train loss:0.3609896342488011\n",
      "train loss:0.2561931568489583\n",
      "train loss:0.3698149215978735\n",
      "train loss:0.3165865431263563\n",
      "train loss:0.40177746374184425\n",
      "train loss:0.17307096167519032\n",
      "train loss:0.18133143702911048\n",
      "train loss:0.32715552165116113\n",
      "train loss:0.19335752659981068\n",
      "train loss:0.3481111487758897\n",
      "train loss:0.24417117847025183\n",
      "train loss:0.1585304885750187\n",
      "train loss:0.29910292361626106\n",
      "train loss:0.24101364597313746\n",
      "train loss:0.20890347852502245\n",
      "train loss:0.2629744865573081\n",
      "train loss:0.2626653274946857\n",
      "train loss:0.24761648116597582\n",
      "train loss:0.2806345283478022\n",
      "train loss:0.3380364768248766\n",
      "train loss:0.29060950481205755\n",
      "train loss:0.24598361468505736\n",
      "train loss:0.30486803173066546\n",
      "train loss:0.1625505606301374\n",
      "train loss:0.16941349443172782\n",
      "train loss:0.24137614321618237\n",
      "train loss:0.35527732550471036\n",
      "train loss:0.21080578528245147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.20506868751284477\n",
      "train loss:0.2627372864880542\n",
      "train loss:0.21828614840433372\n",
      "train loss:0.3175802711774647\n",
      "train loss:0.3602783743729605\n",
      "train loss:0.2220619706003202\n",
      "train loss:0.21495406083414587\n",
      "train loss:0.19951440661192651\n",
      "train loss:0.1450541486713814\n",
      "train loss:0.1721000697447031\n",
      "train loss:0.2930998267418376\n",
      "train loss:0.2570889295961183\n",
      "train loss:0.12097244924429824\n",
      "train loss:0.35336132337812665\n",
      "train loss:0.19814609601867475\n",
      "train loss:0.23451666428238435\n",
      "train loss:0.1645692212672131\n",
      "train loss:0.26659536712542886\n",
      "train loss:0.22910238472460942\n",
      "train loss:0.22835879124764855\n",
      "train loss:0.28316631072734155\n",
      "train loss:0.25982613191309717\n",
      "train loss:0.3761664672428233\n",
      "train loss:0.1539724003366865\n",
      "train loss:0.32837121749039644\n",
      "train loss:0.26302596564119823\n",
      "train loss:0.35589183415847436\n",
      "train loss:0.285820494399379\n",
      "train loss:0.2922199229893694\n",
      "train loss:0.14903603183873698\n",
      "train loss:0.38072912186858365\n",
      "train loss:0.25885916380702356\n",
      "train loss:0.2053287203293225\n",
      "train loss:0.3090595420977064\n",
      "train loss:0.18789402552594203\n",
      "train loss:0.12406765665350869\n",
      "train loss:0.19940607067575772\n",
      "train loss:0.25536221181582575\n",
      "train loss:0.16448899161868497\n",
      "train loss:0.18846690145690614\n",
      "train loss:0.17030008122293247\n",
      "train loss:0.1707775076235594\n",
      "train loss:0.12719021096060978\n",
      "train loss:0.17278592558789202\n",
      "train loss:0.22218470498063286\n",
      "train loss:0.2688993837883874\n",
      "train loss:0.20205107557306318\n",
      "train loss:0.14895393557454317\n",
      "train loss:0.37346482361599775\n",
      "train loss:0.21723356735994956\n",
      "train loss:0.23218054316378597\n",
      "train loss:0.32717613451462235\n",
      "train loss:0.22321080584457903\n",
      "train loss:0.33635207655292504\n",
      "train loss:0.44828122879772936\n",
      "train loss:0.2557954522588312\n",
      "train loss:0.1559443037651237\n",
      "train loss:0.18670088221209868\n",
      "train loss:0.29285246805703785\n",
      "train loss:0.18094658708517086\n",
      "train loss:0.1907703071549337\n",
      "train loss:0.17779715201469629\n",
      "train loss:0.21429947714095074\n",
      "train loss:0.21816216588567464\n",
      "train loss:0.14324138618893226\n",
      "train loss:0.1569320952378283\n",
      "train loss:0.13915380998746596\n",
      "train loss:0.3041034564143602\n",
      "train loss:0.293328880625048\n",
      "train loss:0.21581185506749417\n",
      "train loss:0.21990706194893103\n",
      "train loss:0.16732265827628778\n",
      "train loss:0.22470531600273985\n",
      "train loss:0.18143890163186904\n",
      "train loss:0.302789177931571\n",
      "train loss:0.3383129379698751\n",
      "train loss:0.2538866823031334\n",
      "train loss:0.22417205789932992\n",
      "train loss:0.24910183853107146\n",
      "train loss:0.14862726135688642\n",
      "train loss:0.1425263249262315\n",
      "train loss:0.21692657876094118\n",
      "train loss:0.293648908951719\n",
      "train loss:0.17957360253546814\n",
      "train loss:0.1157991370344733\n",
      "train loss:0.13755987513976556\n",
      "train loss:0.32594517294340086\n",
      "train loss:0.14650853718685625\n",
      "train loss:0.27421618843464457\n",
      "train loss:0.2523043181755602\n",
      "train loss:0.4355056222184265\n",
      "train loss:0.12939928334897094\n",
      "train loss:0.25373821732626795\n",
      "train loss:0.29853245917932514\n",
      "train loss:0.12070549861484416\n",
      "train loss:0.12443162400075884\n",
      "train loss:0.16484665039485463\n",
      "train loss:0.214995143714167\n",
      "train loss:0.10055426752914633\n",
      "train loss:0.3176912850386456\n",
      "train loss:0.14997977356070605\n",
      "train loss:0.17944997372494825\n",
      "train loss:0.4826527619720851\n",
      "train loss:0.09792111516319886\n",
      "train loss:0.17552080149861113\n",
      "train loss:0.1048080920320199\n",
      "train loss:0.15337618010269066\n",
      "train loss:0.20571437140586496\n",
      "train loss:0.17925039693594733\n",
      "train loss:0.21514427505805345\n",
      "train loss:0.2416335017191642\n",
      "train loss:0.11471764650200907\n",
      "train loss:0.2731915099926532\n",
      "train loss:0.21061633453526266\n",
      "train loss:0.1616340317338025\n",
      "train loss:0.19674107538638907\n",
      "train loss:0.1971675744577533\n",
      "train loss:0.17465521646558854\n",
      "train loss:0.25457985943793704\n",
      "train loss:0.31293626454556545\n",
      "train loss:0.17074527159512262\n",
      "train loss:0.13825144559231023\n",
      "train loss:0.28519298381833147\n",
      "train loss:0.16404464020150683\n",
      "train loss:0.11719055868543203\n",
      "train loss:0.2175574176164577\n",
      "train loss:0.18468671938254397\n",
      "train loss:0.12320962675464246\n",
      "train loss:0.22265917185100967\n",
      "train loss:0.24705928140836303\n",
      "train loss:0.15399867576376502\n",
      "train loss:0.1734899576159936\n",
      "train loss:0.12385066369080441\n",
      "train loss:0.37191048638480334\n",
      "train loss:0.19213402955966186\n",
      "train loss:0.21520384690015346\n",
      "train loss:0.2514577370193522\n",
      "train loss:0.14956973110248153\n",
      "train loss:0.17310694863136727\n",
      "train loss:0.2016029849884799\n",
      "train loss:0.10451671614043159\n",
      "train loss:0.21314363391154414\n",
      "train loss:0.10278331002077375\n",
      "train loss:0.18309315271873478\n",
      "train loss:0.15763794055969482\n",
      "train loss:0.14520027286589202\n",
      "train loss:0.19606878088632335\n",
      "train loss:0.05765690093252645\n",
      "train loss:0.08159345569205768\n",
      "train loss:0.17858830477667895\n",
      "train loss:0.15788336190715938\n",
      "train loss:0.1445433342391307\n",
      "train loss:0.1350224611915889\n",
      "train loss:0.3213282961355247\n",
      "train loss:0.1455036509508779\n",
      "train loss:0.2012672395833089\n",
      "train loss:0.1646008264614261\n",
      "train loss:0.24718086752731916\n",
      "train loss:0.23768292075156633\n",
      "train loss:0.23696255720409753\n",
      "train loss:0.20377591745075294\n",
      "train loss:0.09438160807786365\n",
      "train loss:0.12330449393973732\n",
      "train loss:0.21669546862628078\n",
      "train loss:0.25349864238038805\n",
      "train loss:0.18342224641640884\n",
      "train loss:0.1731976588515187\n",
      "train loss:0.28000875576875006\n",
      "train loss:0.2593447695796865\n",
      "train loss:0.09721645419527958\n",
      "train loss:0.19280193965742862\n",
      "train loss:0.07577878426397229\n",
      "train loss:0.12951012122121353\n",
      "train loss:0.19847188502721283\n",
      "train loss:0.21821192212339163\n",
      "train loss:0.14184312253398026\n",
      "train loss:0.12439700460717365\n",
      "train loss:0.20790375206384226\n",
      "train loss:0.051238265449731465\n",
      "train loss:0.13210155785347427\n",
      "train loss:0.20265541220333425\n",
      "train loss:0.10055135536864915\n",
      "train loss:0.16870691923673306\n",
      "train loss:0.22105041372860237\n",
      "train loss:0.0774685193085176\n",
      "train loss:0.09446352904647166\n",
      "train loss:0.11956454378377421\n",
      "train loss:0.22724544768549204\n",
      "train loss:0.1603270113364339\n",
      "train loss:0.2485715201530569\n",
      "train loss:0.09210085096464563\n",
      "train loss:0.11970549996365408\n",
      "train loss:0.08786388941418599\n",
      "train loss:0.15309414516281986\n",
      "train loss:0.08952686363428049\n",
      "train loss:0.12329744996323581\n",
      "train loss:0.11569715553969344\n",
      "train loss:0.14871774777976182\n",
      "train loss:0.22126858359503332\n",
      "train loss:0.3462326028579956\n",
      "train loss:0.11810782393889299\n",
      "train loss:0.23096875158999694\n",
      "train loss:0.09577021796330051\n",
      "train loss:0.10813592186784954\n",
      "train loss:0.09357908423041367\n",
      "train loss:0.22265943353998313\n",
      "train loss:0.1701548039418124\n",
      "train loss:0.20210458286119595\n",
      "train loss:0.1661228221280406\n",
      "train loss:0.2200142076649107\n",
      "train loss:0.14878336897965536\n",
      "train loss:0.19350392544530234\n",
      "train loss:0.169723222500781\n",
      "train loss:0.21870491954664792\n",
      "train loss:0.13885569166839032\n",
      "train loss:0.23725051177350473\n",
      "train loss:0.13725460302860915\n",
      "train loss:0.21426106003735054\n",
      "train loss:0.15849694878657952\n",
      "train loss:0.15371312759495598\n",
      "train loss:0.13748884799909444\n",
      "train loss:0.2043186215985003\n",
      "train loss:0.16111475589319518\n",
      "train loss:0.3055820136159998\n",
      "train loss:0.21213885060249726\n",
      "train loss:0.17482401628937136\n",
      "train loss:0.11322429870243912\n",
      "train loss:0.1777452732740386\n",
      "train loss:0.1646610338479247\n",
      "train loss:0.15462540767975372\n",
      "train loss:0.2376609633596296\n",
      "train loss:0.16918786722587115\n",
      "train loss:0.16164371399661268\n",
      "train loss:0.1492974194147541\n",
      "train loss:0.1644426406780453\n",
      "train loss:0.20581202544456242\n",
      "train loss:0.11391455663281329\n",
      "train loss:0.17846378766547172\n",
      "train loss:0.12281301484971845\n",
      "train loss:0.20506428547049008\n",
      "train loss:0.056534244881883675\n",
      "train loss:0.3565201584699706\n",
      "train loss:0.2361925285407412\n",
      "train loss:0.13222199647771374\n",
      "train loss:0.22297207436112598\n",
      "train loss:0.37715234748805626\n",
      "train loss:0.11799851566808486\n",
      "train loss:0.34753447300087825\n",
      "train loss:0.23095505124985757\n",
      "train loss:0.09262636362775367\n",
      "train loss:0.20697462388547655\n",
      "train loss:0.11006878420484041\n",
      "train loss:0.08573806384881622\n",
      "train loss:0.10495715574331968\n",
      "train loss:0.245977598161628\n",
      "train loss:0.0987948932960247\n",
      "train loss:0.1444308755699995\n",
      "train loss:0.1299860182867155\n",
      "train loss:0.17486646877609519\n",
      "train loss:0.24126852165383147\n",
      "train loss:0.1475746692170089\n",
      "train loss:0.0956747596315593\n",
      "train loss:0.17333571187689154\n",
      "train loss:0.20550080801399367\n",
      "train loss:0.16210489339568732\n",
      "train loss:0.12833729675694516\n",
      "train loss:0.18293676068847803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.22352198896871886\n",
      "train loss:0.21882435157341665\n",
      "train loss:0.13130392120814444\n",
      "train loss:0.12691176132323365\n",
      "train loss:0.1591349820233077\n",
      "train loss:0.14106356845712328\n",
      "train loss:0.11827073332728391\n",
      "train loss:0.12621163529194182\n",
      "train loss:0.0625820345431352\n",
      "train loss:0.12101626661145864\n",
      "train loss:0.0986264335040255\n",
      "train loss:0.20355673864367468\n",
      "train loss:0.1520004531006794\n",
      "train loss:0.13628422587272984\n",
      "train loss:0.15365474452428649\n",
      "train loss:0.19043197814695778\n",
      "train loss:0.1546948801484528\n",
      "train loss:0.12846829372740076\n",
      "train loss:0.23166545664080612\n",
      "train loss:0.14112904662137823\n",
      "train loss:0.16762794292939226\n",
      "train loss:0.16597227927324987\n",
      "train loss:0.17500706217076115\n",
      "train loss:0.1348197325800523\n",
      "train loss:0.0675776041558981\n",
      "train loss:0.21588637695178137\n",
      "train loss:0.11443338448015322\n",
      "train loss:0.19095877365341685\n",
      "train loss:0.15244967571322227\n",
      "train loss:0.10211084653833716\n",
      "train loss:0.11218175286405006\n",
      "train loss:0.1220838068198742\n",
      "train loss:0.05478412628796001\n",
      "train loss:0.10642656365600177\n",
      "train loss:0.23808537659222945\n",
      "train loss:0.1402970533379929\n",
      "train loss:0.05645732094339975\n",
      "train loss:0.14939088021085115\n",
      "train loss:0.16544952667193125\n",
      "train loss:0.10116048704349073\n",
      "train loss:0.29948645144873937\n",
      "train loss:0.10525861236365713\n",
      "train loss:0.2351844305392119\n",
      "train loss:0.06125712493061851\n",
      "train loss:0.14636443046320916\n",
      "train loss:0.14356278499410582\n",
      "train loss:0.11454397539185625\n",
      "train loss:0.16233433028924227\n",
      "train loss:0.15266770664517593\n",
      "train loss:0.1603330355702212\n",
      "train loss:0.15663645652975847\n",
      "train loss:0.1304714678991603\n",
      "train loss:0.1756065039535165\n",
      "train loss:0.15185034571675424\n",
      "train loss:0.1025312846095741\n",
      "train loss:0.13552747146731484\n",
      "train loss:0.20558773101586714\n",
      "train loss:0.2703599668917699\n",
      "train loss:0.2155870025182139\n",
      "train loss:0.07886908693811996\n",
      "train loss:0.17166793916541997\n",
      "train loss:0.20436061440918848\n",
      "train loss:0.18177242474997723\n",
      "train loss:0.07011237367877701\n",
      "train loss:0.08378813465656548\n",
      "=== epoch:2, train acc:0.958, test acc:0.967 ===\n",
      "train loss:0.2040296904738196\n",
      "train loss:0.07580959146687043\n",
      "train loss:0.11429984665399129\n",
      "train loss:0.14783422522313616\n",
      "train loss:0.20338239152141324\n",
      "train loss:0.1350987306356796\n",
      "train loss:0.1163742446364087\n",
      "train loss:0.15024634797290512\n",
      "train loss:0.04568589059025516\n",
      "train loss:0.07125952859331953\n",
      "train loss:0.12716012132553486\n",
      "train loss:0.09786169259387495\n",
      "train loss:0.12971514505224407\n",
      "train loss:0.13755755191213725\n",
      "train loss:0.050875226767889324\n",
      "train loss:0.07056139188801597\n",
      "train loss:0.11735253955958741\n",
      "train loss:0.061116778944074614\n",
      "train loss:0.05232254232683831\n",
      "train loss:0.1308712260545045\n",
      "train loss:0.16095927884784478\n",
      "train loss:0.20507237373550133\n",
      "train loss:0.1530523405685912\n",
      "train loss:0.09233345560894972\n",
      "train loss:0.13838768569470383\n",
      "train loss:0.15971944018860326\n",
      "train loss:0.14809336942232376\n",
      "train loss:0.14323336104974552\n",
      "train loss:0.17778249577944696\n",
      "train loss:0.16396276844512328\n",
      "train loss:0.129543240072398\n",
      "train loss:0.05730720817495128\n",
      "train loss:0.15528925339323904\n",
      "train loss:0.19182647129429933\n",
      "train loss:0.19383020726441758\n",
      "train loss:0.16387520243743275\n",
      "train loss:0.07234712991054669\n",
      "train loss:0.16311109393461018\n",
      "train loss:0.11502239489731773\n",
      "train loss:0.1733228868848603\n",
      "train loss:0.0737580276876373\n",
      "train loss:0.07257689120541334\n",
      "train loss:0.08425913533677416\n",
      "train loss:0.12993042345671493\n",
      "train loss:0.0684780273007949\n",
      "train loss:0.05719801702859421\n",
      "train loss:0.13003856782957823\n",
      "train loss:0.14763435165783703\n",
      "train loss:0.11262632484631813\n",
      "train loss:0.16555576473191178\n",
      "train loss:0.12735662422617156\n",
      "train loss:0.18880338193905996\n",
      "train loss:0.05956387418138705\n",
      "train loss:0.11217864584618663\n",
      "train loss:0.14603037140580186\n",
      "train loss:0.08940555542430394\n",
      "train loss:0.12524017892790842\n",
      "train loss:0.0764788867024836\n",
      "train loss:0.18602215358588495\n",
      "train loss:0.099277396612538\n",
      "train loss:0.1694702465442761\n",
      "train loss:0.1484032552904728\n",
      "train loss:0.10028125339665124\n",
      "train loss:0.1171584574815446\n",
      "train loss:0.11118028168191475\n",
      "train loss:0.0720869665692375\n",
      "train loss:0.1871133308649244\n",
      "train loss:0.05238846513319384\n",
      "train loss:0.1355209062926463\n",
      "train loss:0.06839085193136203\n",
      "train loss:0.13392546432830776\n",
      "train loss:0.2144956093023427\n",
      "train loss:0.07507005441686927\n",
      "train loss:0.04535199373731001\n",
      "train loss:0.06588107333453118\n",
      "train loss:0.07997042772912817\n",
      "train loss:0.08624127201484068\n",
      "train loss:0.1775223479537405\n",
      "train loss:0.07332106132479392\n",
      "train loss:0.22117125521683342\n",
      "train loss:0.07998463413463286\n",
      "train loss:0.06685285496853872\n",
      "train loss:0.08330550237874826\n",
      "train loss:0.12080349081883293\n",
      "train loss:0.07968821009110472\n",
      "train loss:0.15797887050303105\n",
      "train loss:0.07885944766724726\n",
      "train loss:0.08599901197204493\n",
      "train loss:0.15760886278356842\n",
      "train loss:0.12449973134401698\n",
      "train loss:0.1370430941777435\n",
      "train loss:0.06947763120721101\n",
      "train loss:0.133204391367988\n",
      "train loss:0.06697305701035765\n",
      "train loss:0.15101694663555787\n",
      "train loss:0.0531334758170717\n",
      "train loss:0.10594121333890164\n",
      "train loss:0.029768509425969092\n",
      "train loss:0.1252887398580472\n",
      "train loss:0.14082850199695152\n",
      "train loss:0.10599151112127346\n",
      "train loss:0.21418422457679834\n",
      "train loss:0.08932740670698618\n",
      "train loss:0.1528779526057411\n",
      "train loss:0.06902873917674328\n",
      "train loss:0.11547041639822934\n",
      "train loss:0.1704648536986066\n",
      "train loss:0.07891962083302265\n",
      "train loss:0.13872060511332554\n",
      "train loss:0.1419484403234357\n",
      "train loss:0.06132593096524215\n",
      "train loss:0.16067510443456623\n",
      "train loss:0.1761685894543983\n",
      "train loss:0.1894904265647381\n",
      "train loss:0.1553534675145787\n",
      "train loss:0.0711813227883251\n",
      "train loss:0.09645915450640796\n",
      "train loss:0.09884437913940473\n",
      "train loss:0.17244834091363323\n",
      "train loss:0.07103998734495859\n",
      "train loss:0.07458147737667682\n",
      "train loss:0.12143740371659557\n",
      "train loss:0.1579584806411896\n",
      "train loss:0.12212130295294794\n",
      "train loss:0.12433692180103822\n",
      "train loss:0.03148192172992417\n",
      "train loss:0.14812337966118588\n",
      "train loss:0.08192532753600573\n",
      "train loss:0.11732555541478515\n",
      "train loss:0.1983931875531419\n",
      "train loss:0.10422782163289859\n",
      "train loss:0.11382961447209164\n",
      "train loss:0.09974987907390397\n",
      "train loss:0.14616533755397165\n",
      "train loss:0.10554974022090872\n",
      "train loss:0.18136804433268267\n",
      "train loss:0.15940358730627552\n",
      "train loss:0.15277293451971075\n",
      "train loss:0.09821902141327316\n",
      "train loss:0.11165778006416513\n",
      "train loss:0.03439882123275267\n",
      "train loss:0.1374202645672663\n",
      "train loss:0.08873587727823232\n",
      "train loss:0.0692145633913613\n",
      "train loss:0.03935047189537413\n",
      "train loss:0.04195468298826413\n",
      "train loss:0.10862086743067699\n",
      "train loss:0.059009811959424265\n",
      "train loss:0.13301147299051963\n",
      "train loss:0.09884565548114678\n",
      "train loss:0.09017687478712723\n",
      "train loss:0.1333224529224252\n",
      "train loss:0.0639579194875008\n",
      "train loss:0.0428770077936624\n",
      "train loss:0.18266260265810463\n",
      "train loss:0.1299909034942769\n",
      "train loss:0.11297612127640619\n",
      "train loss:0.1272289796493741\n",
      "train loss:0.16064724362329938\n",
      "train loss:0.09524461274562325\n",
      "train loss:0.06579393861557196\n",
      "train loss:0.154311302810096\n",
      "train loss:0.061963947880592674\n",
      "train loss:0.09133624944942093\n",
      "train loss:0.13298788026944913\n",
      "train loss:0.11491919811250594\n",
      "train loss:0.12287010584260451\n",
      "train loss:0.17047827410206837\n",
      "train loss:0.15853201361606614\n",
      "train loss:0.10103846731944208\n",
      "train loss:0.098363376154572\n",
      "train loss:0.18086694650857205\n",
      "train loss:0.10087455722835637\n",
      "train loss:0.0743630545108704\n",
      "train loss:0.15184321250306104\n",
      "train loss:0.12839237589861863\n",
      "train loss:0.07982346101298834\n",
      "train loss:0.06925394402536864\n",
      "train loss:0.0955731723626402\n",
      "train loss:0.06397263743478883\n",
      "train loss:0.07831643164257752\n",
      "train loss:0.14695071045066702\n",
      "train loss:0.17058766098264924\n",
      "train loss:0.07608721812504336\n",
      "train loss:0.14230583262878535\n",
      "train loss:0.084056813622934\n",
      "train loss:0.08380441709825813\n",
      "train loss:0.06878846388928916\n",
      "train loss:0.1645700709968322\n",
      "train loss:0.05812257149674843\n",
      "train loss:0.14028624665261258\n",
      "train loss:0.07427105328975042\n",
      "train loss:0.11018945088530041\n",
      "train loss:0.04130136868146032\n",
      "train loss:0.0895493289985125\n",
      "train loss:0.16151803366252424\n",
      "train loss:0.21968276926928873\n",
      "train loss:0.11961903930989246\n",
      "train loss:0.04026789090722889\n",
      "train loss:0.357958852381079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12844489332097084\n",
      "train loss:0.07502702832289738\n",
      "train loss:0.11089005008166303\n",
      "train loss:0.10993359084921606\n",
      "train loss:0.09333240644046523\n",
      "train loss:0.07249989165397192\n",
      "train loss:0.06924848126354627\n",
      "train loss:0.14319087601320885\n",
      "train loss:0.14318858890208153\n",
      "train loss:0.10675907386229758\n",
      "train loss:0.05604820279178284\n",
      "train loss:0.05292797749304067\n",
      "train loss:0.08175835750153122\n",
      "train loss:0.12277845682647713\n",
      "train loss:0.06759612440762452\n",
      "train loss:0.11755123667495199\n",
      "train loss:0.07109392032578085\n",
      "train loss:0.09652672946643674\n",
      "train loss:0.027366239958665033\n",
      "train loss:0.07288582920356902\n",
      "train loss:0.09301970475243954\n",
      "train loss:0.09365709208541315\n",
      "train loss:0.11057604324020176\n",
      "train loss:0.044464531383469834\n",
      "train loss:0.039165034695919296\n",
      "train loss:0.142197119774249\n",
      "train loss:0.14336121320804526\n",
      "train loss:0.15545718642655842\n",
      "train loss:0.18035356821270676\n",
      "train loss:0.16167867703964314\n",
      "train loss:0.09835961200317227\n",
      "train loss:0.06729130536826884\n",
      "train loss:0.09223871549802291\n",
      "train loss:0.058109600928531104\n",
      "train loss:0.20636212879950044\n",
      "train loss:0.095195132625153\n",
      "train loss:0.08128884249151619\n",
      "train loss:0.09952940646173608\n",
      "train loss:0.10994246512977165\n",
      "train loss:0.09772309481434104\n",
      "train loss:0.1364827265771703\n",
      "train loss:0.08041374132088229\n",
      "train loss:0.1250443579152229\n",
      "train loss:0.0736317768273761\n",
      "train loss:0.13926549300050234\n",
      "train loss:0.12810834895145856\n",
      "train loss:0.1529996765499457\n",
      "train loss:0.08416937107188155\n",
      "train loss:0.08359157973424536\n",
      "train loss:0.1442447482050644\n",
      "train loss:0.1945252258507656\n",
      "train loss:0.16292321469991422\n",
      "train loss:0.11262584020480226\n",
      "train loss:0.14267657218123367\n",
      "train loss:0.09731278117702134\n",
      "train loss:0.07393267735260463\n",
      "train loss:0.12444054991092525\n",
      "train loss:0.2697514482429442\n",
      "train loss:0.08042887288744353\n",
      "train loss:0.1089468866332456\n",
      "train loss:0.10278703994651033\n",
      "train loss:0.12079049412286634\n",
      "train loss:0.07847535221877504\n",
      "train loss:0.09285236520784254\n",
      "train loss:0.09724138372921023\n",
      "train loss:0.06449326407968722\n",
      "train loss:0.10596821617003593\n",
      "train loss:0.11989093609409007\n",
      "train loss:0.05898991163701341\n",
      "train loss:0.07159363779287141\n",
      "train loss:0.27036524153067854\n",
      "train loss:0.10366626976639143\n",
      "train loss:0.11415724515876305\n",
      "train loss:0.0940328124390879\n",
      "train loss:0.11012167058633006\n",
      "train loss:0.13951784305248272\n",
      "train loss:0.08154473342466499\n",
      "train loss:0.07761039007655442\n",
      "train loss:0.09524455725181437\n",
      "train loss:0.14103381806819323\n",
      "train loss:0.05538720299393879\n",
      "train loss:0.11511888159125057\n",
      "train loss:0.1070594598718622\n",
      "train loss:0.08278072901708917\n",
      "train loss:0.0937819150763082\n",
      "train loss:0.05347263143061337\n",
      "train loss:0.08509607712405359\n",
      "train loss:0.17655798400107858\n",
      "train loss:0.05810367168098485\n",
      "train loss:0.1560869125598089\n",
      "train loss:0.10491303544123726\n",
      "train loss:0.07022163588650815\n",
      "train loss:0.037714896013345\n",
      "train loss:0.1934743213258664\n",
      "train loss:0.0986661210941834\n",
      "train loss:0.034373915858368485\n",
      "train loss:0.09332469069476218\n",
      "train loss:0.12352660728347668\n",
      "train loss:0.054573490207890235\n",
      "train loss:0.10631882438326187\n",
      "train loss:0.10793035994926256\n",
      "train loss:0.16804544201252106\n",
      "train loss:0.047244279406554374\n",
      "train loss:0.10810644750398442\n",
      "train loss:0.07366719219878537\n",
      "train loss:0.09400143536200854\n",
      "train loss:0.045277635502103904\n",
      "train loss:0.02821247241725748\n",
      "train loss:0.10306650557606843\n",
      "train loss:0.08586482333038932\n",
      "train loss:0.1199605553132188\n",
      "train loss:0.12813871693399181\n",
      "train loss:0.1882031177311772\n",
      "train loss:0.13888244835926689\n",
      "train loss:0.06653428349042571\n",
      "train loss:0.0809077167218058\n",
      "train loss:0.06798430572125154\n",
      "train loss:0.03790658424488245\n",
      "train loss:0.12364745540187712\n",
      "train loss:0.036303289821446656\n",
      "train loss:0.09892534426191389\n",
      "train loss:0.0338238667085687\n",
      "train loss:0.06059483503596733\n",
      "train loss:0.17055036974940635\n",
      "train loss:0.07448866445820022\n",
      "train loss:0.15599508793285333\n",
      "train loss:0.08153847720282918\n",
      "train loss:0.09410214893472732\n",
      "train loss:0.16737253931883175\n",
      "train loss:0.07078149874721781\n",
      "train loss:0.04637806246630915\n",
      "train loss:0.04408031115664737\n",
      "train loss:0.1050229431725633\n",
      "train loss:0.09691190837409135\n",
      "train loss:0.10436487968772923\n",
      "train loss:0.10493712170691649\n",
      "train loss:0.04114182911645977\n",
      "train loss:0.03479839875199733\n",
      "train loss:0.16360381652717323\n",
      "train loss:0.037909083117878675\n",
      "train loss:0.10366561564294993\n",
      "train loss:0.05271735699925897\n",
      "train loss:0.0922625058866188\n",
      "train loss:0.12231211167949324\n",
      "train loss:0.0638672343803666\n",
      "train loss:0.10732896195213643\n",
      "train loss:0.06051814240981594\n",
      "train loss:0.04723563826006668\n",
      "train loss:0.08980615627061683\n",
      "train loss:0.0837046868354074\n",
      "train loss:0.10332913437143394\n",
      "train loss:0.13403940501517236\n",
      "train loss:0.05455775132344079\n",
      "train loss:0.1034864717636565\n",
      "train loss:0.08045917663991517\n",
      "train loss:0.08374019095671781\n",
      "train loss:0.04946758427906367\n",
      "train loss:0.07253832253258452\n",
      "train loss:0.0791208177714276\n",
      "train loss:0.10466370303713664\n",
      "train loss:0.04271399051620018\n",
      "train loss:0.0504363429338798\n",
      "train loss:0.07912875918162325\n",
      "train loss:0.05356415258400931\n",
      "train loss:0.06862057438946688\n",
      "train loss:0.09872482327125016\n",
      "train loss:0.1517752519472398\n",
      "train loss:0.049504237248518025\n",
      "train loss:0.13247683974793348\n",
      "train loss:0.22005532359655153\n",
      "train loss:0.09203217114773064\n",
      "train loss:0.13203304243383035\n",
      "train loss:0.08975975257722121\n",
      "train loss:0.12386936134084506\n",
      "train loss:0.19067025078206343\n",
      "train loss:0.02923633211325844\n",
      "train loss:0.11839558377100787\n",
      "train loss:0.05263136212551858\n",
      "train loss:0.199423147255109\n",
      "train loss:0.029327344791304638\n",
      "train loss:0.05678159779688936\n",
      "train loss:0.03525471687784809\n",
      "train loss:0.054283842486715334\n",
      "train loss:0.07342370868035854\n",
      "train loss:0.054196882693201956\n",
      "train loss:0.05152977393488561\n",
      "train loss:0.04328036258143114\n",
      "train loss:0.061268079956147734\n",
      "train loss:0.05723556041653107\n",
      "train loss:0.08381491781243401\n",
      "train loss:0.08037491335150249\n",
      "train loss:0.17969831357429214\n",
      "train loss:0.1703915907773953\n",
      "train loss:0.07862710254069535\n",
      "train loss:0.1373606107189465\n",
      "train loss:0.08586192421547696\n",
      "train loss:0.10310232330346336\n",
      "train loss:0.0734929034376203\n",
      "train loss:0.14042509914253895\n",
      "train loss:0.13062314263283312\n",
      "train loss:0.11318206687639909\n",
      "train loss:0.07124053570347831\n",
      "train loss:0.07972454168065794\n",
      "train loss:0.04854218950405002\n",
      "train loss:0.08538963902372453\n",
      "train loss:0.07495485367441619\n",
      "train loss:0.11435819168469148\n",
      "train loss:0.032108027620988605\n",
      "train loss:0.0888138337256999\n",
      "train loss:0.07705365633316713\n",
      "train loss:0.11342640557212665\n",
      "train loss:0.058073123066410236\n",
      "train loss:0.09350969726375237\n",
      "train loss:0.07255599619564744\n",
      "train loss:0.05487553152073791\n",
      "train loss:0.2041559540776584\n",
      "train loss:0.11324164929282692\n",
      "train loss:0.0846268114393652\n",
      "train loss:0.03501643775918393\n",
      "train loss:0.15370819252560508\n",
      "train loss:0.09671310020849684\n",
      "train loss:0.1429928171204986\n",
      "train loss:0.136350261465659\n",
      "train loss:0.05614029240695261\n",
      "train loss:0.08037850750000201\n",
      "train loss:0.060480100745700406\n",
      "train loss:0.047232177365504634\n",
      "train loss:0.13676839562210735\n",
      "train loss:0.11909482120949458\n",
      "train loss:0.08204579137913269\n",
      "train loss:0.027242649582915446\n",
      "train loss:0.0625360904606826\n",
      "train loss:0.06102806756755814\n",
      "train loss:0.0501755441281279\n",
      "train loss:0.16123673379109899\n",
      "train loss:0.09675334427929291\n",
      "train loss:0.12439030710077834\n",
      "train loss:0.05704514569566657\n",
      "train loss:0.05372225163847614\n",
      "train loss:0.10896065023896576\n",
      "train loss:0.09974467768285229\n",
      "train loss:0.0584393322647857\n",
      "train loss:0.054556290972075615\n",
      "train loss:0.07203497259425296\n",
      "train loss:0.04877046692193934\n",
      "train loss:0.03947719060507846\n",
      "train loss:0.04026988945257836\n",
      "train loss:0.09818925157434309\n",
      "train loss:0.08075842420309139\n",
      "train loss:0.02638801342469488\n",
      "train loss:0.0461979120648687\n",
      "train loss:0.07404089245638773\n",
      "train loss:0.11017498842232082\n",
      "train loss:0.1362133278488568\n",
      "train loss:0.06795525359097417\n",
      "train loss:0.07151660251196972\n",
      "train loss:0.04796243396910451\n",
      "train loss:0.08469971827401655\n",
      "train loss:0.04047641124707074\n",
      "train loss:0.0434078067719331\n",
      "train loss:0.07084092753292684\n",
      "train loss:0.1532249098925022\n",
      "train loss:0.07055256348719385\n",
      "train loss:0.025219015167873504\n",
      "train loss:0.03887712076458256\n",
      "train loss:0.03316056388900533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11390339340966314\n",
      "train loss:0.07404857534110212\n",
      "train loss:0.14571637643594113\n",
      "train loss:0.05062364679136491\n",
      "train loss:0.03787140427960249\n",
      "train loss:0.06796818335624238\n",
      "train loss:0.04868135436367213\n",
      "train loss:0.06034482179977532\n",
      "train loss:0.07148498976210589\n",
      "train loss:0.05624147975536669\n",
      "train loss:0.07546859535450037\n",
      "train loss:0.051338697021603555\n",
      "train loss:0.09126782094765547\n",
      "train loss:0.10711844667679317\n",
      "train loss:0.10074727835390913\n",
      "train loss:0.05839706673343348\n",
      "train loss:0.06415617295295192\n",
      "train loss:0.08012752354178276\n",
      "train loss:0.20913424137791575\n",
      "train loss:0.09495938226367275\n",
      "train loss:0.055604415105714636\n",
      "train loss:0.04207244412678464\n",
      "train loss:0.0330512105282655\n",
      "train loss:0.0947830071649596\n",
      "train loss:0.04426318132043344\n",
      "train loss:0.05271389893172369\n",
      "train loss:0.05792526344111343\n",
      "train loss:0.049278774575035315\n",
      "train loss:0.09414014821777532\n",
      "train loss:0.04773705518653793\n",
      "train loss:0.07298338945009085\n",
      "train loss:0.03673272334846772\n",
      "train loss:0.03342480574590568\n",
      "train loss:0.02922241314165838\n",
      "train loss:0.04499126124419527\n",
      "train loss:0.07162353901124942\n",
      "train loss:0.04144199301493948\n",
      "train loss:0.05809246836358648\n",
      "train loss:0.11005895705638244\n",
      "train loss:0.03436428164724958\n",
      "train loss:0.09326913259682172\n",
      "train loss:0.03727647024653092\n",
      "train loss:0.04819265629863006\n",
      "train loss:0.1250523013536872\n",
      "train loss:0.057380230477953126\n",
      "train loss:0.15345951444684247\n",
      "train loss:0.09948919175179466\n",
      "train loss:0.030523688503993805\n",
      "train loss:0.041182725102342416\n",
      "train loss:0.043218547044580446\n",
      "train loss:0.0523406254501579\n",
      "train loss:0.07235281107294092\n",
      "train loss:0.08714231127677585\n",
      "train loss:0.07287723191895641\n",
      "train loss:0.08427865425888671\n",
      "train loss:0.10428244775528901\n",
      "train loss:0.08657720733090887\n",
      "train loss:0.06714436170618514\n",
      "train loss:0.10321869456405372\n",
      "train loss:0.12122186751936305\n",
      "train loss:0.15491043987714348\n",
      "train loss:0.0981762029051252\n",
      "train loss:0.13470307134619056\n",
      "train loss:0.060298189796703594\n",
      "train loss:0.14494474422856507\n",
      "train loss:0.07524510191502932\n",
      "train loss:0.10353196693164236\n",
      "train loss:0.08059954806038555\n",
      "train loss:0.13606646621866667\n",
      "train loss:0.08269969062396307\n",
      "train loss:0.09529246091504946\n",
      "train loss:0.03067717011183332\n",
      "train loss:0.04154760719254483\n",
      "train loss:0.02986831650043361\n",
      "train loss:0.07491614515125944\n",
      "train loss:0.14527945224817718\n",
      "train loss:0.024401046612888402\n",
      "train loss:0.06632520096479429\n",
      "train loss:0.24707753987218875\n",
      "train loss:0.17060124392209108\n",
      "train loss:0.044543839375132385\n",
      "train loss:0.08912799588038994\n",
      "train loss:0.09982401550069879\n",
      "train loss:0.0841938159178465\n",
      "train loss:0.03107398584497894\n",
      "train loss:0.06279758770451427\n",
      "train loss:0.0401735183319901\n",
      "train loss:0.06817185007041951\n",
      "train loss:0.088598147297396\n",
      "train loss:0.11698549000877266\n",
      "train loss:0.04085054576635969\n",
      "train loss:0.12936855707956119\n",
      "train loss:0.0629472451669111\n",
      "train loss:0.0470429820838006\n",
      "train loss:0.07517928857840316\n",
      "train loss:0.16618389026272173\n",
      "train loss:0.06578068454307694\n",
      "train loss:0.044250948042472246\n",
      "train loss:0.13982479773672324\n",
      "train loss:0.08224311054537853\n",
      "train loss:0.03994711320305136\n",
      "train loss:0.09060736783157688\n",
      "train loss:0.19955456809698127\n",
      "train loss:0.04042317540805348\n",
      "train loss:0.07998472089618926\n",
      "train loss:0.11310118642228038\n",
      "train loss:0.05576537500536041\n",
      "train loss:0.10921978389404746\n",
      "train loss:0.09085551160894476\n",
      "train loss:0.043915195022665075\n",
      "train loss:0.10903130877384604\n",
      "train loss:0.07903759877773421\n",
      "train loss:0.11923752396245069\n",
      "train loss:0.09732067551738784\n",
      "train loss:0.07070408126474213\n",
      "train loss:0.05300170298959525\n",
      "train loss:0.08385882267016907\n",
      "train loss:0.09896577955444086\n",
      "train loss:0.09954640746290881\n",
      "train loss:0.07976676503664765\n",
      "train loss:0.0889128143729084\n",
      "train loss:0.10126106809396163\n",
      "train loss:0.10293965061218055\n",
      "train loss:0.1089760379353143\n",
      "train loss:0.05840521338727112\n",
      "train loss:0.05090324939476022\n",
      "train loss:0.13263791690738247\n",
      "train loss:0.1021563973032012\n",
      "train loss:0.12006140958567872\n",
      "train loss:0.05106642506442252\n",
      "train loss:0.054594392921512844\n",
      "train loss:0.12990778453533344\n",
      "train loss:0.017615233494398138\n",
      "train loss:0.03961142635593361\n",
      "=== epoch:3, train acc:0.976, test acc:0.975 ===\n",
      "train loss:0.09838053362169114\n",
      "train loss:0.14420249950612532\n",
      "train loss:0.06762364333148295\n",
      "train loss:0.08551113012968806\n",
      "train loss:0.119628285074793\n",
      "train loss:0.07166704858713441\n",
      "train loss:0.09160518572268928\n",
      "train loss:0.1296492162046291\n",
      "train loss:0.08885500445334876\n",
      "train loss:0.10989771601023719\n",
      "train loss:0.08154678502803428\n",
      "train loss:0.024007426694121214\n",
      "train loss:0.11185626430598888\n",
      "train loss:0.03828718258557423\n",
      "train loss:0.0985516817222358\n",
      "train loss:0.053144165730336874\n",
      "train loss:0.06969265275528619\n",
      "train loss:0.06769510294606243\n",
      "train loss:0.05800023159019354\n",
      "train loss:0.0422019175251608\n",
      "train loss:0.053090705570290296\n",
      "train loss:0.054922314422386244\n",
      "train loss:0.10232344627518641\n",
      "train loss:0.059574104444579584\n",
      "train loss:0.04556388564927419\n",
      "train loss:0.09191709734704227\n",
      "train loss:0.04304915318627565\n",
      "train loss:0.08796091180425065\n",
      "train loss:0.03973181314554377\n",
      "train loss:0.051581922419604805\n",
      "train loss:0.0725429058576149\n",
      "train loss:0.06835091964511768\n",
      "train loss:0.04545879191803073\n",
      "train loss:0.12062749228031143\n",
      "train loss:0.06712244941341741\n",
      "train loss:0.0993899376947668\n",
      "train loss:0.0672277423568093\n",
      "train loss:0.0373622887330941\n",
      "train loss:0.024702365118531976\n",
      "train loss:0.05491668111071555\n",
      "train loss:0.07966396042559283\n",
      "train loss:0.09543534078394503\n",
      "train loss:0.06402012314502971\n",
      "train loss:0.06291040139917282\n",
      "train loss:0.042867883219858724\n",
      "train loss:0.046080647357195706\n",
      "train loss:0.026049790486814092\n",
      "train loss:0.14170307412296143\n",
      "train loss:0.03577741860794271\n",
      "train loss:0.03750064574473574\n",
      "train loss:0.03573797089920979\n",
      "train loss:0.05777452295898323\n",
      "train loss:0.13073350405006537\n",
      "train loss:0.0266499120968545\n",
      "train loss:0.04128279969039208\n",
      "train loss:0.08176879377083358\n",
      "train loss:0.0298634345083346\n",
      "train loss:0.04783646107712427\n",
      "train loss:0.09382339332298263\n",
      "train loss:0.019362925768323765\n",
      "train loss:0.05437934388963018\n",
      "train loss:0.06586198922988648\n",
      "train loss:0.08091065775388996\n",
      "train loss:0.04068440248479778\n",
      "train loss:0.04017397123466889\n",
      "train loss:0.0665109121099423\n",
      "train loss:0.04045902683482765\n",
      "train loss:0.013781786616758631\n",
      "train loss:0.02283564025422919\n",
      "train loss:0.0635444821573332\n",
      "train loss:0.020206252635232128\n",
      "train loss:0.04038230258970216\n",
      "train loss:0.14791667974625708\n",
      "train loss:0.01038397180357473\n",
      "train loss:0.09079189220220969\n",
      "train loss:0.11828120836248054\n",
      "train loss:0.041034177206436734\n",
      "train loss:0.06905342406185999\n",
      "train loss:0.07446933416478602\n",
      "train loss:0.05360549096185067\n",
      "train loss:0.1623859400403253\n",
      "train loss:0.07409437638591511\n",
      "train loss:0.06180704059697507\n",
      "train loss:0.07975249221641696\n",
      "train loss:0.07049506571667576\n",
      "train loss:0.07045292670243346\n",
      "train loss:0.038099928306568304\n",
      "train loss:0.03603346574288008\n",
      "train loss:0.03767030467490339\n",
      "train loss:0.11267362900677112\n",
      "train loss:0.09185357802913419\n",
      "train loss:0.047914224915086255\n",
      "train loss:0.1716531546349741\n",
      "train loss:0.040815335404276516\n",
      "train loss:0.07373654528061992\n",
      "train loss:0.059236360735790576\n",
      "train loss:0.03692620635564254\n",
      "train loss:0.038843186971084374\n",
      "train loss:0.08488892230517109\n",
      "train loss:0.08143192957355674\n",
      "train loss:0.10038696303380978\n",
      "train loss:0.08200903323264713\n",
      "train loss:0.05049720230707873\n",
      "train loss:0.0963694873151571\n",
      "train loss:0.1088284273998355\n",
      "train loss:0.038341478092650136\n",
      "train loss:0.02061360223890772\n",
      "train loss:0.09881601941301967\n",
      "train loss:0.029643471926210845\n",
      "train loss:0.14421530049833467\n",
      "train loss:0.12501691984278954\n",
      "train loss:0.04923802872071331\n",
      "train loss:0.16251891557660614\n",
      "train loss:0.03735147402783853\n",
      "train loss:0.059721979277542726\n",
      "train loss:0.07045066937760498\n",
      "train loss:0.05625879282647248\n",
      "train loss:0.05012202650701271\n",
      "train loss:0.11952705401772475\n",
      "train loss:0.10704813765353975\n",
      "train loss:0.07057252645704114\n",
      "train loss:0.06173831838569316\n",
      "train loss:0.037764696763928525\n",
      "train loss:0.07091262976178897\n",
      "train loss:0.04019890948627809\n",
      "train loss:0.05246562944162649\n",
      "train loss:0.1100972985884007\n",
      "train loss:0.05391061742581714\n",
      "train loss:0.03724220557190558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.038267864972078416\n",
      "train loss:0.08659743170159837\n",
      "train loss:0.05312538179520607\n",
      "train loss:0.06863408395647147\n",
      "train loss:0.05939731554444492\n",
      "train loss:0.054815628987354516\n",
      "train loss:0.015130776434829416\n",
      "train loss:0.12204008234335338\n",
      "train loss:0.05589075955909029\n",
      "train loss:0.05322172056448546\n",
      "train loss:0.034843293622980415\n",
      "train loss:0.024759971927989784\n",
      "train loss:0.07937015873166273\n",
      "train loss:0.06252258358575397\n",
      "train loss:0.03131077619574089\n",
      "train loss:0.022256801200795283\n",
      "train loss:0.07325187133927352\n",
      "train loss:0.015125196478826425\n",
      "train loss:0.050808774729089644\n",
      "train loss:0.029238873095196242\n",
      "train loss:0.06272077867485848\n",
      "train loss:0.0577494126615454\n",
      "train loss:0.07373406072482937\n",
      "train loss:0.10003181378707605\n",
      "train loss:0.04166536948384301\n",
      "train loss:0.061871676081488074\n",
      "train loss:0.08984820212506169\n",
      "train loss:0.049814416449674\n",
      "train loss:0.02320381288922759\n",
      "train loss:0.04708851821012769\n",
      "train loss:0.05440553431862811\n",
      "train loss:0.03348550405941582\n",
      "train loss:0.024461713428375203\n",
      "train loss:0.05808285960914417\n",
      "train loss:0.06404196087960146\n",
      "train loss:0.03732250736689011\n",
      "train loss:0.03541812368700041\n",
      "train loss:0.020414221761479535\n",
      "train loss:0.034510290773859816\n",
      "train loss:0.01844504770176228\n",
      "train loss:0.05366612641942753\n",
      "train loss:0.017037828155966706\n",
      "train loss:0.022726845495781915\n",
      "train loss:0.15171042068355356\n",
      "train loss:0.030215236732834945\n",
      "train loss:0.1037988962175319\n",
      "train loss:0.025360141516719583\n",
      "train loss:0.017165319289052273\n",
      "train loss:0.038090140190869703\n",
      "train loss:0.08138037457209726\n",
      "train loss:0.11100899366632482\n",
      "train loss:0.03199147840094873\n",
      "train loss:0.02496084836464108\n",
      "train loss:0.023649067894416925\n",
      "train loss:0.07563790426309212\n",
      "train loss:0.053590579581138185\n",
      "train loss:0.07718564583666171\n",
      "train loss:0.014523208969295097\n",
      "train loss:0.0935369520012632\n",
      "train loss:0.052177241276099975\n",
      "train loss:0.03917074616597942\n",
      "train loss:0.06951043881959387\n",
      "train loss:0.04104049653412558\n",
      "train loss:0.07930070510788961\n",
      "train loss:0.06463715965376415\n",
      "train loss:0.036639169007049575\n",
      "train loss:0.04536504777207539\n",
      "train loss:0.1244701775503335\n",
      "train loss:0.1380505048597388\n",
      "train loss:0.09035744309561869\n",
      "train loss:0.057997568008785055\n",
      "train loss:0.03859305927962287\n",
      "train loss:0.08316239625471768\n",
      "train loss:0.0836278968860645\n",
      "train loss:0.06723802189488313\n",
      "train loss:0.03788139950825889\n",
      "train loss:0.11862965343073378\n",
      "train loss:0.15050439091439913\n",
      "train loss:0.09607666766059561\n",
      "train loss:0.14635640695599986\n",
      "train loss:0.05348405854379405\n",
      "train loss:0.15365893267056469\n",
      "train loss:0.09199337830662063\n",
      "train loss:0.051423414514140384\n",
      "train loss:0.011051717237361034\n",
      "train loss:0.056415265406521434\n",
      "train loss:0.09402548356599207\n",
      "train loss:0.18788757429022063\n",
      "train loss:0.0970365700869834\n",
      "train loss:0.043059155259145075\n",
      "train loss:0.0560410448860914\n",
      "train loss:0.0908056690666119\n",
      "train loss:0.05992745428573097\n",
      "train loss:0.016698040818702253\n",
      "train loss:0.04349713592298924\n",
      "train loss:0.08973166668803544\n",
      "train loss:0.1183317374591702\n",
      "train loss:0.06046439778777212\n",
      "train loss:0.028504857997660685\n",
      "train loss:0.03051468034019122\n",
      "train loss:0.07150131053470457\n",
      "train loss:0.03636269648013898\n",
      "train loss:0.03010695197456343\n",
      "train loss:0.04233249254665394\n",
      "train loss:0.0583442120661531\n",
      "train loss:0.035751621280647614\n",
      "train loss:0.03882322804631751\n",
      "train loss:0.04914634840230298\n",
      "train loss:0.035150608384248605\n",
      "train loss:0.15228480345478201\n",
      "train loss:0.09621151359985655\n",
      "train loss:0.13750150126061397\n",
      "train loss:0.045886214901107406\n",
      "train loss:0.07995277429717003\n",
      "train loss:0.1003009134516817\n",
      "train loss:0.054253959337688444\n",
      "train loss:0.046888816786633924\n",
      "train loss:0.1749871302405652\n",
      "train loss:0.08379259075408768\n",
      "train loss:0.0635970141149838\n",
      "train loss:0.0751373757405997\n",
      "train loss:0.0458283495969902\n",
      "train loss:0.051589069054028186\n",
      "train loss:0.10832183211705741\n",
      "train loss:0.055711438655958005\n",
      "train loss:0.03611422956249485\n",
      "train loss:0.09860777011534572\n",
      "train loss:0.11708955760177953\n",
      "train loss:0.11604202252252568\n",
      "train loss:0.1110452050121775\n",
      "train loss:0.09792618210906623\n",
      "train loss:0.09062295438629044\n",
      "train loss:0.03435740378662832\n",
      "train loss:0.02657672225094563\n",
      "train loss:0.04258641432641867\n",
      "train loss:0.08517150055799609\n",
      "train loss:0.04902279190082967\n",
      "train loss:0.03910814784019244\n",
      "train loss:0.03249509863145977\n",
      "train loss:0.03550300294219197\n",
      "train loss:0.08049921881394384\n",
      "train loss:0.017800647148052136\n",
      "train loss:0.04086586176297301\n",
      "train loss:0.06265763756978983\n",
      "train loss:0.01960028131532214\n",
      "train loss:0.04384877194014106\n",
      "train loss:0.09179657996426097\n",
      "train loss:0.03972867380135306\n",
      "train loss:0.024794012108154014\n",
      "train loss:0.05508119366517237\n",
      "train loss:0.027808420563166923\n",
      "train loss:0.028284350105241152\n",
      "train loss:0.043631784645460144\n",
      "train loss:0.0999116785070955\n",
      "train loss:0.09779725450316404\n",
      "train loss:0.07294999035552291\n",
      "train loss:0.035600070437944234\n",
      "train loss:0.0333959276760834\n",
      "train loss:0.017995271475384777\n",
      "train loss:0.04941229063218259\n",
      "train loss:0.15846528529184703\n",
      "train loss:0.05362020711819722\n",
      "train loss:0.07028020158996416\n",
      "train loss:0.07553640442032797\n",
      "train loss:0.05080081945463597\n",
      "train loss:0.03624684690521252\n",
      "train loss:0.025178477773389645\n",
      "train loss:0.03447692218704033\n",
      "train loss:0.051929871368642744\n",
      "train loss:0.04684875105323038\n",
      "train loss:0.035672939650937555\n",
      "train loss:0.03384187029106558\n",
      "train loss:0.04167296710756457\n",
      "train loss:0.042216178524338205\n",
      "train loss:0.08357506329017593\n",
      "train loss:0.07640480431469088\n",
      "train loss:0.025054677352731765\n",
      "train loss:0.05868855758236653\n",
      "train loss:0.022289429719023632\n",
      "train loss:0.08522665170857673\n",
      "train loss:0.024619655751350895\n",
      "train loss:0.04336926794278797\n",
      "train loss:0.12276569821517512\n",
      "train loss:0.07565047949615131\n",
      "train loss:0.06691406308289329\n",
      "train loss:0.08096548397005945\n",
      "train loss:0.10828947413172743\n",
      "train loss:0.05728901950809932\n",
      "train loss:0.07487301153117257\n",
      "train loss:0.037696264073804185\n",
      "train loss:0.0412892196425054\n",
      "train loss:0.09588377559959127\n",
      "train loss:0.05084675422714204\n",
      "train loss:0.05083213598953563\n",
      "train loss:0.01636222855821364\n",
      "train loss:0.10207416965882164\n",
      "train loss:0.05245574180685576\n",
      "train loss:0.020962699826710587\n",
      "train loss:0.08258653050708549\n",
      "train loss:0.0394486538553301\n",
      "train loss:0.021733994358844405\n",
      "train loss:0.10997954455213663\n",
      "train loss:0.13670810307457226\n",
      "train loss:0.028779207937906594\n",
      "train loss:0.0380197591275454\n",
      "train loss:0.06792877471146162\n",
      "train loss:0.055921429176225085\n",
      "train loss:0.04113779274244425\n",
      "train loss:0.021764495228785864\n",
      "train loss:0.04800371904414165\n",
      "train loss:0.04946616265203863\n",
      "train loss:0.02685787977842384\n",
      "train loss:0.06244396072725108\n",
      "train loss:0.057545253583595295\n",
      "train loss:0.07562359558610753\n",
      "train loss:0.10932707819979003\n",
      "train loss:0.028176448249313327\n",
      "train loss:0.03457808641730697\n",
      "train loss:0.056985763175587734\n",
      "train loss:0.02037019792997818\n",
      "train loss:0.05433507595568031\n",
      "train loss:0.04337174811095153\n",
      "train loss:0.11372075303295962\n",
      "train loss:0.10723605320601794\n",
      "train loss:0.2170867401863721\n",
      "train loss:0.06062412076342474\n",
      "train loss:0.04126169092755914\n",
      "train loss:0.016448178049585004\n",
      "train loss:0.0183020607815437\n",
      "train loss:0.036458669167872985\n",
      "train loss:0.0336206238302587\n",
      "train loss:0.07358229952865068\n",
      "train loss:0.10066312033051524\n",
      "train loss:0.05040958639702445\n",
      "train loss:0.008104838788086427\n",
      "train loss:0.07384142146099734\n",
      "train loss:0.036729642507162936\n",
      "train loss:0.03626459414566908\n",
      "train loss:0.030708170253711305\n",
      "train loss:0.02589314204291394\n",
      "train loss:0.1134588188179147\n",
      "train loss:0.027091959362481984\n",
      "train loss:0.0777100858438701\n",
      "train loss:0.05655915558976032\n",
      "train loss:0.06064506543447565\n",
      "train loss:0.14091414645522687\n",
      "train loss:0.07954169443964255\n",
      "train loss:0.03033823036354599\n",
      "train loss:0.04676544652675887\n",
      "train loss:0.03305271589637866\n",
      "train loss:0.0410251351940585\n",
      "train loss:0.06803299943217861\n",
      "train loss:0.055273070733051995\n",
      "train loss:0.03231054236287114\n",
      "train loss:0.07602863624011345\n",
      "train loss:0.07441704446290605\n",
      "train loss:0.04426733382280723\n",
      "train loss:0.028640074637916894\n",
      "train loss:0.03773179703502507\n",
      "train loss:0.03811732010021616\n",
      "train loss:0.04837990792860449\n",
      "train loss:0.05592722358684348\n",
      "train loss:0.1469084456969804\n",
      "train loss:0.04787952098250126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014058543282520463\n",
      "train loss:0.04290185105951785\n",
      "train loss:0.04615096971182771\n",
      "train loss:0.0470005007746603\n",
      "train loss:0.10299077125542533\n",
      "train loss:0.02783285238250517\n",
      "train loss:0.061505548598383204\n",
      "train loss:0.020526569475930304\n",
      "train loss:0.04458276782180366\n",
      "train loss:0.018553204118034194\n",
      "train loss:0.019930216188411558\n",
      "train loss:0.062190765725037636\n",
      "train loss:0.0346522358258002\n",
      "train loss:0.15234200316841387\n",
      "train loss:0.053369395975020384\n",
      "train loss:0.029372664501892232\n",
      "train loss:0.021909571887170274\n",
      "train loss:0.033918464113254686\n",
      "train loss:0.04566382832033012\n",
      "train loss:0.05282734174971969\n",
      "train loss:0.02528333014570564\n",
      "train loss:0.049194239432697684\n",
      "train loss:0.05795227546388719\n",
      "train loss:0.040805490000138084\n",
      "train loss:0.058917591961125136\n",
      "train loss:0.05541497193804223\n",
      "train loss:0.07287989213555097\n",
      "train loss:0.03978737970470967\n",
      "train loss:0.025701579494008645\n",
      "train loss:0.04493667134573626\n",
      "train loss:0.1264744512551422\n",
      "train loss:0.01419241602452889\n",
      "train loss:0.0750644155495607\n",
      "train loss:0.05299564008021393\n",
      "train loss:0.045761344404316597\n",
      "train loss:0.09393699903068653\n",
      "train loss:0.033941340478910974\n",
      "train loss:0.09308457933146345\n",
      "train loss:0.06654071462921322\n",
      "train loss:0.02940836449111268\n",
      "train loss:0.030200738110487717\n",
      "train loss:0.03171083235321452\n",
      "train loss:0.08573510508153159\n",
      "train loss:0.03156202023696307\n",
      "train loss:0.14441239199301742\n",
      "train loss:0.09384187589041833\n",
      "train loss:0.036120835877634046\n",
      "train loss:0.040770723532395366\n",
      "train loss:0.045235492033367714\n",
      "train loss:0.03628285971946359\n",
      "train loss:0.10474256152571725\n",
      "train loss:0.027821218441739584\n",
      "train loss:0.03341302681398415\n",
      "train loss:0.03754447169371146\n",
      "train loss:0.05846112579172931\n",
      "train loss:0.04017165037286175\n",
      "train loss:0.04186514723613742\n",
      "train loss:0.08485803790999244\n",
      "train loss:0.03120501343310476\n",
      "train loss:0.07466248643508008\n",
      "train loss:0.036343278699886274\n",
      "train loss:0.02479545154719579\n",
      "train loss:0.07492671126044965\n",
      "train loss:0.017518320256842083\n",
      "train loss:0.09762967585252452\n",
      "train loss:0.08713357625582532\n",
      "train loss:0.12831766128885788\n",
      "train loss:0.02190078991935573\n",
      "train loss:0.017543300087491328\n",
      "train loss:0.012494197243943527\n",
      "train loss:0.029517976415965506\n",
      "train loss:0.03346737229906956\n",
      "train loss:0.03411747783046036\n",
      "train loss:0.059461337377612195\n",
      "train loss:0.05694233828724675\n",
      "train loss:0.05470315372817284\n",
      "train loss:0.024767959898776747\n",
      "train loss:0.022623642984064954\n",
      "train loss:0.1667562733743712\n",
      "train loss:0.03832817562276353\n",
      "train loss:0.04804990140541876\n",
      "train loss:0.03047172258083535\n",
      "train loss:0.03664628099706824\n",
      "train loss:0.024094908133309646\n",
      "train loss:0.026029806517796943\n",
      "train loss:0.06378046891192211\n",
      "train loss:0.005153087732721131\n",
      "train loss:0.02761593671833537\n",
      "train loss:0.04430814176246101\n",
      "train loss:0.058152366931015435\n",
      "train loss:0.037046281421510466\n",
      "train loss:0.03288724491609306\n",
      "train loss:0.07933105959257271\n",
      "train loss:0.07272047300605683\n",
      "train loss:0.06105920538427861\n",
      "train loss:0.09219549188752695\n",
      "train loss:0.07618052009997396\n",
      "train loss:0.05063735213791081\n",
      "train loss:0.20064741579205095\n",
      "train loss:0.06552162885944646\n",
      "train loss:0.013349024832116608\n",
      "train loss:0.14755091946471502\n",
      "train loss:0.03445515205657872\n",
      "train loss:0.023387570965516958\n",
      "train loss:0.008464586073053386\n",
      "train loss:0.037392905860672655\n",
      "train loss:0.0478311550053368\n",
      "train loss:0.03467902364626259\n",
      "train loss:0.054097621250389735\n",
      "train loss:0.02777865487197799\n",
      "train loss:0.00963558674191095\n",
      "train loss:0.10007462349701207\n",
      "train loss:0.00996975154688951\n",
      "train loss:0.04336742199997809\n",
      "train loss:0.031556768506182\n",
      "train loss:0.08774595143670579\n",
      "train loss:0.028865345790764708\n",
      "train loss:0.04895671096410527\n",
      "train loss:0.029297771486913503\n",
      "train loss:0.04963786446552839\n",
      "train loss:0.023098448373033084\n",
      "train loss:0.0338909714369486\n",
      "train loss:0.02549516923160024\n",
      "train loss:0.014794222700515357\n",
      "train loss:0.1646413145579942\n",
      "train loss:0.048571887955213826\n",
      "train loss:0.034482011660326266\n",
      "train loss:0.08681676660422978\n",
      "train loss:0.036164388341519714\n",
      "train loss:0.024138960145854836\n",
      "train loss:0.03261156884131729\n",
      "train loss:0.05974995131560118\n",
      "train loss:0.031601524950878875\n",
      "train loss:0.14617066892119968\n",
      "train loss:0.026491409846054147\n",
      "train loss:0.021073595473428672\n",
      "train loss:0.0604112400065171\n",
      "train loss:0.06041890711226453\n",
      "train loss:0.08682414279159616\n",
      "train loss:0.058411303949579746\n",
      "train loss:0.03862923673530169\n",
      "train loss:0.0597020577780298\n",
      "train loss:0.02973095414359284\n",
      "train loss:0.10237315173299302\n",
      "train loss:0.08480500069670635\n",
      "train loss:0.07942080424311461\n",
      "train loss:0.03590024580140643\n",
      "train loss:0.014089181680430204\n",
      "train loss:0.030172385912316937\n",
      "train loss:0.09836019553663258\n",
      "train loss:0.07842246777218918\n",
      "train loss:0.047444827725015334\n",
      "train loss:0.025250259748212257\n",
      "train loss:0.05965855499339181\n",
      "train loss:0.03253574312831384\n",
      "train loss:0.023428957285862046\n",
      "train loss:0.06862643303996883\n",
      "train loss:0.023085653939750636\n",
      "train loss:0.08864892215343395\n",
      "train loss:0.06706199937821633\n",
      "train loss:0.02599666472420548\n",
      "train loss:0.03627593322640158\n",
      "train loss:0.0693944377129674\n",
      "train loss:0.029925742915455526\n",
      "train loss:0.03417991984193112\n",
      "train loss:0.07962084244957922\n",
      "train loss:0.04263375520916811\n",
      "train loss:0.04985072886502714\n",
      "train loss:0.017162001391227005\n",
      "train loss:0.029660683290292086\n",
      "train loss:0.00815401116023697\n",
      "train loss:0.10313524560741419\n",
      "train loss:0.0819327357660211\n",
      "train loss:0.028487346351991974\n",
      "train loss:0.09742405952837917\n",
      "train loss:0.14839579227342495\n",
      "train loss:0.028160099470586\n",
      "train loss:0.060344729835471254\n",
      "train loss:0.053695218229886564\n",
      "train loss:0.011940224156976298\n",
      "train loss:0.1375627879370602\n",
      "train loss:0.05733210784230013\n",
      "train loss:0.095688585998638\n",
      "train loss:0.05331371022091793\n",
      "train loss:0.035509983474509774\n",
      "train loss:0.01702624199869955\n",
      "train loss:0.015855387182361375\n",
      "train loss:0.02739160123966555\n",
      "train loss:0.07416256191515176\n",
      "train loss:0.10051517866178118\n",
      "train loss:0.01226976978193115\n",
      "train loss:0.022322138490759983\n",
      "train loss:0.034406896121534\n",
      "train loss:0.03709088677461874\n",
      "train loss:0.05824296037151275\n",
      "train loss:0.058275449698466444\n",
      "train loss:0.023041892727399836\n",
      "train loss:0.025040082210943008\n",
      "train loss:0.038529672975448376\n",
      "train loss:0.0377155620149218\n",
      "train loss:0.05179677829376949\n",
      "train loss:0.05554725639030285\n",
      "train loss:0.06894935013854737\n",
      "train loss:0.04520804435959825\n",
      "train loss:0.010046627415087692\n",
      "train loss:0.060091942157326494\n",
      "train loss:0.05640501741879867\n",
      "=== epoch:4, train acc:0.979, test acc:0.98 ===\n",
      "train loss:0.07181647255077059\n",
      "train loss:0.031251097859681415\n",
      "train loss:0.06733688834544532\n",
      "train loss:0.02558383110862786\n",
      "train loss:0.01911290741840237\n",
      "train loss:0.0487747965842922\n",
      "train loss:0.035934681562204494\n",
      "train loss:0.06978593876202865\n",
      "train loss:0.042319590293239756\n",
      "train loss:0.02884422142619377\n",
      "train loss:0.021767557166873636\n",
      "train loss:0.05394848091020756\n",
      "train loss:0.15482037156149775\n",
      "train loss:0.06133362119498611\n",
      "train loss:0.07695844380165937\n",
      "train loss:0.04749298755910759\n",
      "train loss:0.04849797707003947\n",
      "train loss:0.09734054308484716\n",
      "train loss:0.014794864724570334\n",
      "train loss:0.07587610153531674\n",
      "train loss:0.0714312791406528\n",
      "train loss:0.04497253767012042\n",
      "train loss:0.019850495388917946\n",
      "train loss:0.026904181704168466\n",
      "train loss:0.07290474552428611\n",
      "train loss:0.05751344284079279\n",
      "train loss:0.09716904381613181\n",
      "train loss:0.03224344763838625\n",
      "train loss:0.043028250670112914\n",
      "train loss:0.04559115169028447\n",
      "train loss:0.04849519156298277\n",
      "train loss:0.03971704942749228\n",
      "train loss:0.020876903923533755\n",
      "train loss:0.07088944042009077\n",
      "train loss:0.048730053718990085\n",
      "train loss:0.07028581862568484\n",
      "train loss:0.03046238097224818\n",
      "train loss:0.012144264257145017\n",
      "train loss:0.10841065312771905\n",
      "train loss:0.15744878132574933\n",
      "train loss:0.07980988936415406\n",
      "train loss:0.04370105914982228\n",
      "train loss:0.04230624175419737\n",
      "train loss:0.07046824186236064\n",
      "train loss:0.024768751527176506\n",
      "train loss:0.11713841088690505\n",
      "train loss:0.057681155311615856\n",
      "train loss:0.02069504151085978\n",
      "train loss:0.01659444730802811\n",
      "train loss:0.0349818754871781\n",
      "train loss:0.013329357054295752\n",
      "train loss:0.07391910608442387\n",
      "train loss:0.05694656306991637\n",
      "train loss:0.020578346164477623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026741307933067\n",
      "train loss:0.015128882251329683\n",
      "train loss:0.02839967100341835\n",
      "train loss:0.07832822397804107\n",
      "train loss:0.05475707575230591\n",
      "train loss:0.03705451518686787\n",
      "train loss:0.01598743295356048\n",
      "train loss:0.02037016093040308\n",
      "train loss:0.029689376620743876\n",
      "train loss:0.06766618230606382\n",
      "train loss:0.02241238300314387\n",
      "train loss:0.02228019278290519\n",
      "train loss:0.02968867382347792\n",
      "train loss:0.05758035484308924\n",
      "train loss:0.03608386328648187\n",
      "train loss:0.07743710515489692\n",
      "train loss:0.06472513070176306\n",
      "train loss:0.0442739841896152\n",
      "train loss:0.08234191032336159\n",
      "train loss:0.04618719268318495\n",
      "train loss:0.022127966228900783\n",
      "train loss:0.034434362825107964\n",
      "train loss:0.0232494088603078\n",
      "train loss:0.049996066597914134\n",
      "train loss:0.07668859795990655\n",
      "train loss:0.03539597294952697\n",
      "train loss:0.019643023392102908\n",
      "train loss:0.015706987894750203\n",
      "train loss:0.05626623799296343\n",
      "train loss:0.015568740389037473\n",
      "train loss:0.1140677746149079\n",
      "train loss:0.11886836804602377\n",
      "train loss:0.04330317320172247\n",
      "train loss:0.03214709771445968\n",
      "train loss:0.17404767826823594\n",
      "train loss:0.018148693195166675\n",
      "train loss:0.03862200007972888\n",
      "train loss:0.04362795707757554\n",
      "train loss:0.028964187309190613\n",
      "train loss:0.013399004110944452\n",
      "train loss:0.08151206370297802\n",
      "train loss:0.049971331509740986\n",
      "train loss:0.017150555660894698\n",
      "train loss:0.05677376122514024\n",
      "train loss:0.015123913672926563\n",
      "train loss:0.037248934474244655\n",
      "train loss:0.12194291573444835\n",
      "train loss:0.06652342965757212\n",
      "train loss:0.013520951925456883\n",
      "train loss:0.04133279565181405\n",
      "train loss:0.07350183087187165\n",
      "train loss:0.09008373645727254\n",
      "train loss:0.05614766197309048\n",
      "train loss:0.03185010092648848\n",
      "train loss:0.07763287138591755\n",
      "train loss:0.05520753848457152\n",
      "train loss:0.05642262884498657\n",
      "train loss:0.0763866388096526\n",
      "train loss:0.019889008507548406\n",
      "train loss:0.016019334959480297\n",
      "train loss:0.0396492245335491\n",
      "train loss:0.024900447852365084\n",
      "train loss:0.019439267089389634\n",
      "train loss:0.037468572250594134\n",
      "train loss:0.06367206715044767\n",
      "train loss:0.04611289816171707\n",
      "train loss:0.024543630743691813\n",
      "train loss:0.05872614918707732\n",
      "train loss:0.03438611116311696\n",
      "train loss:0.01764802088981379\n",
      "train loss:0.05087738502229298\n",
      "train loss:0.06526372364756923\n",
      "train loss:0.034339896379770536\n",
      "train loss:0.07049254247109596\n",
      "train loss:0.09358825165131215\n",
      "train loss:0.06768170553360717\n",
      "train loss:0.09474978646148013\n",
      "train loss:0.09483614381322326\n",
      "train loss:0.04778543998798734\n",
      "train loss:0.03922380731240754\n",
      "train loss:0.015214439118113838\n",
      "train loss:0.027108627176763843\n",
      "train loss:0.05676438194190063\n",
      "train loss:0.07738119763932814\n",
      "train loss:0.020785355483298427\n",
      "train loss:0.025594054397982825\n",
      "train loss:0.04181421946151102\n",
      "train loss:0.03744012566588324\n",
      "train loss:0.025922656049108386\n",
      "train loss:0.15749799266561526\n",
      "train loss:0.013993825657876118\n",
      "train loss:0.06975735008442206\n",
      "train loss:0.046884789847218666\n",
      "train loss:0.03805955084021899\n",
      "train loss:0.050231660544277565\n",
      "train loss:0.09956280178055887\n",
      "train loss:0.03534449817056114\n",
      "train loss:0.0323729631737174\n",
      "train loss:0.07028765911795815\n",
      "train loss:0.030889800260263972\n",
      "train loss:0.08823289043136677\n",
      "train loss:0.03747316210208003\n",
      "train loss:0.017789067450318576\n",
      "train loss:0.10391411149019399\n",
      "train loss:0.018352305401412906\n",
      "train loss:0.047796844272880216\n",
      "train loss:0.0584826065412693\n",
      "train loss:0.06621962599697552\n",
      "train loss:0.058851176358784764\n",
      "train loss:0.013770976384652779\n",
      "train loss:0.1007968585177685\n",
      "train loss:0.013860160318872985\n",
      "train loss:0.03487730769377802\n",
      "train loss:0.03851357838391363\n",
      "train loss:0.011697296277115155\n",
      "train loss:0.029438752658850223\n",
      "train loss:0.05519451907620497\n",
      "train loss:0.08874161276006325\n",
      "train loss:0.044927014340830275\n",
      "train loss:0.05668474709764104\n",
      "train loss:0.022103455546148655\n",
      "train loss:0.024553310353468364\n",
      "train loss:0.023256718633774275\n",
      "train loss:0.07969995074177745\n",
      "train loss:0.04397695773662049\n",
      "train loss:0.04109510185709701\n",
      "train loss:0.04346355080889217\n",
      "train loss:0.024942635652535426\n",
      "train loss:0.030620057287794183\n",
      "train loss:0.044165884041708854\n",
      "train loss:0.023713130493609094\n",
      "train loss:0.040604577887293714\n",
      "train loss:0.06545041153639194\n",
      "train loss:0.025697843084366415\n",
      "train loss:0.05278989491860593\n",
      "train loss:0.01910781312721719\n",
      "train loss:0.09244558221468255\n",
      "train loss:0.08625906496453128\n",
      "train loss:0.10145935513850349\n",
      "train loss:0.0193759670289249\n",
      "train loss:0.015789175778366235\n",
      "train loss:0.017906092809672355\n",
      "train loss:0.08477611749710212\n",
      "train loss:0.03153826654125097\n",
      "train loss:0.012423190479583126\n",
      "train loss:0.01725116317847752\n",
      "train loss:0.03416347126831201\n",
      "train loss:0.035112601856143885\n",
      "train loss:0.028416755680646756\n",
      "train loss:0.03865917470368351\n",
      "train loss:0.04772957536103894\n",
      "train loss:0.04054579360366357\n",
      "train loss:0.04182165438132693\n",
      "train loss:0.008086415702938917\n",
      "train loss:0.058710363920296486\n",
      "train loss:0.03843478570949721\n",
      "train loss:0.025146249709340793\n",
      "train loss:0.04643116083196148\n",
      "train loss:0.013712594130096569\n",
      "train loss:0.04034653507460718\n",
      "train loss:0.04466951679685579\n",
      "train loss:0.025007507813799405\n",
      "train loss:0.0976981635195385\n",
      "train loss:0.043698494083527016\n",
      "train loss:0.07900829732716201\n",
      "train loss:0.040126028154605996\n",
      "train loss:0.07082288753357725\n",
      "train loss:0.007582707302620132\n",
      "train loss:0.013072983378887596\n",
      "train loss:0.04484936598068659\n",
      "train loss:0.056297908172496164\n",
      "train loss:0.004145942481501098\n",
      "train loss:0.022382149753398667\n",
      "train loss:0.03281945967463289\n",
      "train loss:0.02195077494038249\n",
      "train loss:0.042652861739071415\n",
      "train loss:0.04773536264447467\n",
      "train loss:0.025251935080771393\n",
      "train loss:0.021979275677451553\n",
      "train loss:0.016263214013179213\n",
      "train loss:0.09680512123694142\n",
      "train loss:0.03096267277464591\n",
      "train loss:0.03480033171204098\n",
      "train loss:0.03156045750682014\n",
      "train loss:0.017654387537591288\n",
      "train loss:0.015926115020804696\n",
      "train loss:0.023397984889908345\n",
      "train loss:0.04185345226559246\n",
      "train loss:0.06273595608360238\n",
      "train loss:0.010045551397773113\n",
      "train loss:0.060063975439287216\n",
      "train loss:0.02080320350741148\n",
      "train loss:0.027589097787289955\n",
      "train loss:0.03579246562001033\n",
      "train loss:0.0713903798620389\n",
      "train loss:0.05313809734938041\n",
      "train loss:0.05422111468971693\n",
      "train loss:0.02306089158662443\n",
      "train loss:0.021455431945836392\n",
      "train loss:0.01984640520561104\n",
      "train loss:0.068934899240364\n",
      "train loss:0.06493111185490077\n",
      "train loss:0.049263597868381775\n",
      "train loss:0.04411804310160019\n",
      "train loss:0.06756903519881835\n",
      "train loss:0.07348124934722838\n",
      "train loss:0.052803162491792205\n",
      "train loss:0.03409171689519954\n",
      "train loss:0.10625853854489806\n",
      "train loss:0.05868938911248956\n",
      "train loss:0.021328712263791818\n",
      "train loss:0.007902176970774659\n",
      "train loss:0.007580029369918273\n",
      "train loss:0.032428918152029015\n",
      "train loss:0.019274574351669273\n",
      "train loss:0.010947101868502286\n",
      "train loss:0.026097285250527253\n",
      "train loss:0.0187219473022953\n",
      "train loss:0.022931021912963798\n",
      "train loss:0.03373780296090114\n",
      "train loss:0.10679935370764744\n",
      "train loss:0.11797037252769949\n",
      "train loss:0.08055477472404154\n",
      "train loss:0.10763564104334362\n",
      "train loss:0.018881556203558216\n",
      "train loss:0.1394048091752281\n",
      "train loss:0.038786732319234\n",
      "train loss:0.03416688987359742\n",
      "train loss:0.053831890426977516\n",
      "train loss:0.01586794409447955\n",
      "train loss:0.06771576728366503\n",
      "train loss:0.016976220075243315\n",
      "train loss:0.06628144754803349\n",
      "train loss:0.012508565730252622\n",
      "train loss:0.042184969178937506\n",
      "train loss:0.032210068720684375\n",
      "train loss:0.08258743618149478\n",
      "train loss:0.047432077040594545\n",
      "train loss:0.07553150680997428\n",
      "train loss:0.06926744686926954\n",
      "train loss:0.008231122312342399\n",
      "train loss:0.017411242516317062\n",
      "train loss:0.07622826399360243\n",
      "train loss:0.03636352894612998\n",
      "train loss:0.01337047116242977\n",
      "train loss:0.07121369849352929\n",
      "train loss:0.10562631045334317\n",
      "train loss:0.05811273909423851\n",
      "train loss:0.05507536387336169\n",
      "train loss:0.04484551293022518\n",
      "train loss:0.0282469098617361\n",
      "train loss:0.12180804611644935\n",
      "train loss:0.06114271190217847\n",
      "train loss:0.013798450642172111\n",
      "train loss:0.037124726819114696\n",
      "train loss:0.029873944224005987\n",
      "train loss:0.04296169947609212\n",
      "train loss:0.042035382479324805\n",
      "train loss:0.019671345847568286\n",
      "train loss:0.03972199878849006\n",
      "train loss:0.07302803946037542\n",
      "train loss:0.038098858555952436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.021806938598378695\n",
      "train loss:0.03476746599403493\n",
      "train loss:0.047073543908021716\n",
      "train loss:0.06546971767560884\n",
      "train loss:0.07319012912118394\n",
      "train loss:0.029183036493499303\n",
      "train loss:0.025997730993169207\n",
      "train loss:0.030119428751674816\n",
      "train loss:0.018967542467376995\n",
      "train loss:0.015919040101050014\n",
      "train loss:0.02548124205221653\n",
      "train loss:0.028590781289609762\n",
      "train loss:0.01075245998956637\n",
      "train loss:0.025393284529917917\n",
      "train loss:0.051220385353868234\n",
      "train loss:0.028935007058236817\n",
      "train loss:0.030293968404488027\n",
      "train loss:0.015933580021206234\n",
      "train loss:0.01716890066766183\n",
      "train loss:0.04208855334673855\n",
      "train loss:0.07984155959790684\n",
      "train loss:0.03413848091441059\n",
      "train loss:0.07310728772906701\n",
      "train loss:0.05793269737782244\n",
      "train loss:0.04596980257878777\n",
      "train loss:0.012318801764456188\n",
      "train loss:0.0318089233450004\n",
      "train loss:0.07583966642251799\n",
      "train loss:0.06899043976759352\n",
      "train loss:0.025078390797670772\n",
      "train loss:0.06287677234279312\n",
      "train loss:0.05621491322685016\n",
      "train loss:0.011498893672202526\n",
      "train loss:0.033048512526212305\n",
      "train loss:0.024861903030929913\n",
      "train loss:0.04180166641393201\n",
      "train loss:0.005082681801659585\n",
      "train loss:0.022627520833812184\n",
      "train loss:0.03581799711106513\n",
      "train loss:0.024750384306049728\n",
      "train loss:0.01600154540902332\n",
      "train loss:0.003955726227784977\n",
      "train loss:0.032182534628446675\n",
      "train loss:0.020180411921001458\n",
      "train loss:0.01576550731342911\n",
      "train loss:0.056024771922528485\n",
      "train loss:0.03104666971834534\n",
      "train loss:0.044136613526764734\n",
      "train loss:0.013022629416569035\n",
      "train loss:0.017322858464490613\n",
      "train loss:0.07511452039125127\n",
      "train loss:0.02295384372941738\n",
      "train loss:0.07853899214239063\n",
      "train loss:0.03231109215788084\n",
      "train loss:0.04159535880375131\n",
      "train loss:0.04198047320658287\n",
      "train loss:0.01520393895829686\n",
      "train loss:0.028679615725001453\n",
      "train loss:0.05498304013777336\n",
      "train loss:0.012278606055996948\n",
      "train loss:0.012239637764019741\n",
      "train loss:0.015415147787903712\n",
      "train loss:0.1104384570745828\n",
      "train loss:0.021380288958904155\n",
      "train loss:0.007555210966380812\n",
      "train loss:0.06863989865898261\n",
      "train loss:0.07973282353842327\n",
      "train loss:0.04281403481867071\n",
      "train loss:0.03373598785719539\n",
      "train loss:0.028243282561421442\n",
      "train loss:0.014564486192956234\n",
      "train loss:0.022585465464314572\n",
      "train loss:0.021092909376863495\n",
      "train loss:0.051256832418069526\n",
      "train loss:0.007097150926477714\n",
      "train loss:0.060337235005845626\n",
      "train loss:0.019895486294196064\n",
      "train loss:0.03310551295350963\n",
      "train loss:0.006976083352636816\n",
      "train loss:0.01749331028653211\n",
      "train loss:0.09201030800527303\n",
      "train loss:0.07455910507899476\n",
      "train loss:0.03145373074542974\n",
      "train loss:0.027934825490041698\n",
      "train loss:0.021864106916378703\n",
      "train loss:0.025548564515542854\n",
      "train loss:0.04322242747810909\n",
      "train loss:0.020057668441627444\n",
      "train loss:0.0648120366076966\n",
      "train loss:0.007068329227607512\n",
      "train loss:0.026433859085362797\n",
      "train loss:0.013875423593240692\n",
      "train loss:0.027173137951767515\n",
      "train loss:0.04368328802228644\n",
      "train loss:0.034711964619660376\n",
      "train loss:0.04571854880938481\n",
      "train loss:0.02216043742056401\n",
      "train loss:0.057126364128110584\n",
      "train loss:0.019864002483760187\n",
      "train loss:0.025110608361832085\n",
      "train loss:0.005876972834242363\n",
      "train loss:0.037689715973887594\n",
      "train loss:0.05900938233778407\n",
      "train loss:0.014691188109010005\n",
      "train loss:0.04575289946102602\n",
      "train loss:0.04056618779369511\n",
      "train loss:0.006615709178756056\n",
      "train loss:0.055532595219479106\n",
      "train loss:0.1381052445159008\n",
      "train loss:0.019783979230513237\n",
      "train loss:0.026797856741841278\n",
      "train loss:0.08220438412523814\n",
      "train loss:0.0076068686399395295\n",
      "train loss:0.03379516941753493\n",
      "train loss:0.07953082644762233\n",
      "train loss:0.0312976286148201\n",
      "train loss:0.035896276663801206\n",
      "train loss:0.028837541766697394\n",
      "train loss:0.017332528820202687\n",
      "train loss:0.04794016593098343\n",
      "train loss:0.022247344620528183\n",
      "train loss:0.02775984631443232\n",
      "train loss:0.025948738348199392\n",
      "train loss:0.07216761415081457\n",
      "train loss:0.00970167424632132\n",
      "train loss:0.007992998495824761\n",
      "train loss:0.024352410461538646\n",
      "train loss:0.0545432227843585\n",
      "train loss:0.016158965402245103\n",
      "train loss:0.022421650388415103\n",
      "train loss:0.044267303579730424\n",
      "train loss:0.05722965936678075\n",
      "train loss:0.02291470672232955\n",
      "train loss:0.03231963638791761\n",
      "train loss:0.029650987279044\n",
      "train loss:0.09723213597252213\n",
      "train loss:0.05008748779229357\n",
      "train loss:0.029747936309534376\n",
      "train loss:0.023190790461398395\n",
      "train loss:0.011572067322851834\n",
      "train loss:0.025596055882252906\n",
      "train loss:0.006165779092143068\n",
      "train loss:0.0407445540061826\n",
      "train loss:0.009261092920849322\n",
      "train loss:0.012712411312805611\n",
      "train loss:0.05504793903995351\n",
      "train loss:0.011139916059008865\n",
      "train loss:0.0714639773969089\n",
      "train loss:0.04318822961092365\n",
      "train loss:0.07855536384435571\n",
      "train loss:0.031650322193386884\n",
      "train loss:0.07010439401599852\n",
      "train loss:0.022963776595892292\n",
      "train loss:0.03852392153819162\n",
      "train loss:0.006690542761061565\n",
      "train loss:0.02017615357037277\n",
      "train loss:0.012271867230566239\n",
      "train loss:0.01686612765880556\n",
      "train loss:0.05589873406619605\n",
      "train loss:0.07741394856377246\n",
      "train loss:0.059191621465006596\n",
      "train loss:0.08251245368199944\n",
      "train loss:0.010264273310701394\n",
      "train loss:0.010401830783261422\n",
      "train loss:0.15015215133402385\n",
      "train loss:0.014629483660109506\n",
      "train loss:0.05816399271969599\n",
      "train loss:0.07935238882223579\n",
      "train loss:0.06811459378363026\n",
      "train loss:0.02391990638930714\n",
      "train loss:0.028265105144428926\n",
      "train loss:0.053273924819425555\n",
      "train loss:0.019651302249389595\n",
      "train loss:0.015800353251911255\n",
      "train loss:0.034995501170759315\n",
      "train loss:0.0104812231215824\n",
      "train loss:0.090726917940875\n",
      "train loss:0.027663380121559392\n",
      "train loss:0.11977347395720545\n",
      "train loss:0.056248248163690125\n",
      "train loss:0.015471343634599306\n",
      "train loss:0.02186799523733174\n",
      "train loss:0.06172693664068568\n",
      "train loss:0.03759533176632312\n",
      "train loss:0.036782802566203886\n",
      "train loss:0.06301147192335943\n",
      "train loss:0.023249741065882446\n",
      "train loss:0.02833935753862458\n",
      "train loss:0.06411846526879858\n",
      "train loss:0.03736737812064861\n",
      "train loss:0.032840894107283074\n",
      "train loss:0.04810050163961587\n",
      "train loss:0.05947947049200103\n",
      "train loss:0.043062013750530266\n",
      "train loss:0.056868041514402376\n",
      "train loss:0.00812151541384152\n",
      "train loss:0.054965420495300184\n",
      "train loss:0.053483890584891905\n",
      "train loss:0.025393476667159198\n",
      "train loss:0.052950717984036375\n",
      "train loss:0.035846427389211295\n",
      "train loss:0.04041246861054593\n",
      "train loss:0.04548285421361018\n",
      "train loss:0.03358835877350094\n",
      "train loss:0.03060447204337792\n",
      "train loss:0.07695902200317098\n",
      "train loss:0.017892646621061825\n",
      "train loss:0.031017260092755575\n",
      "train loss:0.06780560337305772\n",
      "train loss:0.0461586433301229\n",
      "train loss:0.08457071749011526\n",
      "train loss:0.01728309878328884\n",
      "train loss:0.030755753762059034\n",
      "train loss:0.00794521810028095\n",
      "train loss:0.05540525815646447\n",
      "train loss:0.016265900946990538\n",
      "train loss:0.02328390341664986\n",
      "train loss:0.008692880294749237\n",
      "train loss:0.0328660804513494\n",
      "train loss:0.030129486318180465\n",
      "train loss:0.018797862894798054\n",
      "train loss:0.06299255563511523\n",
      "train loss:0.010203121179819303\n",
      "train loss:0.035368786207765034\n",
      "train loss:0.014023567604617416\n",
      "train loss:0.027207039329626904\n",
      "train loss:0.015811696281264987\n",
      "train loss:0.04261598666154197\n",
      "train loss:0.038322440985443615\n",
      "train loss:0.03785171079860192\n",
      "train loss:0.0183508422803874\n",
      "train loss:0.0807396024350329\n",
      "train loss:0.019225887469047683\n",
      "train loss:0.03938319006750071\n",
      "train loss:0.03011547711687901\n",
      "train loss:0.011571560070697637\n",
      "train loss:0.053952777106753606\n",
      "train loss:0.037654873236599176\n",
      "train loss:0.11836492984775315\n",
      "train loss:0.01251829640672679\n",
      "train loss:0.006956754581212093\n",
      "train loss:0.014973876302707361\n",
      "train loss:0.014720202306315832\n",
      "train loss:0.03698409605272643\n",
      "train loss:0.010434395411498624\n",
      "train loss:0.01142297514119919\n",
      "train loss:0.029864395670943112\n",
      "train loss:0.039124469034378856\n",
      "train loss:0.015309052635583142\n",
      "train loss:0.012918798401262315\n",
      "train loss:0.04011810291509803\n",
      "train loss:0.03548467195230553\n",
      "train loss:0.04585932670084314\n",
      "train loss:0.053794664413449114\n",
      "train loss:0.010756421875047628\n",
      "train loss:0.012783453975068589\n",
      "train loss:0.017028783205734806\n",
      "train loss:0.020432766012842083\n",
      "train loss:0.02640350410425854\n",
      "train loss:0.0033089962133708217\n",
      "train loss:0.013000170711204358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06123979890625818\n",
      "train loss:0.03418053927751326\n",
      "train loss:0.12481187515698189\n",
      "train loss:0.052500855633989714\n",
      "train loss:0.04134833202108408\n",
      "train loss:0.057212329029837056\n",
      "train loss:0.014352359707453778\n",
      "train loss:0.08473879749836521\n",
      "train loss:0.039957501650356664\n",
      "train loss:0.09614978665571126\n",
      "train loss:0.027188690424866137\n",
      "train loss:0.12227684530037485\n",
      "train loss:0.02581623782677755\n",
      "train loss:0.0953510327633676\n",
      "train loss:0.0188684241853389\n",
      "train loss:0.025270887896441593\n",
      "train loss:0.04285834989553157\n",
      "train loss:0.025348740773238582\n",
      "train loss:0.036285884042584954\n",
      "train loss:0.0781668602002357\n",
      "train loss:0.02494920671013215\n",
      "train loss:0.045564725650707676\n",
      "train loss:0.046600077215635576\n",
      "=== epoch:5, train acc:0.985, test acc:0.981 ===\n",
      "train loss:0.04550246007902033\n",
      "train loss:0.01413833203949672\n",
      "train loss:0.04871631064077982\n",
      "train loss:0.014971964958336564\n",
      "train loss:0.05115906865602199\n",
      "train loss:0.014630883428109502\n",
      "train loss:0.028034972000682244\n",
      "train loss:0.08810758984144287\n",
      "train loss:0.013396871794022984\n",
      "train loss:0.00479615194514202\n",
      "train loss:0.042269926292424834\n",
      "train loss:0.05686611411495423\n",
      "train loss:0.03981012564338322\n",
      "train loss:0.05501817290137599\n",
      "train loss:0.05795100510037465\n",
      "train loss:0.011995780327102237\n",
      "train loss:0.015964720515772954\n",
      "train loss:0.013010678259271467\n",
      "train loss:0.011811935352451095\n",
      "train loss:0.09365490751890757\n",
      "train loss:0.07563627531927221\n",
      "train loss:0.025824648015584154\n",
      "train loss:0.04198679037706509\n",
      "train loss:0.09702332367886157\n",
      "train loss:0.012012421995260716\n",
      "train loss:0.0732943157083769\n",
      "train loss:0.08155244011741171\n",
      "train loss:0.02302328460381504\n",
      "train loss:0.07921211434283464\n",
      "train loss:0.04482715115001176\n",
      "train loss:0.012220251453106285\n",
      "train loss:0.007775753467483448\n",
      "train loss:0.014187970365979432\n",
      "train loss:0.02364189623287792\n",
      "train loss:0.06707012076249386\n",
      "train loss:0.08791218683683764\n",
      "train loss:0.02305664576651551\n",
      "train loss:0.12167224486454126\n",
      "train loss:0.04973339009619495\n",
      "train loss:0.011921105367238425\n",
      "train loss:0.014260705488754924\n",
      "train loss:0.02059539859812709\n",
      "train loss:0.0899659990168319\n",
      "train loss:0.01629291422054674\n",
      "train loss:0.029926128190922822\n",
      "train loss:0.011118461907801264\n",
      "train loss:0.00836303817012192\n",
      "train loss:0.011430653671248514\n",
      "train loss:0.019993961706623896\n",
      "train loss:0.0255659856992967\n",
      "train loss:0.02125506453431488\n",
      "train loss:0.02627711250554356\n",
      "train loss:0.01583247962132076\n",
      "train loss:0.05849101800162807\n",
      "train loss:0.041597171942590265\n",
      "train loss:0.02259964947044747\n",
      "train loss:0.009018307328817185\n",
      "train loss:0.044946874585888176\n",
      "train loss:0.017300154773506632\n",
      "train loss:0.01532119626389426\n",
      "train loss:0.004537227452812432\n",
      "train loss:0.05306326455617182\n",
      "train loss:0.0596808417521701\n",
      "train loss:0.012096406614481634\n",
      "train loss:0.015640102826926967\n",
      "train loss:0.10932236832488922\n",
      "train loss:0.05122207684094083\n",
      "train loss:0.02024463217053237\n",
      "train loss:0.012825583146607224\n",
      "train loss:0.08798734531721297\n",
      "train loss:0.03112837733699756\n",
      "train loss:0.04511600347703792\n",
      "train loss:0.012572370176764385\n",
      "train loss:0.10745454289921538\n",
      "train loss:0.011209012795770659\n",
      "train loss:0.029455407549629897\n",
      "train loss:0.016522911932347003\n",
      "train loss:0.022033777207103568\n",
      "train loss:0.04701197261674637\n",
      "train loss:0.021911090025202352\n",
      "train loss:0.023343352728415905\n",
      "train loss:0.030306592437606555\n",
      "train loss:0.06730406582443832\n",
      "train loss:0.010325804868288832\n",
      "train loss:0.00666895428782277\n",
      "train loss:0.0229481841246751\n",
      "train loss:0.006469582405548239\n",
      "train loss:0.020461941589353647\n",
      "train loss:0.0068408022690524236\n",
      "train loss:0.01414173760293967\n",
      "train loss:0.03711881165990655\n",
      "train loss:0.04323954275298751\n",
      "train loss:0.01197531192922225\n",
      "train loss:0.0078103264653000635\n",
      "train loss:0.1003604184288325\n",
      "train loss:0.03831445112276792\n",
      "train loss:0.07080840727845256\n",
      "train loss:0.034015867983092224\n",
      "train loss:0.018376809703540962\n",
      "train loss:0.045688695999318296\n",
      "train loss:0.022617699317078233\n",
      "train loss:0.01624783442750495\n",
      "train loss:0.02737881442013609\n",
      "train loss:0.06626530523581722\n",
      "train loss:0.053732650682447945\n",
      "train loss:0.00933046563557588\n",
      "train loss:0.05854799889513369\n",
      "train loss:0.016959918827245967\n",
      "train loss:0.005978806734913489\n",
      "train loss:0.03414397747608682\n",
      "train loss:0.033535358334445646\n",
      "train loss:0.0032898035716697636\n",
      "train loss:0.007017937740245141\n",
      "train loss:0.043640184428914\n",
      "train loss:0.045976811978671525\n",
      "train loss:0.036350851364296666\n",
      "train loss:0.043564007081029456\n",
      "train loss:0.05768387290767246\n",
      "train loss:0.009394696119108644\n",
      "train loss:0.01145833047930346\n",
      "train loss:0.011551755065323998\n",
      "train loss:0.007295286731836547\n",
      "train loss:0.017493113575541168\n",
      "train loss:0.022397935805498554\n",
      "train loss:0.05194634017466832\n",
      "train loss:0.04870968082090205\n",
      "train loss:0.021925353642537206\n",
      "train loss:0.035217899049076656\n",
      "train loss:0.007608589260942575\n",
      "train loss:0.010759989239233823\n",
      "train loss:0.015528368060798875\n",
      "train loss:0.02250106793229362\n",
      "train loss:0.015062462155617002\n",
      "train loss:0.045841147077345726\n",
      "train loss:0.005395823097609082\n",
      "train loss:0.008566223329346104\n",
      "train loss:0.11298929127200676\n",
      "train loss:0.07633732516965717\n",
      "train loss:0.06278335037204599\n",
      "train loss:0.01574686389696228\n",
      "train loss:0.04841237133488849\n",
      "train loss:0.039866283417453914\n",
      "train loss:0.04331700330309689\n",
      "train loss:0.040145312597091545\n",
      "train loss:0.13542760057630127\n",
      "train loss:0.03729295019478709\n",
      "train loss:0.019137824769064612\n",
      "train loss:0.019764195775810886\n",
      "train loss:0.01801654228482036\n",
      "train loss:0.009688660744249204\n",
      "train loss:0.015363637762672626\n",
      "train loss:0.01884885576613058\n",
      "train loss:0.06293569615384462\n",
      "train loss:0.03818381492280155\n",
      "train loss:0.036034539850239966\n",
      "train loss:0.006430505291486591\n",
      "train loss:0.18325831597261166\n",
      "train loss:0.027404567773031716\n",
      "train loss:0.011289995247159783\n",
      "train loss:0.04585509756105575\n",
      "train loss:0.024667058804994663\n",
      "train loss:0.020885555511646108\n",
      "train loss:0.015255292735406984\n",
      "train loss:0.01108491871813876\n",
      "train loss:0.054305241886022336\n",
      "train loss:0.05619432774628913\n",
      "train loss:0.020843164492088805\n",
      "train loss:0.00887676604054861\n",
      "train loss:0.04068052448657551\n",
      "train loss:0.046017403974773\n",
      "train loss:0.033450247195215\n",
      "train loss:0.005159236824561093\n",
      "train loss:0.03875643392843935\n",
      "train loss:0.054973959174847736\n",
      "train loss:0.027829005553258675\n",
      "train loss:0.0038365860420510323\n",
      "train loss:0.03362641787814524\n",
      "train loss:0.022048390335742553\n",
      "train loss:0.018317551466887225\n",
      "train loss:0.027928619734597038\n",
      "train loss:0.01282242942618304\n",
      "train loss:0.02194937468107014\n",
      "train loss:0.01975646657073605\n",
      "train loss:0.03129992071413888\n",
      "train loss:0.028525061219261922\n",
      "train loss:0.08944377337491373\n",
      "train loss:0.05502208813559717\n",
      "train loss:0.033869673148280065\n",
      "train loss:0.07919362339749061\n",
      "train loss:0.004009745179011082\n",
      "train loss:0.006423714202039208\n",
      "train loss:0.03480143855953981\n",
      "train loss:0.02267209627899258\n",
      "train loss:0.020538846880275713\n",
      "train loss:0.06217984207274872\n",
      "train loss:0.031183074857112834\n",
      "train loss:0.014500088451280747\n",
      "train loss:0.012153956918990653\n",
      "train loss:0.0866866525316693\n",
      "train loss:0.05413753889783445\n",
      "train loss:0.04927801511211331\n",
      "train loss:0.030259577710508277\n",
      "train loss:0.01361847363146088\n",
      "train loss:0.00617171711773291\n",
      "train loss:0.047332283390596676\n",
      "train loss:0.09368292030118744\n",
      "train loss:0.025342379566899158\n",
      "train loss:0.045709402658032514\n",
      "train loss:0.01864706117305819\n",
      "train loss:0.009080813624943191\n",
      "train loss:0.019700181677441222\n",
      "train loss:0.021819395705916636\n",
      "train loss:0.031142704345390296\n",
      "train loss:0.04005831624205497\n",
      "train loss:0.01411185522319894\n",
      "train loss:0.03310877445832605\n",
      "train loss:0.054424626689010006\n",
      "train loss:0.021118186414735368\n",
      "train loss:0.038820824736381536\n",
      "train loss:0.08783366060706811\n",
      "train loss:0.01116233221767927\n",
      "train loss:0.04364547951271775\n",
      "train loss:0.013093153102825302\n",
      "train loss:0.009930102478955552\n",
      "train loss:0.00878099026401427\n",
      "train loss:0.022879851984837378\n",
      "train loss:0.015300464642688352\n",
      "train loss:0.02324324963057676\n",
      "train loss:0.013838432154640727\n",
      "train loss:0.06045840440487885\n",
      "train loss:0.01801537935145333\n",
      "train loss:0.039041681332146014\n",
      "train loss:0.014997530883690536\n",
      "train loss:0.003930008398835573\n",
      "train loss:0.010976821363378209\n",
      "train loss:0.03533820050724166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01127137838990574\n",
      "train loss:0.027737766986284555\n",
      "train loss:0.01700293213262829\n",
      "train loss:0.006554948155037703\n",
      "train loss:0.0638654820966383\n",
      "train loss:0.018183776205220527\n",
      "train loss:0.023810621135463596\n",
      "train loss:0.04664410613538876\n",
      "train loss:0.014274138742222204\n",
      "train loss:0.009165245770323498\n",
      "train loss:0.04991512816520622\n",
      "train loss:0.026921037277663203\n",
      "train loss:0.020687929492458013\n",
      "train loss:0.012585721119313331\n",
      "train loss:0.01900558752957943\n",
      "train loss:0.01329099129313172\n",
      "train loss:0.046681259593921894\n",
      "train loss:0.045430161288494045\n",
      "train loss:0.01626798165030205\n",
      "train loss:0.016948869046654814\n",
      "train loss:0.0518872914413577\n",
      "train loss:0.07490870705037034\n",
      "train loss:0.0640709729593889\n",
      "train loss:0.057084837743389245\n",
      "train loss:0.023029009072043083\n",
      "train loss:0.019835408748559984\n",
      "train loss:0.09270928461210773\n",
      "train loss:0.014866936609177612\n",
      "train loss:0.012902974386001338\n",
      "train loss:0.011157333556123323\n",
      "train loss:0.05623969549200481\n",
      "train loss:0.02543457923938605\n",
      "train loss:0.01640186453349095\n",
      "train loss:0.031651873490865096\n",
      "train loss:0.010189378850533332\n",
      "train loss:0.008130273663453463\n",
      "train loss:0.007258104767733496\n",
      "train loss:0.027141659842357987\n",
      "train loss:0.014010656021595602\n",
      "train loss:0.015586928264842807\n",
      "train loss:0.05448401471538477\n",
      "train loss:0.0046661324452504085\n",
      "train loss:0.026267369368997383\n",
      "train loss:0.06552435004719535\n",
      "train loss:0.07564573162704429\n",
      "train loss:0.04469467663988969\n",
      "train loss:0.11981497083107996\n",
      "train loss:0.010637115373191357\n",
      "train loss:0.011197545668592981\n",
      "train loss:0.052255029618204656\n",
      "train loss:0.02298907769952657\n",
      "train loss:0.019041650447617645\n",
      "train loss:0.010852804451216835\n",
      "train loss:0.026593555079935688\n",
      "train loss:0.07195878909431223\n",
      "train loss:0.023748717611735068\n",
      "train loss:0.04158410707110589\n",
      "train loss:0.00379840092787637\n",
      "train loss:0.024225392652863192\n",
      "train loss:0.012134031984332303\n",
      "train loss:0.0865333044699147\n",
      "train loss:0.01175351084128471\n",
      "train loss:0.03232441755564953\n",
      "train loss:0.00623631690847724\n",
      "train loss:0.011309091761384258\n",
      "train loss:0.018741826403524377\n",
      "train loss:0.006124833989737114\n",
      "train loss:0.045285483114888135\n",
      "train loss:0.012690515592853955\n",
      "train loss:0.009391913130579051\n",
      "train loss:0.03998921582314104\n",
      "train loss:0.008422686814085435\n",
      "train loss:0.11569575087881637\n",
      "train loss:0.04081422397121292\n",
      "train loss:0.029392621638840488\n",
      "train loss:0.03427124765414433\n",
      "train loss:0.03246881657341872\n",
      "train loss:0.025228539900047853\n",
      "train loss:0.035062867202183254\n",
      "train loss:0.004405635060004863\n",
      "train loss:0.011623961051347451\n",
      "train loss:0.017988539808193288\n",
      "train loss:0.02099385936299554\n",
      "train loss:0.07091307991026632\n",
      "train loss:0.03544927012236492\n",
      "train loss:0.0783670831181244\n",
      "train loss:0.07560982498810769\n",
      "train loss:0.08803775342922235\n",
      "train loss:0.043399701189394964\n",
      "train loss:0.0333602548428917\n",
      "train loss:0.007180577424112694\n",
      "train loss:0.038019847202448415\n",
      "train loss:0.08681681476486693\n",
      "train loss:0.023254002789559355\n",
      "train loss:0.01676498077770565\n",
      "train loss:0.012556040707191905\n",
      "train loss:0.013002281848831572\n",
      "train loss:0.018338855099779856\n",
      "train loss:0.01169779543398735\n",
      "train loss:0.15150622782170398\n",
      "train loss:0.06369612494693482\n",
      "train loss:0.05380508425323172\n",
      "train loss:0.03532125170373371\n",
      "train loss:0.2018438162741717\n",
      "train loss:0.006185498834056744\n",
      "train loss:0.03776279500931427\n",
      "train loss:0.005858055431819081\n",
      "train loss:0.012793263437907196\n",
      "train loss:0.023097650892968377\n",
      "train loss:0.07900324518569292\n",
      "train loss:0.023980497779862383\n",
      "train loss:0.011340889097658681\n",
      "train loss:0.011225896090075831\n",
      "train loss:0.0285956649452606\n",
      "train loss:0.019526373891618064\n",
      "train loss:0.02160422918407197\n",
      "train loss:0.0691193874585248\n",
      "train loss:0.021737520378051222\n",
      "train loss:0.00563513745785949\n",
      "train loss:0.059877914181909485\n",
      "train loss:0.015353879185760007\n",
      "train loss:0.06923213182386098\n",
      "train loss:0.015355469719222524\n",
      "train loss:0.008778841305818517\n",
      "train loss:0.10225834233534209\n",
      "train loss:0.09661051414474413\n",
      "train loss:0.006769063257332713\n",
      "train loss:0.024003027744065836\n",
      "train loss:0.07137648049008939\n",
      "train loss:0.046958716584249646\n",
      "train loss:0.0171253720949049\n",
      "train loss:0.025599221895088155\n",
      "train loss:0.0733288693901927\n",
      "train loss:0.027456138358718164\n",
      "train loss:0.015772027337125547\n",
      "train loss:0.003796425792573552\n",
      "train loss:0.020339383231594586\n",
      "train loss:0.04181066843004175\n",
      "train loss:0.031036023481069357\n",
      "train loss:0.03443062610693785\n",
      "train loss:0.009784280910739487\n",
      "train loss:0.010115770931566405\n",
      "train loss:0.012823868093603443\n",
      "train loss:0.049017493472167974\n",
      "train loss:0.024695912740499468\n",
      "train loss:0.04487918257102574\n",
      "train loss:0.02503129100558578\n",
      "train loss:0.01436833900323273\n",
      "train loss:0.023133492323840057\n",
      "train loss:0.0275928765412407\n",
      "train loss:0.009513696861397022\n",
      "train loss:0.025383351499169496\n",
      "train loss:0.04374186737267158\n",
      "train loss:0.04537924690531528\n",
      "train loss:0.030103300435522787\n",
      "train loss:0.00944932829659454\n",
      "train loss:0.025409387014778555\n",
      "train loss:0.020797366432149408\n",
      "train loss:0.01009540592282534\n",
      "train loss:0.03758687693354445\n",
      "train loss:0.011884373266389048\n",
      "train loss:0.03826343754709471\n",
      "train loss:0.04532683413914309\n",
      "train loss:0.06491167870432267\n",
      "train loss:0.033972574799858594\n",
      "train loss:0.021318060470895225\n",
      "train loss:0.012939823362890478\n",
      "train loss:0.028287390245126973\n",
      "train loss:0.03326306078529359\n",
      "train loss:0.045305855964458436\n",
      "train loss:0.016653305613855345\n",
      "train loss:0.03166472031106842\n",
      "train loss:0.031244226793857983\n",
      "train loss:0.03436687696589811\n",
      "train loss:0.016385768352855573\n",
      "train loss:0.007836513212296359\n",
      "train loss:0.022334514970313087\n",
      "train loss:0.04030483630073706\n",
      "train loss:0.05586774993669332\n",
      "train loss:0.011146618902903627\n",
      "train loss:0.02332632277706661\n",
      "train loss:0.01373218199329371\n",
      "train loss:0.006087282064420261\n",
      "train loss:0.026127222017007328\n",
      "train loss:0.03335343267999038\n",
      "train loss:0.00575483296869473\n",
      "train loss:0.0442917657477893\n",
      "train loss:0.008769643105214484\n",
      "train loss:0.014670003584782218\n",
      "train loss:0.017003934097775855\n",
      "train loss:0.042550487269821254\n",
      "train loss:0.015312469270907056\n",
      "train loss:0.005129945226474462\n",
      "train loss:0.08585059375575882\n",
      "train loss:0.021722141771303972\n",
      "train loss:0.011419875453433174\n",
      "train loss:0.024951831904450397\n",
      "train loss:0.036773055692343626\n",
      "train loss:0.03228661008246172\n",
      "train loss:0.031000673512151265\n",
      "train loss:0.009699500967312855\n",
      "train loss:0.021566372663273548\n",
      "train loss:0.05397612487088553\n",
      "train loss:0.011549400829557776\n",
      "train loss:0.011878321505887442\n",
      "train loss:0.028221156153501434\n",
      "train loss:0.012172492109448508\n",
      "train loss:0.060784226728220335\n",
      "train loss:0.02188011203246324\n",
      "train loss:0.12285413897589564\n",
      "train loss:0.026477694579494008\n",
      "train loss:0.032894568180757464\n",
      "train loss:0.03205135965040915\n",
      "train loss:0.053751797405677176\n",
      "train loss:0.020022762336987937\n",
      "train loss:0.026704032262450814\n",
      "train loss:0.027537809412774103\n",
      "train loss:0.005087727835964652\n",
      "train loss:0.03548300985789512\n",
      "train loss:0.020441186364015988\n",
      "train loss:0.05020880383623739\n",
      "train loss:0.007880861926620564\n",
      "train loss:0.018070226742713105\n",
      "train loss:0.038544168979713474\n",
      "train loss:0.007403863044457114\n",
      "train loss:0.07091248893477826\n",
      "train loss:0.017490844893034877\n",
      "train loss:0.024488383846576894\n",
      "train loss:0.012735114958055738\n",
      "train loss:0.026940700093988666\n",
      "train loss:0.009390251977874292\n",
      "train loss:0.003931354764297035\n",
      "train loss:0.019403788881241724\n",
      "train loss:0.07055090394478392\n",
      "train loss:0.061477988051987224\n",
      "train loss:0.10602175570013926\n",
      "train loss:0.00751339296543047\n",
      "train loss:0.05521446080868356\n",
      "train loss:0.05438821465350635\n",
      "train loss:0.009663573233488546\n",
      "train loss:0.018248361575679075\n",
      "train loss:0.10109088382168001\n",
      "train loss:0.013123852257064665\n",
      "train loss:0.03371226559383634\n",
      "train loss:0.009042654485015122\n",
      "train loss:0.0346442304189746\n",
      "train loss:0.022337802167847077\n",
      "train loss:0.012695755510522362\n",
      "train loss:0.09945960211778063\n",
      "train loss:0.025787045883618673\n",
      "train loss:0.0689777751718868\n",
      "train loss:0.014066994075692703\n",
      "train loss:0.050156113858207896\n",
      "train loss:0.026449448389283994\n",
      "train loss:0.011456046471959073\n",
      "train loss:0.02501273193327983\n",
      "train loss:0.018997047263933378\n",
      "train loss:0.03483251040237585\n",
      "train loss:0.009073100039876986\n",
      "train loss:0.009319924803244676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06406636840621943\n",
      "train loss:0.0372934390490439\n",
      "train loss:0.06714684516278997\n",
      "train loss:0.06723184958225015\n",
      "train loss:0.009669670901177353\n",
      "train loss:0.011601897057886626\n",
      "train loss:0.04342254344765415\n",
      "train loss:0.01946190303460011\n",
      "train loss:0.008315037380655891\n",
      "train loss:0.016891958768915267\n",
      "train loss:0.031612324953952844\n",
      "train loss:0.016330413452373106\n",
      "train loss:0.010993860744680456\n",
      "train loss:0.011587832569922867\n",
      "train loss:0.02113920880522481\n",
      "train loss:0.07284021319993751\n",
      "train loss:0.014111407654176069\n",
      "train loss:0.023766373694626655\n",
      "train loss:0.01903610458243253\n",
      "train loss:0.02058166659108243\n",
      "train loss:0.02552388987906341\n",
      "train loss:0.03380266444675498\n",
      "train loss:0.01060154597603308\n",
      "train loss:0.004578315331543823\n",
      "train loss:0.049013861803632056\n",
      "train loss:0.005984201971958748\n",
      "train loss:0.03375723983550878\n",
      "train loss:0.06354167881485988\n",
      "train loss:0.05076856404155799\n",
      "train loss:0.029715601573499534\n",
      "train loss:0.024973948551762333\n",
      "train loss:0.029041314812637446\n",
      "train loss:0.009791082508828928\n",
      "train loss:0.013412837866627449\n",
      "train loss:0.026870170865766166\n",
      "train loss:0.019988238046860354\n",
      "train loss:0.02155058378182753\n",
      "train loss:0.026805303576031562\n",
      "train loss:0.11915124321246401\n",
      "train loss:0.014136952756250685\n",
      "train loss:0.017248449041457344\n",
      "train loss:0.011055614952387868\n",
      "train loss:0.04178139703436213\n",
      "train loss:0.024498691126088254\n",
      "train loss:0.04113897408573534\n",
      "train loss:0.07094063459811509\n",
      "train loss:0.0804865377513924\n",
      "train loss:0.012305739932534168\n",
      "train loss:0.00792825256503605\n",
      "train loss:0.04430412068987169\n",
      "train loss:0.016147251828375304\n",
      "train loss:0.016390094472414334\n",
      "train loss:0.02272143857855375\n",
      "train loss:0.015042387656668774\n",
      "train loss:0.03213602552671355\n",
      "train loss:0.036612878907656896\n",
      "train loss:0.016129910751349043\n",
      "train loss:0.02470301508267727\n",
      "train loss:0.01528083478027375\n",
      "train loss:0.05249009753134725\n",
      "train loss:0.014689361951082171\n",
      "train loss:0.05124615548753941\n",
      "train loss:0.03290008875899878\n",
      "train loss:0.008884798541737715\n",
      "train loss:0.05190022726831534\n",
      "train loss:0.04322148801524613\n",
      "train loss:0.026839166407919234\n",
      "train loss:0.009939696001720105\n",
      "train loss:0.024213990045869396\n",
      "train loss:0.054407764920191636\n",
      "train loss:0.019903449895745468\n",
      "train loss:0.027242771330503762\n",
      "train loss:0.03732031110350566\n",
      "train loss:0.020950241987304916\n",
      "train loss:0.0407730336640981\n",
      "train loss:0.008606724371064231\n",
      "train loss:0.02564825097664176\n",
      "train loss:0.03494697783308601\n",
      "train loss:0.01909478853097704\n",
      "train loss:0.03174521881561581\n",
      "train loss:0.02197547123495593\n",
      "train loss:0.04341524426890737\n",
      "train loss:0.010166130154694353\n",
      "train loss:0.034858206582599055\n",
      "train loss:0.012750707247947692\n",
      "train loss:0.019114114987157385\n",
      "train loss:0.07846088117084572\n",
      "train loss:0.1265631716859092\n",
      "train loss:0.008410641421108148\n",
      "train loss:0.005829139282970119\n",
      "train loss:0.016081878891082296\n",
      "train loss:0.022859849026843397\n",
      "train loss:0.016899345147908605\n",
      "train loss:0.04886138357531161\n",
      "train loss:0.045602150944919\n",
      "train loss:0.02051701936919599\n",
      "train loss:0.011472745785071873\n",
      "train loss:0.016245121500259457\n",
      "train loss:0.024126646021554326\n",
      "train loss:0.01172003911917293\n",
      "train loss:0.005876040135550704\n",
      "train loss:0.002668069577509255\n",
      "train loss:0.01890081735972475\n",
      "train loss:0.050785705967203304\n",
      "=== epoch:6, train acc:0.987, test acc:0.982 ===\n",
      "train loss:0.015209324471191634\n",
      "train loss:0.053730928387642304\n",
      "train loss:0.021430579593465112\n",
      "train loss:0.038031271136226924\n",
      "train loss:0.00876168286476231\n",
      "train loss:0.01638609548164792\n",
      "train loss:0.003155469102390461\n",
      "train loss:0.0630850034777507\n",
      "train loss:0.08673341830956602\n",
      "train loss:0.030267120312019394\n",
      "train loss:0.004217739712687657\n",
      "train loss:0.013216951545891984\n",
      "train loss:0.018498027035081896\n",
      "train loss:0.013115446216531405\n",
      "train loss:0.03627797596549527\n",
      "train loss:0.0080105348037122\n",
      "train loss:0.09480036847253873\n",
      "train loss:0.020963269291876654\n",
      "train loss:0.009199388910199115\n",
      "train loss:0.016472514768288305\n",
      "train loss:0.019066038186063068\n",
      "train loss:0.016663480388641846\n",
      "train loss:0.018738618879763146\n",
      "train loss:0.024486927127773016\n",
      "train loss:0.020943845259885394\n",
      "train loss:0.01921489193455751\n",
      "train loss:0.01956241637805316\n",
      "train loss:0.002906724303065834\n",
      "train loss:0.00468351315198026\n",
      "train loss:0.06463913911636324\n",
      "train loss:0.013347081648105098\n",
      "train loss:0.007339136964473686\n",
      "train loss:0.01827551746955265\n",
      "train loss:0.04497362533191817\n",
      "train loss:0.013110578777443607\n",
      "train loss:0.03746376966490978\n",
      "train loss:0.02595176206774672\n",
      "train loss:0.0032137607138749084\n",
      "train loss:0.008181976826150034\n",
      "train loss:0.030766379247597356\n",
      "train loss:0.021518053582965598\n",
      "train loss:0.029212913867992487\n",
      "train loss:0.019588672558140438\n",
      "train loss:0.011828309287034442\n",
      "train loss:0.005001750860311891\n",
      "train loss:0.009619153530855629\n",
      "train loss:0.08833301227724977\n",
      "train loss:0.023567143366083006\n",
      "train loss:0.041059668934881846\n",
      "train loss:0.008571456095019673\n",
      "train loss:0.009578592037214357\n",
      "train loss:0.009206783257808158\n",
      "train loss:0.019762317277962016\n",
      "train loss:0.006635758911917096\n",
      "train loss:0.14095216414456518\n",
      "train loss:0.06198120259816232\n",
      "train loss:0.03377902790828183\n",
      "train loss:0.07054089067797681\n",
      "train loss:0.0197996614057251\n",
      "train loss:0.011104422907134206\n",
      "train loss:0.03644920961742932\n",
      "train loss:0.07261117959687685\n",
      "train loss:0.009728018631018565\n",
      "train loss:0.009349088200706374\n",
      "train loss:0.007457964165311221\n",
      "train loss:0.017571478669061315\n",
      "train loss:0.0361266788592659\n",
      "train loss:0.005419169997934012\n",
      "train loss:0.006482527863821331\n",
      "train loss:0.027518983399689726\n",
      "train loss:0.02435485140958541\n",
      "train loss:0.0640254114714911\n",
      "train loss:0.005850420902150461\n",
      "train loss:0.01743033468463252\n",
      "train loss:0.002796051209437201\n",
      "train loss:0.03428071014503715\n",
      "train loss:0.032661595345495564\n",
      "train loss:0.014173028140603821\n",
      "train loss:0.10923396669631627\n",
      "train loss:0.014811320123593468\n",
      "train loss:0.004517184538846872\n",
      "train loss:0.031011710225967593\n",
      "train loss:0.13486738495562514\n",
      "train loss:0.004110695963632325\n",
      "train loss:0.011787744616388807\n",
      "train loss:0.0059982664130793974\n",
      "train loss:0.009314361763108656\n",
      "train loss:0.016622241559952847\n",
      "train loss:0.01395869535870395\n",
      "train loss:0.01579370723883911\n",
      "train loss:0.021207281676240922\n",
      "train loss:0.020311115551522107\n",
      "train loss:0.018682418320871776\n",
      "train loss:0.04532072424407239\n",
      "train loss:0.047391083944095774\n",
      "train loss:0.11210953431500496\n",
      "train loss:0.015197205445738137\n",
      "train loss:0.021981495158604526\n",
      "train loss:0.029250790701285473\n",
      "train loss:0.05559362136234097\n",
      "train loss:0.012815539024288686\n",
      "train loss:0.02980583168294715\n",
      "train loss:0.019558929103988563\n",
      "train loss:0.0846958442182417\n",
      "train loss:0.04545701696397109\n",
      "train loss:0.009783686174315805\n",
      "train loss:0.03215425611106638\n",
      "train loss:0.047892422377242096\n",
      "train loss:0.07741177338222614\n",
      "train loss:0.02915548951631949\n",
      "train loss:0.015293362433023294\n",
      "train loss:0.009151054312724796\n",
      "train loss:0.008667766858648668\n",
      "train loss:0.036036258996464884\n",
      "train loss:0.020109935839821142\n",
      "train loss:0.036526919444568116\n",
      "train loss:0.02687202399979614\n",
      "train loss:0.023089737303829527\n",
      "train loss:0.03060841357227395\n",
      "train loss:0.009059935437604097\n",
      "train loss:0.06593370730833986\n",
      "train loss:0.01998637285058697\n",
      "train loss:0.057369643090652796\n",
      "train loss:0.08332233710563741\n",
      "train loss:0.010575466314709035\n",
      "train loss:0.031718703318242156\n",
      "train loss:0.029887179785784188\n",
      "train loss:0.004607196580092764\n",
      "train loss:0.03169912834829941\n",
      "train loss:0.08418353166256917\n",
      "train loss:0.0188917639216568\n",
      "train loss:0.0518452993058401\n",
      "train loss:0.07827180275629017\n",
      "train loss:0.012483764364189768\n",
      "train loss:0.01134475493708146\n",
      "train loss:0.018346559665968973\n",
      "train loss:0.025589916444619908\n",
      "train loss:0.13839612795898548\n",
      "train loss:0.01643342713970448\n",
      "train loss:0.06513198633424123\n",
      "train loss:0.010411808668597032\n",
      "train loss:0.060789210307120776\n",
      "train loss:0.023513287726679457\n",
      "train loss:0.034307286753527316\n",
      "train loss:0.0499608235123407\n",
      "train loss:0.011720331002889805\n",
      "train loss:0.010025262242181018\n",
      "train loss:0.021232036807971463\n",
      "train loss:0.029553856127863612\n",
      "train loss:0.022900646161491248\n",
      "train loss:0.040919150233695877\n",
      "train loss:0.022132958277355397\n",
      "train loss:0.047488421758744605\n",
      "train loss:0.01130466419561154\n",
      "train loss:0.00915686247378175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.061446878468805206\n",
      "train loss:0.014501564226171073\n",
      "train loss:0.009317277831938897\n",
      "train loss:0.010941642953492208\n",
      "train loss:0.015271466334883584\n",
      "train loss:0.015181921026671036\n",
      "train loss:0.01151854195605262\n",
      "train loss:0.03040903072377335\n",
      "train loss:0.06417053791139737\n",
      "train loss:0.021998330571687933\n",
      "train loss:0.0025090461838271475\n",
      "train loss:0.009735630256180565\n",
      "train loss:0.01250836043240967\n",
      "train loss:0.010143058102053144\n",
      "train loss:0.00787291943856923\n",
      "train loss:0.010509409563808437\n",
      "train loss:0.010887557049632906\n",
      "train loss:0.03743649593298014\n",
      "train loss:0.015910964405231723\n",
      "train loss:0.010949836708710086\n",
      "train loss:0.01178077540233038\n",
      "train loss:0.026228501522141158\n",
      "train loss:0.021855169589631088\n",
      "train loss:0.009515258812302021\n",
      "train loss:0.007901183050454877\n",
      "train loss:0.02622285461334466\n",
      "train loss:0.0023824560948518428\n",
      "train loss:0.0246523120364272\n",
      "train loss:0.006920133747612258\n",
      "train loss:0.02793821373077003\n",
      "train loss:0.012445099826069228\n",
      "train loss:0.008400819465346957\n",
      "train loss:0.025914915747305752\n",
      "train loss:0.048913995025274076\n",
      "train loss:0.10477894343972378\n",
      "train loss:0.005205281510355459\n",
      "train loss:0.012516882919655439\n",
      "train loss:0.0222665101134105\n",
      "train loss:0.016707572656456792\n",
      "train loss:0.0045095347104998325\n",
      "train loss:0.03673863805182064\n",
      "train loss:0.08117561623244784\n",
      "train loss:0.00279272760762005\n",
      "train loss:0.10968477710374587\n",
      "train loss:0.004170266733981765\n",
      "train loss:0.06612486129431386\n",
      "train loss:0.009535427525307427\n",
      "train loss:0.01169180290133821\n",
      "train loss:0.017509663041806088\n",
      "train loss:0.016274368301898677\n",
      "train loss:0.012361234244086434\n",
      "train loss:0.02594849989105495\n",
      "train loss:0.019425745561910762\n",
      "train loss:0.004129038543045974\n",
      "train loss:0.013355093926780302\n",
      "train loss:0.0341818771599566\n",
      "train loss:0.014532414301472547\n",
      "train loss:0.021837661355503614\n",
      "train loss:0.022513025343587945\n",
      "train loss:0.017464158360599346\n",
      "train loss:0.01664799084435073\n",
      "train loss:0.03650798824730372\n",
      "train loss:0.05613302771003446\n",
      "train loss:0.02575828286416242\n",
      "train loss:0.02497685246764864\n",
      "train loss:0.029434641811297672\n",
      "train loss:0.012967767380122406\n",
      "train loss:0.01865437485679951\n",
      "train loss:0.009193352416596126\n",
      "train loss:0.006718258952902825\n",
      "train loss:0.04381547406370758\n",
      "train loss:0.03709946957534502\n",
      "train loss:0.032247645463595036\n",
      "train loss:0.02293275205352334\n",
      "train loss:0.020540245156748335\n",
      "train loss:0.03272138042383342\n",
      "train loss:0.008338800724093647\n",
      "train loss:0.05779538850677286\n",
      "train loss:0.012699406065033822\n",
      "train loss:0.004289232083034808\n",
      "train loss:0.007808472060403152\n",
      "train loss:0.014342384050150026\n",
      "train loss:0.05362239823847152\n",
      "train loss:0.021665748355900325\n",
      "train loss:0.019129409142836427\n",
      "train loss:0.01702677154444192\n",
      "train loss:0.025493357835448795\n",
      "train loss:0.04375805789844425\n",
      "train loss:0.010008534051357992\n",
      "train loss:0.06391799329293874\n",
      "train loss:0.02794842360268217\n",
      "train loss:0.03217238282234146\n",
      "train loss:0.03899313350161686\n",
      "train loss:0.017767630686922057\n",
      "train loss:0.020872413768312215\n",
      "train loss:0.05066510901927128\n",
      "train loss:0.02249258654682507\n",
      "train loss:0.020861705937452978\n",
      "train loss:0.036600318676367295\n",
      "train loss:0.005487204893402991\n",
      "train loss:0.01709643615251116\n",
      "train loss:0.01869662957381049\n",
      "train loss:0.06176883726839111\n",
      "train loss:0.07808624471674808\n",
      "train loss:0.010591535894847523\n",
      "train loss:0.0094030242974847\n",
      "train loss:0.01549972113222622\n",
      "train loss:0.011047245337649008\n",
      "train loss:0.045783650995990584\n",
      "train loss:0.027439961688612544\n",
      "train loss:0.022315724053100606\n",
      "train loss:0.04597333549796378\n",
      "train loss:0.008587970121937002\n",
      "train loss:0.07204355180949777\n",
      "train loss:0.042573283880498865\n",
      "train loss:0.0055767268362892555\n",
      "train loss:0.07246371911005302\n",
      "train loss:0.0061290128700585145\n",
      "train loss:0.011073007590786952\n",
      "train loss:0.027674314100943443\n",
      "train loss:0.01292057566225022\n",
      "train loss:0.023933531318947692\n",
      "train loss:0.011197471207193086\n",
      "train loss:0.003833627590796779\n",
      "train loss:0.010321899466343612\n",
      "train loss:0.018248674503461317\n",
      "train loss:0.003858180681803962\n",
      "train loss:0.060614636124587784\n",
      "train loss:0.011574641423807682\n",
      "train loss:0.03396591525645573\n",
      "train loss:0.009343202382586195\n",
      "train loss:0.012589673972516473\n",
      "train loss:0.007846533859873096\n",
      "train loss:0.01345716077059725\n",
      "train loss:0.01975304898221382\n",
      "train loss:0.03403463906419661\n",
      "train loss:0.011278804670434578\n",
      "train loss:0.0265950043643309\n",
      "train loss:0.061806932991852886\n",
      "train loss:0.00811281055047506\n",
      "train loss:0.029494611512840087\n",
      "train loss:0.025032883678975604\n",
      "train loss:0.016852462646782772\n",
      "train loss:0.0355799820136197\n",
      "train loss:0.02077905715025967\n",
      "train loss:0.02437182657703024\n",
      "train loss:0.03628626144609054\n",
      "train loss:0.005678384104450159\n",
      "train loss:0.06804716301149964\n",
      "train loss:0.015206698817968867\n",
      "train loss:0.017917769097794457\n",
      "train loss:0.009892862045649363\n",
      "train loss:0.08091331370945955\n",
      "train loss:0.009171945109046977\n",
      "train loss:0.012183915155388048\n",
      "train loss:0.10184206403284592\n",
      "train loss:0.006678500838800544\n",
      "train loss:0.009091769670099286\n",
      "train loss:0.10217233148173781\n",
      "train loss:0.039162628383412154\n",
      "train loss:0.026645206377870375\n",
      "train loss:0.004590231120753608\n",
      "train loss:0.049674900493107285\n",
      "train loss:0.02754767519082328\n",
      "train loss:0.04120189746142526\n",
      "train loss:0.01952050268744302\n",
      "train loss:0.04340320372963826\n",
      "train loss:0.02186458118516859\n",
      "train loss:0.01379434888381013\n",
      "train loss:0.011664267089626814\n",
      "train loss:0.019714600450474483\n",
      "train loss:0.012669576905718245\n",
      "train loss:0.010116334205348966\n",
      "train loss:0.05302404457637731\n",
      "train loss:0.017833261777036636\n",
      "train loss:0.03562291582261802\n",
      "train loss:0.005022345573651734\n",
      "train loss:0.01070896172487935\n",
      "train loss:0.02099632750394388\n",
      "train loss:0.008309577474151364\n",
      "train loss:0.02154310912587181\n",
      "train loss:0.06208991898592726\n",
      "train loss:0.030225966225813153\n",
      "train loss:0.018271010999215194\n",
      "train loss:0.0051509830754953015\n",
      "train loss:0.011821867948385478\n",
      "train loss:0.021926830411667972\n",
      "train loss:0.014475671887181341\n",
      "train loss:0.022330601889525726\n",
      "train loss:0.015240295779710564\n",
      "train loss:0.02138842979846577\n",
      "train loss:0.010883416008753205\n",
      "train loss:0.005661369508829812\n",
      "train loss:0.01744742513181607\n",
      "train loss:0.0200020520432466\n",
      "train loss:0.012781676974685874\n",
      "train loss:0.0030460493290858075\n",
      "train loss:0.013283507482012348\n",
      "train loss:0.03483803687345887\n",
      "train loss:0.01062799301993834\n",
      "train loss:0.03758340366095522\n",
      "train loss:0.023757325407890054\n",
      "train loss:0.009445317024187865\n",
      "train loss:0.06362548736853763\n",
      "train loss:0.008831673135673589\n",
      "train loss:0.01590165505847492\n",
      "train loss:0.006716420395039899\n",
      "train loss:0.005431802392018511\n",
      "train loss:0.01049384168211497\n",
      "train loss:0.0030665300186543\n",
      "train loss:0.07607282482477515\n",
      "train loss:0.011356123144628083\n",
      "train loss:0.007211339471822714\n",
      "train loss:0.007191234645995743\n",
      "train loss:0.025053629009051483\n",
      "train loss:0.0013757309233720805\n",
      "train loss:0.03224007798451349\n",
      "train loss:0.012052612100873834\n",
      "train loss:0.021511733828393963\n",
      "train loss:0.07630294039851453\n",
      "train loss:0.0102077968647179\n",
      "train loss:0.04582856874605781\n",
      "train loss:0.009468476034205088\n",
      "train loss:0.032188394166249086\n",
      "train loss:0.03450510594851975\n",
      "train loss:0.01261190797869384\n",
      "train loss:0.004349389552256822\n",
      "train loss:0.014513702088757074\n",
      "train loss:0.04315422501636682\n",
      "train loss:0.02203782226166264\n",
      "train loss:0.006209916743439733\n",
      "train loss:0.013500916029480533\n",
      "train loss:0.0200180816311719\n",
      "train loss:0.06652876101056511\n",
      "train loss:0.03856590040030144\n",
      "train loss:0.026231672373580265\n",
      "train loss:0.019945873109445626\n",
      "train loss:0.022869632597923437\n",
      "train loss:0.009126461174118836\n",
      "train loss:0.0025128783416398853\n",
      "train loss:0.007605284777425598\n",
      "train loss:0.017655220069164233\n",
      "train loss:0.014897493518976835\n",
      "train loss:0.02647391362222433\n",
      "train loss:0.018898769055534698\n",
      "train loss:0.08202049699555797\n",
      "train loss:0.018611588599418333\n",
      "train loss:0.007764439414323232\n",
      "train loss:0.018242357222185403\n",
      "train loss:0.026723168968628426\n",
      "train loss:0.008123270748669918\n",
      "train loss:0.004340598308029253\n",
      "train loss:0.032790772091544435\n",
      "train loss:0.00867643122379778\n",
      "train loss:0.012234253882157686\n",
      "train loss:0.03143505083210055\n",
      "train loss:0.009796180410848572\n",
      "train loss:0.01289520043062353\n",
      "train loss:0.004967000528470858\n",
      "train loss:0.006315318102190259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012115043138423104\n",
      "train loss:0.003951083437712774\n",
      "train loss:0.010626103254127923\n",
      "train loss:0.014553585787037802\n",
      "train loss:0.01359653252599637\n",
      "train loss:0.011661959853053808\n",
      "train loss:0.036949339761327554\n",
      "train loss:0.0063014446379459875\n",
      "train loss:0.036044279108732445\n",
      "train loss:0.003995811665681432\n",
      "train loss:0.024051998209124993\n",
      "train loss:0.011148549250302963\n",
      "train loss:0.0035031924782304162\n",
      "train loss:0.018552050408940476\n",
      "train loss:0.002614101808553361\n",
      "train loss:0.004333494192357103\n",
      "train loss:0.00882491891744531\n",
      "train loss:0.010999058251466892\n",
      "train loss:0.007962725914196545\n",
      "train loss:0.002934927075925258\n",
      "train loss:0.09882320326911072\n",
      "train loss:0.015605188911482056\n",
      "train loss:0.013510961791336333\n",
      "train loss:0.005157663686265852\n",
      "train loss:0.01951507119959179\n",
      "train loss:0.016811634946838513\n",
      "train loss:0.004545018430997627\n",
      "train loss:0.0063842850510576095\n",
      "train loss:0.03639862653721176\n",
      "train loss:0.00384739453238216\n",
      "train loss:0.008626912693921842\n",
      "train loss:0.012119659994417638\n",
      "train loss:0.004783788252848267\n",
      "train loss:0.006624034289755225\n",
      "train loss:0.04440463595796497\n",
      "train loss:0.013606287426499575\n",
      "train loss:0.006167760195009166\n",
      "train loss:0.03867049650101185\n",
      "train loss:0.043746954157819665\n",
      "train loss:0.001036805410734922\n",
      "train loss:0.010051232509963698\n",
      "train loss:0.01091779078001832\n",
      "train loss:0.008080438557855769\n",
      "train loss:0.04536911555992185\n",
      "train loss:0.02481764883344301\n",
      "train loss:0.016632619679166447\n",
      "train loss:0.016360248265111576\n",
      "train loss:0.014211120931451403\n",
      "train loss:0.05966809116607392\n",
      "train loss:0.013938397622707798\n",
      "train loss:0.01937744067098482\n",
      "train loss:0.016109650192736094\n",
      "train loss:0.010868816045618361\n",
      "train loss:0.01823579335181518\n",
      "train loss:0.03308358959738426\n",
      "train loss:0.0022839057703519326\n",
      "train loss:0.020221302607622983\n",
      "train loss:0.005299193666191505\n",
      "train loss:0.010721298258776393\n",
      "train loss:0.03578913798146794\n",
      "train loss:0.013345446754555547\n",
      "train loss:0.003953340960629822\n",
      "train loss:0.011496491994516394\n",
      "train loss:0.008138126266223254\n",
      "train loss:0.007315279974059786\n",
      "train loss:0.051231825658579734\n",
      "train loss:0.03145089924063455\n",
      "train loss:0.008684436180818262\n",
      "train loss:0.0063145851696919586\n",
      "train loss:0.0191466886625593\n",
      "train loss:0.012113074384740321\n",
      "train loss:0.08095403085694496\n",
      "train loss:0.024835645897718046\n",
      "train loss:0.014899119624537507\n",
      "train loss:0.015865564203354953\n",
      "train loss:0.01876098632756587\n",
      "train loss:0.005086352758781868\n",
      "train loss:0.0072742796847063175\n",
      "train loss:0.02338040805187562\n",
      "train loss:0.006847567712945401\n",
      "train loss:0.011947284776148202\n",
      "train loss:0.012612942956411355\n",
      "train loss:0.00731568040074647\n",
      "train loss:0.04126872198940508\n",
      "train loss:0.015235933278624316\n",
      "train loss:0.0035310190138515833\n",
      "train loss:0.025512583008214303\n",
      "train loss:0.012761163644220221\n",
      "train loss:0.0251221227504635\n",
      "train loss:0.018447475729932678\n",
      "train loss:0.015482823489837684\n",
      "train loss:0.03810361575464623\n",
      "train loss:0.031945095998252744\n",
      "train loss:0.021638256761079066\n",
      "train loss:0.0037709623877375904\n",
      "train loss:0.02797124414201313\n",
      "train loss:0.011035332560991309\n",
      "train loss:0.04419026303214532\n",
      "train loss:0.08938512398265581\n",
      "train loss:0.016131293952593145\n",
      "train loss:0.025600517928977537\n",
      "train loss:0.02826422558223482\n",
      "train loss:0.013121049505502502\n",
      "train loss:0.10233967980102798\n",
      "train loss:0.0042874089074330275\n",
      "train loss:0.009586795523350268\n",
      "train loss:0.007594423554056024\n",
      "train loss:0.021888531528089047\n",
      "train loss:0.06699280556762006\n",
      "train loss:0.008213597746743734\n",
      "train loss:0.023252843263358476\n",
      "train loss:0.01489918121076671\n",
      "train loss:0.03263500176510281\n",
      "train loss:0.018915179102625322\n",
      "train loss:0.008456961884020913\n",
      "train loss:0.008201889119068191\n",
      "train loss:0.025620103003887982\n",
      "train loss:0.016984385357418377\n",
      "train loss:0.1178227886399716\n",
      "train loss:0.07255993447653891\n",
      "train loss:0.007254140613220499\n",
      "train loss:0.06956514726883399\n",
      "train loss:0.038077683234053514\n",
      "train loss:0.06535474661065441\n",
      "train loss:0.05005351398352216\n",
      "train loss:0.012276277723048377\n",
      "train loss:0.019867426254464415\n",
      "train loss:0.013811121114407677\n",
      "train loss:0.006199283958233726\n",
      "train loss:0.03888123276344745\n",
      "train loss:0.022965326332701663\n",
      "train loss:0.03820896868154842\n",
      "train loss:0.030219162737882832\n",
      "train loss:0.005435522021937716\n",
      "train loss:0.12519167457154118\n",
      "train loss:0.08840870584461498\n",
      "train loss:0.04939603093745876\n",
      "train loss:0.04796320962962401\n",
      "train loss:0.016469480501054765\n",
      "train loss:0.011625649941591008\n",
      "train loss:0.06364758936682392\n",
      "train loss:0.027995991870734697\n",
      "train loss:0.06756983337046646\n",
      "train loss:0.009710659271096206\n",
      "train loss:0.010493571244289235\n",
      "train loss:0.01207576077159887\n",
      "train loss:0.007898344568822942\n",
      "train loss:0.018910875073487102\n",
      "train loss:0.008976458163878624\n",
      "train loss:0.003175868306157387\n",
      "train loss:0.02520957897531081\n",
      "train loss:0.01913914687200791\n",
      "train loss:0.01978602679658047\n",
      "train loss:0.011948952407154118\n",
      "train loss:0.013255912880579026\n",
      "train loss:0.031931077311170585\n",
      "train loss:0.02961983943890565\n",
      "train loss:0.005070850279131001\n",
      "train loss:0.08596879703343291\n",
      "train loss:0.03667579398858404\n",
      "train loss:0.009610690104259901\n",
      "train loss:0.01676040451417128\n",
      "train loss:0.011355971510734626\n",
      "train loss:0.00508799028317261\n",
      "train loss:0.035715550180676854\n",
      "train loss:0.013388266179829293\n",
      "train loss:0.015402107887869268\n",
      "train loss:0.007607179632178942\n",
      "train loss:0.0034064009531854446\n",
      "train loss:0.06464283645906843\n",
      "train loss:0.0055239150484335375\n",
      "train loss:0.02150754311694534\n",
      "train loss:0.006756934824467836\n",
      "train loss:0.03321711128588985\n",
      "train loss:0.00577529319646882\n",
      "train loss:0.01535946750393134\n",
      "train loss:0.019886863359105545\n",
      "train loss:0.06933144478353333\n",
      "train loss:0.014027292939949126\n",
      "train loss:0.016757678673192843\n",
      "train loss:0.009320604346979136\n",
      "train loss:0.04989119666200034\n",
      "train loss:0.00966400142516852\n",
      "train loss:0.011771402168559857\n",
      "train loss:0.030201393833583428\n",
      "=== epoch:7, train acc:0.987, test acc:0.984 ===\n",
      "train loss:0.02540511148195471\n",
      "train loss:0.03186759504746421\n",
      "train loss:0.013276196232113886\n",
      "train loss:0.048450184076811356\n",
      "train loss:0.03651214026099009\n",
      "train loss:0.004796547721425244\n",
      "train loss:0.010971721158018134\n",
      "train loss:0.009430775325285034\n",
      "train loss:0.008754138924959968\n",
      "train loss:0.017098167824230598\n",
      "train loss:0.024705161073064436\n",
      "train loss:0.00943921613936322\n",
      "train loss:0.02226412893484015\n",
      "train loss:0.060230888939638835\n",
      "train loss:0.00779696842731038\n",
      "train loss:0.025151558624613938\n",
      "train loss:0.08528858009707882\n",
      "train loss:0.004378540898378689\n",
      "train loss:0.0069473394660045686\n",
      "train loss:0.019962455745018287\n",
      "train loss:0.0405255097388679\n",
      "train loss:0.011817496407246037\n",
      "train loss:0.035021468083049914\n",
      "train loss:0.031106431084942435\n",
      "train loss:0.010509116931348655\n",
      "train loss:0.0436714031628946\n",
      "train loss:0.017196315113157046\n",
      "train loss:0.07770867367596532\n",
      "train loss:0.00825095670243755\n",
      "train loss:0.005215382138838621\n",
      "train loss:0.03180718158089472\n",
      "train loss:0.037144241736205806\n",
      "train loss:0.030634529358474643\n",
      "train loss:0.01322052569123951\n",
      "train loss:0.02951747553154823\n",
      "train loss:0.012978783288819478\n",
      "train loss:0.013279560459910649\n",
      "train loss:0.007838277499499748\n",
      "train loss:0.010744461615595368\n",
      "train loss:0.016949743652517966\n",
      "train loss:0.028846043944280607\n",
      "train loss:0.013656990492376057\n",
      "train loss:0.011089789138478608\n",
      "train loss:0.009935673602339401\n",
      "train loss:0.04770229392165535\n",
      "train loss:0.039448027137654475\n",
      "train loss:0.012864338414689723\n",
      "train loss:0.018534374467297034\n",
      "train loss:0.0120874882475272\n",
      "train loss:0.006126407546650001\n",
      "train loss:0.011266814928798474\n",
      "train loss:0.031050121893958966\n",
      "train loss:0.005609831851040298\n",
      "train loss:0.018751136348635636\n",
      "train loss:0.029984182020678193\n",
      "train loss:0.018623324974074543\n",
      "train loss:0.002071713578275653\n",
      "train loss:0.020637329751528474\n",
      "train loss:0.012301381757572102\n",
      "train loss:0.007227752801389697\n",
      "train loss:0.00895263154372977\n",
      "train loss:0.006853094206223797\n",
      "train loss:0.012895677950165742\n",
      "train loss:0.04064939672809924\n",
      "train loss:0.0077089043026718155\n",
      "train loss:0.023555415491755972\n",
      "train loss:0.027421854599385318\n",
      "train loss:0.016877810597783746\n",
      "train loss:0.010925085131203724\n",
      "train loss:0.04685648967399361\n",
      "train loss:0.00705785537042982\n",
      "train loss:0.03649739882174591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027877262977970742\n",
      "train loss:0.012189043353585931\n",
      "train loss:0.009560121691115829\n",
      "train loss:0.025558955837256113\n",
      "train loss:0.01856711663311621\n",
      "train loss:0.008289247131226718\n",
      "train loss:0.010047472575889784\n",
      "train loss:0.03990991601875324\n",
      "train loss:0.0235674449155716\n",
      "train loss:0.018976360899204618\n",
      "train loss:0.03077651968822963\n",
      "train loss:0.037458021388036986\n",
      "train loss:0.007813305127091278\n",
      "train loss:0.015504292517722356\n",
      "train loss:0.030563238847191095\n",
      "train loss:0.036338090143944686\n",
      "train loss:0.026767927551666508\n",
      "train loss:0.017760983195607146\n",
      "train loss:0.004125369651577575\n",
      "train loss:0.0022772938871040097\n",
      "train loss:0.011575986588880491\n",
      "train loss:0.003754207611793721\n",
      "train loss:0.010664291239756374\n",
      "train loss:0.01416476805960954\n",
      "train loss:0.009809872043639858\n",
      "train loss:0.010134850511635317\n",
      "train loss:0.0040046777378091696\n",
      "train loss:0.02316412585505208\n",
      "train loss:0.015999611359845407\n",
      "train loss:0.010438368614685717\n",
      "train loss:0.0452278867998259\n",
      "train loss:0.01805983860095703\n",
      "train loss:0.03062082195260181\n",
      "train loss:0.005159029738431131\n",
      "train loss:0.0205173415484886\n",
      "train loss:0.016186168799199055\n",
      "train loss:0.009254403416806181\n",
      "train loss:0.005993268486189191\n",
      "train loss:0.0127371674390834\n",
      "train loss:0.017167733560189757\n",
      "train loss:0.004293482921202482\n",
      "train loss:0.003456369042793408\n",
      "train loss:0.008390115470958397\n",
      "train loss:0.013988607039654684\n",
      "train loss:0.016820071701359275\n",
      "train loss:0.007032542587666385\n",
      "train loss:0.02458260623197219\n",
      "train loss:0.019474265413285674\n",
      "train loss:0.009274841700026588\n",
      "train loss:0.0042780206935113104\n",
      "train loss:0.04737954446283989\n",
      "train loss:0.008026399486766391\n",
      "train loss:0.00993725400696617\n",
      "train loss:0.005544979745313844\n",
      "train loss:0.08629829718856767\n",
      "train loss:0.05365122339674447\n",
      "train loss:0.013959490747141545\n",
      "train loss:0.014449209976941267\n",
      "train loss:0.014297796627801085\n",
      "train loss:0.025877078953060968\n",
      "train loss:0.06162880528912041\n",
      "train loss:0.004268881387109017\n",
      "train loss:0.033383892926521525\n",
      "train loss:0.012995627775284681\n",
      "train loss:0.029875127825020376\n",
      "train loss:0.010236726469486786\n",
      "train loss:0.01703524502139788\n",
      "train loss:0.042482648333883884\n",
      "train loss:0.025455044838826636\n",
      "train loss:0.027218823220896273\n",
      "train loss:0.021828046014972857\n",
      "train loss:0.0785612573682711\n",
      "train loss:0.03876614010140258\n",
      "train loss:0.010721874087947567\n",
      "train loss:0.01131994410711985\n",
      "train loss:0.0046882979342573496\n",
      "train loss:0.06553234739107998\n",
      "train loss:0.012872590224197074\n",
      "train loss:0.07520360032990796\n",
      "train loss:0.004308734769288468\n",
      "train loss:0.008861575360986019\n",
      "train loss:0.005858022072229188\n",
      "train loss:0.08719019167898208\n",
      "train loss:0.02096540989782868\n",
      "train loss:0.009069529313535767\n",
      "train loss:0.005736930419753213\n",
      "train loss:0.004216781937791513\n",
      "train loss:0.01877724837098266\n",
      "train loss:0.02710265558052935\n",
      "train loss:0.002036817753568411\n",
      "train loss:0.0455568100080864\n",
      "train loss:0.010518180038187918\n",
      "train loss:0.02252784399992053\n",
      "train loss:0.011108942605812702\n",
      "train loss:0.02994822380700357\n",
      "train loss:0.03019880810187709\n",
      "train loss:0.027275775803407547\n",
      "train loss:0.014546954276380093\n",
      "train loss:0.01438124901091194\n",
      "train loss:0.01623624942575244\n",
      "train loss:0.02869011302902615\n",
      "train loss:0.02442411722976563\n",
      "train loss:0.015542618632908895\n",
      "train loss:0.005316207708194461\n",
      "train loss:0.006802945258189732\n",
      "train loss:0.0030326880379610986\n",
      "train loss:0.016840372324869096\n",
      "train loss:0.018777470238965033\n",
      "train loss:0.010154714158133\n",
      "train loss:0.001459943121105157\n",
      "train loss:0.01463966893409827\n",
      "train loss:0.009525841963624932\n",
      "train loss:0.004247345567027837\n",
      "train loss:0.061297797787221525\n",
      "train loss:0.002503236941043417\n",
      "train loss:0.010653250148556387\n",
      "train loss:0.02483042688983729\n",
      "train loss:0.004400385203481047\n",
      "train loss:0.004651151609040866\n",
      "train loss:0.006051929428755789\n",
      "train loss:0.013801389804223853\n",
      "train loss:0.003475669791285306\n",
      "train loss:0.019400321263386353\n",
      "train loss:0.03858535062601595\n",
      "train loss:0.023684831576879017\n",
      "train loss:0.024065646794213337\n",
      "train loss:0.01479198048811951\n",
      "train loss:0.043941013191792576\n",
      "train loss:0.010427717247941965\n",
      "train loss:0.005769899645774531\n",
      "train loss:0.023634535181860473\n",
      "train loss:0.019806461347934106\n",
      "train loss:0.01375085657497641\n",
      "train loss:0.018595736002352366\n",
      "train loss:0.00528160748891022\n",
      "train loss:0.011435401011168533\n",
      "train loss:0.013075520194314022\n",
      "train loss:0.008000636083467372\n",
      "train loss:0.008245835970157015\n",
      "train loss:0.024522146356191807\n",
      "train loss:0.013754900746386007\n",
      "train loss:0.02240421358545118\n",
      "train loss:0.018176966819400592\n",
      "train loss:0.007112649600243535\n",
      "train loss:0.0262487989774285\n",
      "train loss:0.014029446563495508\n",
      "train loss:0.01232006836132087\n",
      "train loss:0.02612619679117797\n",
      "train loss:0.010882422244964982\n",
      "train loss:0.006433410145403894\n",
      "train loss:0.07489379168085804\n",
      "train loss:0.007729203722790223\n",
      "train loss:0.012251937769041205\n",
      "train loss:0.007510776597432771\n",
      "train loss:0.0328122579545379\n",
      "train loss:0.0034956082103401783\n",
      "train loss:0.08819359166373063\n",
      "train loss:0.015339070551967714\n",
      "train loss:0.007603613460249423\n",
      "train loss:0.008848719477423049\n",
      "train loss:0.04516557790937331\n",
      "train loss:0.008137225467629546\n",
      "train loss:0.010768571327195975\n",
      "train loss:0.052562023394988854\n",
      "train loss:0.02423691993861227\n",
      "train loss:0.007054348751255445\n",
      "train loss:0.05116081480152308\n",
      "train loss:0.013150324406604998\n",
      "train loss:0.02442085807448919\n",
      "train loss:0.014218000485711021\n",
      "train loss:0.055923182264791774\n",
      "train loss:0.002429272890687729\n",
      "train loss:0.006465913242789326\n",
      "train loss:0.00835908987361337\n",
      "train loss:0.050253810970381056\n",
      "train loss:0.06353232104611575\n",
      "train loss:0.02685239236556109\n",
      "train loss:0.023505942929481355\n",
      "train loss:0.007964046116291151\n",
      "train loss:0.02369861097576958\n",
      "train loss:0.009876422811062921\n",
      "train loss:0.045092035236449696\n",
      "train loss:0.01806980567005274\n",
      "train loss:0.03252765438024461\n",
      "train loss:0.016667520950432887\n",
      "train loss:0.0533754921095753\n",
      "train loss:0.007590579459527854\n",
      "train loss:0.019136062947728003\n",
      "train loss:0.02110241900206119\n",
      "train loss:0.01104381917172463\n",
      "train loss:0.018275613666582396\n",
      "train loss:0.01641757594036899\n",
      "train loss:0.03557701745729496\n",
      "train loss:0.00601612119535777\n",
      "train loss:0.06445705262200216\n",
      "train loss:0.019670480609622724\n",
      "train loss:0.019946363707513157\n",
      "train loss:0.02190159508004107\n",
      "train loss:0.011237476386958021\n",
      "train loss:0.06709172364105805\n",
      "train loss:0.005015950093698845\n",
      "train loss:0.022394949145867128\n",
      "train loss:0.053427825766008595\n",
      "train loss:0.0047609292780484945\n",
      "train loss:0.017833854911652163\n",
      "train loss:0.019374977080644114\n",
      "train loss:0.015248814166137326\n",
      "train loss:0.015702994932351635\n",
      "train loss:0.0038916901838369727\n",
      "train loss:0.04791066641292698\n",
      "train loss:0.01450796673726589\n",
      "train loss:0.008716651613690759\n",
      "train loss:0.0425627058337494\n",
      "train loss:0.009681718590790402\n",
      "train loss:0.004848488220928277\n",
      "train loss:0.00223202375956447\n",
      "train loss:0.005027993168141818\n",
      "train loss:0.025531318994482445\n",
      "train loss:0.006311495402600054\n",
      "train loss:0.010584338123039251\n",
      "train loss:0.003933245287450091\n",
      "train loss:0.007921754726423808\n",
      "train loss:0.003313551262512772\n",
      "train loss:0.014848139229062075\n",
      "train loss:0.013776968258650013\n",
      "train loss:0.014201869666586975\n",
      "train loss:0.007034110531602828\n",
      "train loss:0.047032995062079995\n",
      "train loss:0.009933495643766926\n",
      "train loss:0.005624411082174\n",
      "train loss:0.05074001564696882\n",
      "train loss:0.010547789980904332\n",
      "train loss:0.009225052296197644\n",
      "train loss:0.010359656150035196\n",
      "train loss:0.008933919992650544\n",
      "train loss:0.04754900961385026\n",
      "train loss:0.007949713517039231\n",
      "train loss:0.03027560442319861\n",
      "train loss:0.005684598690443805\n",
      "train loss:0.002007803116164781\n",
      "train loss:0.015034692530267227\n",
      "train loss:0.019255606945847457\n",
      "train loss:0.013929878393309378\n",
      "train loss:0.0068554383584864065\n",
      "train loss:0.028141563200972438\n",
      "train loss:0.010161990377061884\n",
      "train loss:0.016079405216032877\n",
      "train loss:0.014058842269167284\n",
      "train loss:0.007138245685064331\n",
      "train loss:0.0034295386591109826\n",
      "train loss:0.010442013789358601\n",
      "train loss:0.019252788605705326\n",
      "train loss:0.021128470870504946\n",
      "train loss:0.07796131105545302\n",
      "train loss:0.03474560691468807\n",
      "train loss:0.03935447929540994\n",
      "train loss:0.0025076004910885015\n",
      "train loss:0.002980474152216584\n",
      "train loss:0.007770212250268801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01164239761233679\n",
      "train loss:0.027351024135998495\n",
      "train loss:0.014940818368260946\n",
      "train loss:0.048717018265780926\n",
      "train loss:0.10567744860859546\n",
      "train loss:0.012435233040845482\n",
      "train loss:0.011726149244455468\n",
      "train loss:0.031165905631103247\n",
      "train loss:0.04878736052402499\n",
      "train loss:0.00931215587650723\n",
      "train loss:0.0252918552850631\n",
      "train loss:0.010782837024546316\n",
      "train loss:0.013490794703819592\n",
      "train loss:0.08690427935012975\n",
      "train loss:0.013335107712864572\n",
      "train loss:0.005222132289025033\n",
      "train loss:0.0052790971934090925\n",
      "train loss:0.06011240199242488\n",
      "train loss:0.009714136651563947\n",
      "train loss:0.03943833629204769\n",
      "train loss:0.018295520731063757\n",
      "train loss:0.02509632946952194\n",
      "train loss:0.020442385238417685\n",
      "train loss:0.014177726270467208\n",
      "train loss:0.007079549826564485\n",
      "train loss:0.013567717121182377\n",
      "train loss:0.032292114354548415\n",
      "train loss:0.03713679883627978\n",
      "train loss:0.027172060929886065\n",
      "train loss:0.014445085933436968\n",
      "train loss:0.09378893047612694\n",
      "train loss:0.006269931839389108\n",
      "train loss:0.0286135138513144\n",
      "train loss:0.01897370129257399\n",
      "train loss:0.008212706787485818\n",
      "train loss:0.012484969395147105\n",
      "train loss:0.07261531195465394\n",
      "train loss:0.011554011222307193\n",
      "train loss:0.038883644785014354\n",
      "train loss:0.02096357988754782\n",
      "train loss:0.01813551107861743\n",
      "train loss:0.012910872221977702\n",
      "train loss:0.003920134299923092\n",
      "train loss:0.0024759724897717213\n",
      "train loss:0.0110017730378743\n",
      "train loss:0.015618972250245673\n",
      "train loss:0.05825906435762387\n",
      "train loss:0.018089317756091225\n",
      "train loss:0.008965429462582176\n",
      "train loss:0.013536442701191177\n",
      "train loss:0.007599869238309081\n",
      "train loss:0.019225882977078227\n",
      "train loss:0.011746100730972826\n",
      "train loss:0.028863715139473115\n",
      "train loss:0.006183255005650279\n",
      "train loss:0.04735070536825894\n",
      "train loss:0.061741445415072926\n",
      "train loss:0.006039862763697738\n",
      "train loss:0.114639800706244\n",
      "train loss:0.005570961402841147\n",
      "train loss:0.03696223261284388\n",
      "train loss:0.0415109907681932\n",
      "train loss:0.010106007962044942\n",
      "train loss:0.04797553528945595\n",
      "train loss:0.01948204260434998\n",
      "train loss:0.0028474822423622086\n",
      "train loss:0.015292276749603049\n",
      "train loss:0.018386617365724615\n",
      "train loss:0.020126943154606995\n",
      "train loss:0.06786362664820929\n",
      "train loss:0.010894553905455837\n",
      "train loss:0.015394409646118951\n",
      "train loss:0.04983277057782993\n",
      "train loss:0.014607429377434004\n",
      "train loss:0.006888554343611895\n",
      "train loss:0.021330355390661655\n",
      "train loss:0.01194403826476123\n",
      "train loss:0.004908161428180552\n",
      "train loss:0.04050238397602822\n",
      "train loss:0.022329367607162035\n",
      "train loss:0.0028025435218470163\n",
      "train loss:0.01262039352438314\n",
      "train loss:0.012447701252754864\n",
      "train loss:0.07293969407009673\n",
      "train loss:0.0028818007642614648\n",
      "train loss:0.013805718000447713\n",
      "train loss:0.021938599964268723\n",
      "train loss:0.012659363344592436\n",
      "train loss:0.005224922351561288\n",
      "train loss:0.008817584377361694\n",
      "train loss:0.011700413970286856\n",
      "train loss:0.05396655205285822\n",
      "train loss:0.006627078876896628\n",
      "train loss:0.024059070201866973\n",
      "train loss:0.011812303979798882\n",
      "train loss:0.02119658247362829\n",
      "train loss:0.006445040294340988\n",
      "train loss:0.008209675238006772\n",
      "train loss:0.057140902282949074\n",
      "train loss:0.003972562502912688\n",
      "train loss:0.005356679444017262\n",
      "train loss:0.01855327323611358\n",
      "train loss:0.0029450537205330256\n",
      "train loss:0.03384944504534231\n",
      "train loss:0.01876047213326443\n",
      "train loss:0.05306515665768816\n",
      "train loss:0.014815003068686447\n",
      "train loss:0.01594084271125168\n",
      "train loss:0.009306103940805102\n",
      "train loss:0.0027550606065400527\n",
      "train loss:0.005582996745072063\n",
      "train loss:0.03430199962049117\n",
      "train loss:0.03502873683195946\n",
      "train loss:0.001402810487622212\n",
      "train loss:0.0528667087179306\n",
      "train loss:0.027636536375402497\n",
      "train loss:0.006479966244760565\n",
      "train loss:0.02084189828470647\n",
      "train loss:0.005037953230493779\n",
      "train loss:0.00962012599624904\n",
      "train loss:0.023634619143498098\n",
      "train loss:0.0032692984297988613\n",
      "train loss:0.004243557335220654\n",
      "train loss:0.0077945709451431285\n",
      "train loss:0.009287609101495205\n",
      "train loss:0.013535317994558487\n",
      "train loss:0.02882450318961654\n",
      "train loss:0.00971287952275116\n",
      "train loss:0.03653511264439371\n",
      "train loss:0.018897029187113806\n",
      "train loss:0.009052729875722572\n",
      "train loss:0.004666063314183058\n",
      "train loss:0.006394895595601016\n",
      "train loss:0.0035230564200797055\n",
      "train loss:0.0486128341503869\n",
      "train loss:0.01860981029780156\n",
      "train loss:0.013268719153309905\n",
      "train loss:0.014802473813978739\n",
      "train loss:0.030254164289280416\n",
      "train loss:0.02360175176076333\n",
      "train loss:0.0013535985336194931\n",
      "train loss:0.007341739674286513\n",
      "train loss:0.03447134043995354\n",
      "train loss:0.010428267756020938\n",
      "train loss:0.002330765886387021\n",
      "train loss:0.02907795241693729\n",
      "train loss:0.0059173583039540765\n",
      "train loss:0.04300606675758613\n",
      "train loss:0.064679939525638\n",
      "train loss:0.008583261760427344\n",
      "train loss:0.0033973354868834372\n",
      "train loss:0.011130291283137465\n",
      "train loss:0.0007936397105517413\n",
      "train loss:0.05186868885418356\n",
      "train loss:0.009266633575969088\n",
      "train loss:0.016799905048314343\n",
      "train loss:0.023563641710505547\n",
      "train loss:0.013655175906060479\n",
      "train loss:0.02381801362789152\n",
      "train loss:0.014898887125505338\n",
      "train loss:0.01855599020359987\n",
      "train loss:0.01759443134543457\n",
      "train loss:0.01177014419340108\n",
      "train loss:0.03287127444250472\n",
      "train loss:0.007810601699954845\n",
      "train loss:0.009344811432431809\n",
      "train loss:0.02276025549957283\n",
      "train loss:0.004180842679220847\n",
      "train loss:0.007739241027908456\n",
      "train loss:0.046094753999188116\n",
      "train loss:0.011426810443516518\n",
      "train loss:0.014908000776210269\n",
      "train loss:0.051643306417043\n",
      "train loss:0.01090611331911113\n",
      "train loss:0.010507486560640046\n",
      "train loss:0.021828841187821538\n",
      "train loss:0.010756661114009622\n",
      "train loss:0.006868843573101852\n",
      "train loss:0.011214685565001225\n",
      "train loss:0.0026223380388852528\n",
      "train loss:0.007011236168177667\n",
      "train loss:0.010462851300879619\n",
      "train loss:0.013197473136490829\n",
      "train loss:0.026904829649007988\n",
      "train loss:0.022788581152308675\n",
      "train loss:0.08402200907112604\n",
      "train loss:0.021606106289605617\n",
      "train loss:0.05106938770393146\n",
      "train loss:0.004085269564983463\n",
      "train loss:0.015108398697202994\n",
      "train loss:0.005249662262132001\n",
      "train loss:0.005754003044540128\n",
      "train loss:0.005151421577516214\n",
      "train loss:0.004971471480621704\n",
      "train loss:0.02859745973686906\n",
      "train loss:0.0011669032137275241\n",
      "train loss:0.050389529384665836\n",
      "train loss:0.005281059557008225\n",
      "train loss:0.008090682171797856\n",
      "train loss:0.014563006150297726\n",
      "train loss:0.01592196870219003\n",
      "train loss:0.009418668673467287\n",
      "train loss:0.01854897916394972\n",
      "train loss:0.013378166017226103\n",
      "train loss:0.012525519058989248\n",
      "train loss:0.012744729320947685\n",
      "train loss:0.007253863011453663\n",
      "train loss:0.0053813754517601795\n",
      "train loss:0.009948466032623775\n",
      "train loss:0.007271674461744154\n",
      "train loss:0.003987821984612242\n",
      "train loss:0.04829461288014656\n",
      "train loss:0.02894932749007614\n",
      "train loss:0.002568851163693957\n",
      "train loss:0.014826964400968064\n",
      "train loss:0.015390512328809327\n",
      "train loss:0.00798656623160282\n",
      "train loss:0.0044863976036902346\n",
      "train loss:0.05509157629010089\n",
      "train loss:0.004271255754664452\n",
      "train loss:0.006834711546900875\n",
      "train loss:0.009913822452714865\n",
      "train loss:0.014104119483719488\n",
      "train loss:0.012765271595553835\n",
      "train loss:0.008247443496083386\n",
      "train loss:0.028173961021644198\n",
      "train loss:0.009105560548195774\n",
      "train loss:0.0048881815431518075\n",
      "train loss:0.02178319270938505\n",
      "train loss:0.0072836504762019225\n",
      "train loss:0.010574081571509028\n",
      "train loss:0.007336647760681792\n",
      "train loss:0.0025546907949406893\n",
      "train loss:0.004196827789924292\n",
      "train loss:0.013957382666896733\n",
      "train loss:0.022508197130459564\n",
      "train loss:0.004713776888941109\n",
      "train loss:0.017862214159430078\n",
      "train loss:0.01913892431463774\n",
      "train loss:0.008297664310864056\n",
      "train loss:0.027419277386383993\n",
      "train loss:0.013975441576242054\n",
      "train loss:0.0022964292760419037\n",
      "train loss:0.002194069625483773\n",
      "train loss:0.0015066548154298123\n",
      "train loss:0.02289101221144161\n",
      "train loss:0.006728898161692279\n",
      "train loss:0.09373837124074715\n",
      "train loss:0.008450078336532196\n",
      "train loss:0.013303010266982988\n",
      "train loss:0.018620444847321158\n",
      "train loss:0.0019423685893932483\n",
      "train loss:0.0058303338562814555\n",
      "train loss:0.035062710223605735\n",
      "train loss:0.005186367010812022\n",
      "train loss:0.0786126396093509\n",
      "train loss:0.025372567779658663\n",
      "train loss:0.004317535811002159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01658014536947421\n",
      "train loss:0.01619910612095958\n",
      "train loss:0.02263769507056845\n",
      "train loss:0.010997929931027961\n",
      "train loss:0.004646917064110711\n",
      "train loss:0.018403667821336976\n",
      "train loss:0.00829159481496734\n",
      "train loss:0.0034872275757515964\n",
      "train loss:0.016536128924253074\n",
      "train loss:0.005302115679620654\n",
      "train loss:0.10334948540711056\n",
      "=== epoch:8, train acc:0.99, test acc:0.985 ===\n",
      "train loss:0.003355687128119767\n",
      "train loss:0.00859328569165647\n",
      "train loss:0.00654758225285518\n",
      "train loss:0.010955693104137566\n",
      "train loss:0.012931892250876218\n",
      "train loss:0.0524177978893173\n",
      "train loss:0.004755913550394184\n",
      "train loss:0.00636575802209938\n",
      "train loss:0.01726102521742643\n",
      "train loss:0.0055733435453175825\n",
      "train loss:0.018820843777288713\n",
      "train loss:0.014774924111737728\n",
      "train loss:0.007378889895063484\n",
      "train loss:0.007476097033831325\n",
      "train loss:0.010221439700318545\n",
      "train loss:0.006171678449758525\n",
      "train loss:0.013946486641831924\n",
      "train loss:0.007421981862489171\n",
      "train loss:0.002848721353825178\n",
      "train loss:0.0053272235723514786\n",
      "train loss:0.007489163215989961\n",
      "train loss:0.005094624993494466\n",
      "train loss:0.017032671474021384\n",
      "train loss:0.01930704493505922\n",
      "train loss:0.023635943277342926\n",
      "train loss:0.025589925931612138\n",
      "train loss:0.010494210988693792\n",
      "train loss:0.0066169203583055945\n",
      "train loss:0.01393452564315901\n",
      "train loss:0.017317877285917386\n",
      "train loss:0.008591033154990994\n",
      "train loss:0.01155665658751219\n",
      "train loss:0.006475744794901158\n",
      "train loss:0.0028774726749804707\n",
      "train loss:0.006326434286730438\n",
      "train loss:0.01201142955832769\n",
      "train loss:0.02961949225364503\n",
      "train loss:0.0018298200549295616\n",
      "train loss:0.014526618205809196\n",
      "train loss:0.010726726600934693\n",
      "train loss:0.004908391598054172\n",
      "train loss:0.005833891881138709\n",
      "train loss:0.007531374959503088\n",
      "train loss:0.0075190483500190445\n",
      "train loss:0.01843574644990417\n",
      "train loss:0.004010847572028784\n",
      "train loss:0.020382473206582125\n",
      "train loss:0.04863928672212751\n",
      "train loss:0.002534395380293427\n",
      "train loss:0.02982862485158569\n",
      "train loss:0.017904648486285597\n",
      "train loss:0.016043390420584048\n",
      "train loss:0.01901785862232417\n",
      "train loss:0.01871097834457364\n",
      "train loss:0.001426908539380647\n",
      "train loss:0.043821770494596894\n",
      "train loss:0.04477566052916756\n",
      "train loss:0.03528177427429012\n",
      "train loss:0.02574975546183286\n",
      "train loss:0.034366539617325075\n",
      "train loss:0.010683301941855397\n",
      "train loss:0.015323128332131031\n",
      "train loss:0.008664220293995651\n",
      "train loss:0.011715585528180958\n",
      "train loss:0.04602054799467271\n",
      "train loss:0.002243071372235844\n",
      "train loss:0.020799705746172827\n",
      "train loss:0.019458884262318177\n",
      "train loss:0.0012821096269502335\n",
      "train loss:0.11957579449862822\n",
      "train loss:0.019875444190164415\n",
      "train loss:0.0946017983848714\n",
      "train loss:0.0036173759858918963\n",
      "train loss:0.033814620295212545\n",
      "train loss:0.01910422371519854\n",
      "train loss:0.011791046887793324\n",
      "train loss:0.028529765422922557\n",
      "train loss:0.06176198006107772\n",
      "train loss:0.005178371520538842\n",
      "train loss:0.007155919733717531\n",
      "train loss:0.02036116851975987\n",
      "train loss:0.0679338913533736\n",
      "train loss:0.013876859859274993\n",
      "train loss:0.007582925721035172\n",
      "train loss:0.029160342012671658\n",
      "train loss:0.05101531152911092\n",
      "train loss:0.005922349797586217\n",
      "train loss:0.0057806457989957715\n",
      "train loss:0.0037293327114012982\n",
      "train loss:0.023759610530342572\n",
      "train loss:0.021040443585466043\n",
      "train loss:0.00557079406257435\n",
      "train loss:0.009275487759259593\n",
      "train loss:0.03370106188694476\n",
      "train loss:0.019050625126801314\n",
      "train loss:0.012457039456851065\n",
      "train loss:0.018592806978956742\n",
      "train loss:0.004917204265707145\n",
      "train loss:0.0040507935477337356\n",
      "train loss:0.09031031651369414\n",
      "train loss:0.0017782832059068205\n",
      "train loss:0.006077161384169807\n",
      "train loss:0.010154502892204454\n",
      "train loss:0.01626307928862466\n",
      "train loss:0.005453207131795225\n",
      "train loss:0.06028154439812216\n",
      "train loss:0.011911177696394312\n",
      "train loss:0.021565052589154386\n",
      "train loss:0.04900606965201169\n",
      "train loss:0.00249738929086655\n",
      "train loss:0.038744961199171604\n",
      "train loss:0.0024810418511103318\n",
      "train loss:0.01963515645131027\n",
      "train loss:0.01441518398000062\n",
      "train loss:0.0255942786557793\n",
      "train loss:0.007006625073156522\n",
      "train loss:0.01733921689253691\n",
      "train loss:0.03256319894219572\n",
      "train loss:0.0024611082057012152\n",
      "train loss:0.0020389183579563753\n",
      "train loss:0.007319337769179701\n",
      "train loss:0.009011371059372553\n",
      "train loss:0.020057551462693363\n",
      "train loss:0.008953221274794285\n",
      "train loss:0.01006668708737183\n",
      "train loss:0.006533358835867705\n",
      "train loss:0.012936037225856161\n",
      "train loss:0.0015983029650885041\n",
      "train loss:0.0063880848710599495\n",
      "train loss:0.010630754198798453\n",
      "train loss:0.007486517631148174\n",
      "train loss:0.01943135686961538\n",
      "train loss:0.02920123629385688\n",
      "train loss:0.009797526072847845\n",
      "train loss:0.005273108201391298\n",
      "train loss:0.020179794723162957\n",
      "train loss:0.0216575211351672\n",
      "train loss:0.04238512406470666\n",
      "train loss:0.05368487040450152\n",
      "train loss:0.0053892657460562045\n",
      "train loss:0.0323678638216754\n",
      "train loss:0.005355932041813937\n",
      "train loss:0.054484358028895195\n",
      "train loss:0.007620290423174494\n",
      "train loss:0.0058290581791766395\n",
      "train loss:0.06353769803756723\n",
      "train loss:0.009432345650858577\n",
      "train loss:0.01498313726863052\n",
      "train loss:0.10295721533177088\n",
      "train loss:0.020877737178910314\n",
      "train loss:0.015322158414889651\n",
      "train loss:0.002728307170138688\n",
      "train loss:0.031527771476937985\n",
      "train loss:0.004268419734030347\n",
      "train loss:0.014626846212921627\n",
      "train loss:0.020373730847236145\n",
      "train loss:0.035498271313981505\n",
      "train loss:0.010936443844912236\n",
      "train loss:0.012426202321995697\n",
      "train loss:0.028052329343974974\n",
      "train loss:0.005710237592142773\n",
      "train loss:0.013373030434992222\n",
      "train loss:0.005116582262712023\n",
      "train loss:0.007287413821813111\n",
      "train loss:0.02198276114865518\n",
      "train loss:0.00606284959063316\n",
      "train loss:0.02077376680137265\n",
      "train loss:0.006134832811111337\n",
      "train loss:0.002112283472771697\n",
      "train loss:0.021581427974029753\n",
      "train loss:0.02437609549949028\n",
      "train loss:0.00724498881864471\n",
      "train loss:0.002092679067977594\n",
      "train loss:0.012827882114438176\n",
      "train loss:0.013833087366183048\n",
      "train loss:0.006437259191200759\n",
      "train loss:0.012315178278633467\n",
      "train loss:0.014204826845198698\n",
      "train loss:0.011055595984868131\n",
      "train loss:0.0037534889944733285\n",
      "train loss:0.035185436671494624\n",
      "train loss:0.02346572921989641\n",
      "train loss:0.0068456558564650724\n",
      "train loss:0.025465450295079538\n",
      "train loss:0.004444189421350681\n",
      "train loss:0.01511816059750472\n",
      "train loss:0.02168140251134244\n",
      "train loss:0.017501656189881216\n",
      "train loss:0.013081337500426933\n",
      "train loss:0.043382340455415856\n",
      "train loss:0.006839552027151331\n",
      "train loss:0.005520748865064901\n",
      "train loss:0.015520241566423208\n",
      "train loss:0.016595463940092245\n",
      "train loss:0.003944563691491392\n",
      "train loss:0.018370991242900207\n",
      "train loss:0.02726388049603956\n",
      "train loss:0.043807521464867466\n",
      "train loss:0.002818091787471121\n",
      "train loss:0.02255791961899971\n",
      "train loss:0.04775930110256318\n",
      "train loss:0.007611232886637755\n",
      "train loss:0.00776853629327198\n",
      "train loss:0.006116166389479299\n",
      "train loss:0.04815441739487237\n",
      "train loss:0.050707864652439906\n",
      "train loss:0.0034633470368957897\n",
      "train loss:0.028970380443550933\n",
      "train loss:0.02004345439212532\n",
      "train loss:0.012809103647416126\n",
      "train loss:0.025245225119649807\n",
      "train loss:0.032318065819872\n",
      "train loss:0.004114548709630298\n",
      "train loss:0.007526679413371139\n",
      "train loss:0.004012701361553207\n",
      "train loss:0.003882814734758273\n",
      "train loss:0.005294236442243472\n",
      "train loss:0.0016761899629885776\n",
      "train loss:0.0078005022687315136\n",
      "train loss:0.009370408423737327\n",
      "train loss:0.004112227287563673\n",
      "train loss:0.008389527030331696\n",
      "train loss:0.013044533081903478\n",
      "train loss:0.009064170067517297\n",
      "train loss:0.04576277637222938\n",
      "train loss:0.012607613438566288\n",
      "train loss:0.002428846733300003\n",
      "train loss:0.04099355486450236\n",
      "train loss:0.019766401602419607\n",
      "train loss:0.007041819498765656\n",
      "train loss:0.005564836871988936\n",
      "train loss:0.005382180126435028\n",
      "train loss:0.011098218725522767\n",
      "train loss:0.005561395071191153\n",
      "train loss:0.010660688622424742\n",
      "train loss:0.006677919642639324\n",
      "train loss:0.007568981562762245\n",
      "train loss:0.002503173279100679\n",
      "train loss:0.0008428932807799412\n",
      "train loss:0.011090068464145184\n",
      "train loss:0.003232382054918852\n",
      "train loss:0.007062075062039751\n",
      "train loss:0.004406001352088642\n",
      "train loss:0.01875092767187243\n",
      "train loss:0.02720112350970851\n",
      "train loss:0.01265602358625047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004924996003381971\n",
      "train loss:0.0012365200779239074\n",
      "train loss:0.005063062735346603\n",
      "train loss:0.0062863945779750244\n",
      "train loss:0.01014338804870638\n",
      "train loss:0.0037521695104926756\n",
      "train loss:0.005178065786437718\n",
      "train loss:0.005251661256952655\n",
      "train loss:0.0063239985709832415\n",
      "train loss:0.02157798074622183\n",
      "train loss:0.00974674760798014\n",
      "train loss:0.012035340852974065\n",
      "train loss:0.0037879725447067273\n",
      "train loss:0.0024617065366520836\n",
      "train loss:0.09947478141941339\n",
      "train loss:0.004625206716192056\n",
      "train loss:0.014264000932109042\n",
      "train loss:0.014496295355472756\n",
      "train loss:0.0049406372297473205\n",
      "train loss:0.003875463239773223\n",
      "train loss:0.036684744513034856\n",
      "train loss:0.008512338658641691\n",
      "train loss:0.050638234758264435\n",
      "train loss:0.012790305235470336\n",
      "train loss:0.0021685103098009004\n",
      "train loss:0.00385621934780981\n",
      "train loss:0.00664230034270111\n",
      "train loss:0.01078416492781149\n",
      "train loss:0.02504631007972204\n",
      "train loss:0.009680192085579081\n",
      "train loss:0.0041788798325226\n",
      "train loss:0.002919701076421199\n",
      "train loss:0.07568278398235409\n",
      "train loss:0.020081466881200702\n",
      "train loss:0.02630493294024512\n",
      "train loss:0.005718587104522297\n",
      "train loss:0.025628635884396216\n",
      "train loss:0.008077574571420386\n",
      "train loss:0.002161571123521619\n",
      "train loss:0.0039979309954847105\n",
      "train loss:0.008844983196980783\n",
      "train loss:0.013217512128329018\n",
      "train loss:0.008452580806180013\n",
      "train loss:0.04355442145293882\n",
      "train loss:0.007748095007217429\n",
      "train loss:0.0029895583118966632\n",
      "train loss:0.008549778592798466\n",
      "train loss:0.0026602972963520087\n",
      "train loss:0.005234732356307521\n",
      "train loss:0.00789905095731062\n",
      "train loss:0.0006852694173353605\n",
      "train loss:0.008864318844663273\n",
      "train loss:0.028699894437476954\n",
      "train loss:0.001603692103717608\n",
      "train loss:0.0029853004803661524\n",
      "train loss:0.015733583348583838\n",
      "train loss:0.011103547839507217\n",
      "train loss:0.0025562147124794142\n",
      "train loss:0.0295507686154369\n",
      "train loss:0.010279102177526528\n",
      "train loss:0.0012797653285371998\n",
      "train loss:0.004586758624047661\n",
      "train loss:0.012809239706560093\n",
      "train loss:0.01869653547901586\n",
      "train loss:0.01596747311416148\n",
      "train loss:0.013438921748851185\n",
      "train loss:0.005288282942943546\n",
      "train loss:0.010417356001716529\n",
      "train loss:0.036545048638334576\n",
      "train loss:0.009120271672755885\n",
      "train loss:0.0039809907331940595\n",
      "train loss:0.0027386037764536115\n",
      "train loss:0.016912115976168766\n",
      "train loss:0.0029530146754613816\n",
      "train loss:0.007802955506319068\n",
      "train loss:0.003765097488775689\n",
      "train loss:0.01124391209217388\n",
      "train loss:0.04689240077809949\n",
      "train loss:0.011869439295891708\n",
      "train loss:0.0026811887727407084\n",
      "train loss:0.06281472608229681\n",
      "train loss:0.0017736647373636997\n",
      "train loss:0.013531773210431211\n",
      "train loss:0.008723584428558178\n",
      "train loss:0.00818802307450435\n",
      "train loss:0.010621042592696356\n",
      "train loss:0.04187461532389535\n",
      "train loss:0.00972725340632029\n",
      "train loss:0.0175176500974739\n",
      "train loss:0.015323879719649889\n",
      "train loss:0.029734952777498554\n",
      "train loss:0.0042922837488044065\n",
      "train loss:0.0068230062346500975\n",
      "train loss:0.010214004247869264\n",
      "train loss:0.023860075147773406\n",
      "train loss:0.00450115861720039\n",
      "train loss:0.02056254805767308\n",
      "train loss:0.05418055500577235\n",
      "train loss:0.0660387578681718\n",
      "train loss:0.01992153992045059\n",
      "train loss:0.004798780830391884\n",
      "train loss:0.006293723337880013\n",
      "train loss:0.014442527113032495\n",
      "train loss:0.007351182531256972\n",
      "train loss:0.008667300970332147\n",
      "train loss:0.005254507339218549\n",
      "train loss:0.006875736973958879\n",
      "train loss:0.004509593022218134\n",
      "train loss:0.02094674444823318\n",
      "train loss:0.0050078138670411046\n",
      "train loss:0.0013942821532003638\n",
      "train loss:0.0006936139281614538\n",
      "train loss:0.015663531777171526\n",
      "train loss:0.0033199433289524227\n",
      "train loss:0.005634682982700261\n",
      "train loss:0.047859978556456066\n",
      "train loss:0.003567581645366829\n",
      "train loss:0.012606860196836728\n",
      "train loss:0.0013894242560759254\n",
      "train loss:0.003993987095322636\n",
      "train loss:0.010846424321296651\n",
      "train loss:0.014031886196943098\n",
      "train loss:0.0025928779036479143\n",
      "train loss:0.014315485141745299\n",
      "train loss:0.017814382155110324\n",
      "train loss:0.031717433263722464\n",
      "train loss:0.006220347950159234\n",
      "train loss:0.020881272636273655\n",
      "train loss:0.013505174107409883\n",
      "train loss:0.0031814715836415335\n",
      "train loss:0.005650650369341254\n",
      "train loss:0.015832941492710712\n",
      "train loss:0.01661443539709523\n",
      "train loss:0.006452119889820448\n",
      "train loss:0.003147868548307544\n",
      "train loss:0.00773614960102871\n",
      "train loss:0.011993343325824267\n",
      "train loss:0.0332898469898897\n",
      "train loss:0.001841642161676797\n",
      "train loss:0.009416437857052486\n",
      "train loss:0.05665746229118203\n",
      "train loss:0.0055385507785518885\n",
      "train loss:0.009187967986885297\n",
      "train loss:0.009334677790638074\n",
      "train loss:0.0043713132227994325\n",
      "train loss:0.0063508824221018305\n",
      "train loss:0.004567789292957494\n",
      "train loss:0.010780345021872173\n",
      "train loss:0.01699807107013045\n",
      "train loss:0.020439438335209732\n",
      "train loss:0.0029873821083700692\n",
      "train loss:0.004029693674818407\n",
      "train loss:0.06269435795657974\n",
      "train loss:0.024971619992568327\n",
      "train loss:0.07838332137368365\n",
      "train loss:0.06669708472336998\n",
      "train loss:0.006164209843444215\n",
      "train loss:0.019523664232198566\n",
      "train loss:0.004600175060197603\n",
      "train loss:0.00986483288166802\n",
      "train loss:0.004750823818827437\n",
      "train loss:0.001457810355899879\n",
      "train loss:0.012863657050275\n",
      "train loss:0.01957547602349448\n",
      "train loss:0.0038515975272170573\n",
      "train loss:0.004957662769250278\n",
      "train loss:0.0029454452383306314\n",
      "train loss:0.003714219803928992\n",
      "train loss:0.05156210820315569\n",
      "train loss:0.0060176242550895155\n",
      "train loss:0.011612979242246182\n",
      "train loss:0.004783034119368658\n",
      "train loss:0.007146676480551812\n",
      "train loss:0.030026443702091066\n",
      "train loss:0.007337131843102362\n",
      "train loss:0.006940219231430466\n",
      "train loss:0.00577626716660402\n",
      "train loss:0.0030244915193211653\n",
      "train loss:0.011366948322564945\n",
      "train loss:0.0019441277614150035\n",
      "train loss:0.028603147637135812\n",
      "train loss:0.015707616149407185\n",
      "train loss:0.0192431249060501\n",
      "train loss:0.007486717986916782\n",
      "train loss:0.0023333958454987698\n",
      "train loss:0.0036337218972105558\n",
      "train loss:0.0077752202521421355\n",
      "train loss:0.024704178462226042\n",
      "train loss:0.024262014901432906\n",
      "train loss:0.03833130738493638\n",
      "train loss:0.020429793041447823\n",
      "train loss:0.019717631077643474\n",
      "train loss:0.0032271412411594646\n",
      "train loss:0.0007807138601242964\n",
      "train loss:0.0024173535271806096\n",
      "train loss:0.010484720585210477\n",
      "train loss:0.005753547958277192\n",
      "train loss:0.010525652090862132\n",
      "train loss:0.0991385362404867\n",
      "train loss:0.01581783669684819\n",
      "train loss:0.002412391438401083\n",
      "train loss:0.016787332603709695\n",
      "train loss:0.022483850636890658\n",
      "train loss:0.005271426142835882\n",
      "train loss:0.011566140750204582\n",
      "train loss:0.022975826201421613\n",
      "train loss:0.00537580982529336\n",
      "train loss:0.010844521875765374\n",
      "train loss:0.014351610552808076\n",
      "train loss:0.035451708322602984\n",
      "train loss:0.0046459161963951995\n",
      "train loss:0.006320383472171304\n",
      "train loss:0.0071464329030871444\n",
      "train loss:0.010163922877277892\n",
      "train loss:0.02379150935037428\n",
      "train loss:0.007565780543219586\n",
      "train loss:0.009150336120461402\n",
      "train loss:0.008526749200488841\n",
      "train loss:0.009723038729937353\n",
      "train loss:0.0017453570628483581\n",
      "train loss:0.0007006914288024051\n",
      "train loss:0.010060626697879702\n",
      "train loss:0.0034579236845351706\n",
      "train loss:0.001353025311663841\n",
      "train loss:0.005617620295570041\n",
      "train loss:0.0010090321201450965\n",
      "train loss:0.020159258086307714\n",
      "train loss:0.037115394390079846\n",
      "train loss:0.008453300428207269\n",
      "train loss:0.01679253829027623\n",
      "train loss:0.032502498147800186\n",
      "train loss:0.0030407159138026428\n",
      "train loss:0.0104963814533957\n",
      "train loss:0.003026052677625417\n",
      "train loss:0.006320131411750408\n",
      "train loss:0.015916754050239772\n",
      "train loss:0.008572429227535606\n",
      "train loss:0.005954585568810572\n",
      "train loss:0.0015669049446356024\n",
      "train loss:0.0033248373429810925\n",
      "train loss:0.0062765478809278545\n",
      "train loss:0.014969814728416284\n",
      "train loss:0.06367835668922489\n",
      "train loss:0.006932360068115052\n",
      "train loss:0.002145186250668521\n",
      "train loss:0.0073068297244605965\n",
      "train loss:0.010811809400829674\n",
      "train loss:0.007393452838145519\n",
      "train loss:0.07321675245682145\n",
      "train loss:0.013608592567068908\n",
      "train loss:0.005119702983674861\n",
      "train loss:0.0021904829340737586\n",
      "train loss:0.0007206965408351708\n",
      "train loss:0.018873388714663864\n",
      "train loss:0.0028174428697544333\n",
      "train loss:0.01248879226721188\n",
      "train loss:0.015477306300843548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018130557128302253\n",
      "train loss:0.03500319241821867\n",
      "train loss:0.017619486451684242\n",
      "train loss:0.015120375625249554\n",
      "train loss:0.003182314021244862\n",
      "train loss:0.04631778109844559\n",
      "train loss:0.022811761371864428\n",
      "train loss:0.01701576041383939\n",
      "train loss:0.020322516496450983\n",
      "train loss:0.011413208612268582\n",
      "train loss:0.008197036139786095\n",
      "train loss:0.0011218534368141605\n",
      "train loss:0.003791075224791205\n",
      "train loss:0.0006485361258699829\n",
      "train loss:0.039779744071668406\n",
      "train loss:0.008460990632359298\n",
      "train loss:0.0033756718464228357\n",
      "train loss:0.007424804061988436\n",
      "train loss:0.005185714588826498\n",
      "train loss:0.04069000644536861\n",
      "train loss:0.02800572730233526\n",
      "train loss:0.022242001647051975\n",
      "train loss:0.013829289497011024\n",
      "train loss:0.0053609669917924554\n",
      "train loss:0.02137732930537955\n",
      "train loss:0.007771224249843456\n",
      "train loss:0.00420959481389177\n",
      "train loss:0.004451804517179177\n",
      "train loss:0.016333838211921598\n",
      "train loss:0.006601575017397657\n",
      "train loss:0.016931681213382545\n",
      "train loss:0.03518477701811231\n",
      "train loss:0.014301969114625217\n",
      "train loss:0.0031279502834016064\n",
      "train loss:0.005197588635244115\n",
      "train loss:0.00887850281849607\n",
      "train loss:0.018808028044825235\n",
      "train loss:0.011496403418511348\n",
      "train loss:0.0068194622534990664\n",
      "train loss:0.015185703425825738\n",
      "train loss:0.014141937458399416\n",
      "train loss:0.006720396238295119\n",
      "train loss:0.04239668918291705\n",
      "train loss:0.01834271154436854\n",
      "train loss:0.03875975205288675\n",
      "train loss:0.035908984512341126\n",
      "train loss:0.005413982160776039\n",
      "train loss:0.010162257925698123\n",
      "train loss:0.007107231697989827\n",
      "train loss:0.005189753898291671\n",
      "train loss:0.004740245248808622\n",
      "train loss:0.033648129703635524\n",
      "train loss:0.003317537150935595\n",
      "train loss:0.005051240485830016\n",
      "train loss:0.0034532312485534844\n",
      "train loss:0.0048848288419086955\n",
      "train loss:0.015475121478682616\n",
      "train loss:0.010394499752366755\n",
      "train loss:0.01328232811680242\n",
      "train loss:0.004811082365384016\n",
      "train loss:0.009287393115850487\n",
      "train loss:0.009357926386456378\n",
      "train loss:0.00829656919981383\n",
      "train loss:0.0035633776574228175\n",
      "train loss:0.011093398102894149\n",
      "train loss:0.02552014715721829\n",
      "train loss:0.00211701117933245\n",
      "train loss:0.014845699032730092\n",
      "train loss:0.0213294520982545\n",
      "train loss:0.030267358277979085\n",
      "train loss:0.009347938956849839\n",
      "train loss:0.005517271312002929\n",
      "train loss:0.0031686748188484632\n",
      "train loss:0.014815504092159615\n",
      "train loss:0.017624280861510213\n",
      "train loss:0.02360237967536785\n",
      "train loss:0.00985019009133412\n",
      "train loss:0.007350858845044757\n",
      "train loss:0.0052252545424725716\n",
      "train loss:0.032515658140627804\n",
      "train loss:0.012219279980074337\n",
      "train loss:0.020604178628494448\n",
      "train loss:0.008902539024413339\n",
      "train loss:0.009511893143328218\n",
      "train loss:0.005620688252277363\n",
      "train loss:0.003587790488840517\n",
      "train loss:0.005641733569746245\n",
      "train loss:0.002932585652744598\n",
      "train loss:0.000688208523295136\n",
      "train loss:0.0024445701837310222\n",
      "train loss:0.0024683571560914\n",
      "train loss:0.03936192553352349\n",
      "train loss:0.0019593797355666512\n",
      "train loss:0.011500869527505736\n",
      "train loss:0.005029988735646681\n",
      "train loss:0.0034423485375796974\n",
      "train loss:0.0030744017380072825\n",
      "=== epoch:9, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.005120477622882525\n",
      "train loss:0.01651655147787713\n",
      "train loss:0.001741077064018305\n",
      "train loss:0.029201085620975772\n",
      "train loss:0.005382219605864379\n",
      "train loss:0.0045262855988655246\n",
      "train loss:0.018555860319837886\n",
      "train loss:0.005376890906137624\n",
      "train loss:0.024447509477963737\n",
      "train loss:0.030663629490895142\n",
      "train loss:0.01770832435595907\n",
      "train loss:0.0044413675497476076\n",
      "train loss:0.012710297740119968\n",
      "train loss:0.01812867009660458\n",
      "train loss:0.050588094056748086\n",
      "train loss:0.031689173047925914\n",
      "train loss:0.006270230994172982\n",
      "train loss:0.00698533809218578\n",
      "train loss:0.01391556671791214\n",
      "train loss:0.03311418624656033\n",
      "train loss:0.00722098127168302\n",
      "train loss:0.0029214344536379728\n",
      "train loss:0.00909251689904929\n",
      "train loss:0.019114447182719995\n",
      "train loss:0.04784449986602451\n",
      "train loss:0.007322093075790504\n",
      "train loss:0.0033302361606876176\n",
      "train loss:0.007766520643521313\n",
      "train loss:0.04297036757514031\n",
      "train loss:0.011061141046689277\n",
      "train loss:0.004272433946352809\n",
      "train loss:0.0013264467539658433\n",
      "train loss:0.023598417674624977\n",
      "train loss:0.005250447069618048\n",
      "train loss:0.008050602157075185\n",
      "train loss:0.00324907992900027\n",
      "train loss:0.07454285983073962\n",
      "train loss:0.0233270862306236\n",
      "train loss:0.013815492435561832\n",
      "train loss:0.009558208469872922\n",
      "train loss:0.007703122839660412\n",
      "train loss:0.0010846709902319293\n",
      "train loss:0.006611289267219462\n",
      "train loss:0.009281393744129158\n",
      "train loss:0.0015488023392956755\n",
      "train loss:0.004251159084088024\n",
      "train loss:0.006557300235500569\n",
      "train loss:0.023228618280777255\n",
      "train loss:0.004425796058853158\n",
      "train loss:0.011868026819481452\n",
      "train loss:0.006671501848204877\n",
      "train loss:0.0030810471651005517\n",
      "train loss:0.005185107741846066\n",
      "train loss:0.00477542898083603\n",
      "train loss:0.015752154248215515\n",
      "train loss:0.019575018759252393\n",
      "train loss:0.025588200456702896\n",
      "train loss:0.001574468994217556\n",
      "train loss:0.005398881880739705\n",
      "train loss:0.011227765259531038\n",
      "train loss:0.0008616435818389438\n",
      "train loss:0.05274379752150247\n",
      "train loss:0.004955844443850571\n",
      "train loss:0.009571297749201024\n",
      "train loss:0.02211081378860163\n",
      "train loss:0.004834441248873869\n",
      "train loss:0.006894329662512081\n",
      "train loss:0.001662559765141769\n",
      "train loss:0.02185918041419692\n",
      "train loss:0.001929757107166549\n",
      "train loss:0.017428545717231816\n",
      "train loss:0.0011353275192961644\n",
      "train loss:0.006932529487620132\n",
      "train loss:0.004221043479515853\n",
      "train loss:0.019719879121849103\n",
      "train loss:0.002081344113224454\n",
      "train loss:0.013938663850884199\n",
      "train loss:0.018075464169759737\n",
      "train loss:0.04719290093282688\n",
      "train loss:0.007309790208569962\n",
      "train loss:0.011030028482388574\n",
      "train loss:0.011979057712804705\n",
      "train loss:0.00995986962358358\n",
      "train loss:0.03463927542407228\n",
      "train loss:0.05827526170248094\n",
      "train loss:0.029427618457765127\n",
      "train loss:0.0158075767489539\n",
      "train loss:0.020037492869492586\n",
      "train loss:0.07457299571034366\n",
      "train loss:0.026167503928097503\n",
      "train loss:0.002731825189266155\n",
      "train loss:0.005800670988340594\n",
      "train loss:0.003538863980079883\n",
      "train loss:0.011487169336885704\n",
      "train loss:0.0062419168017793444\n",
      "train loss:0.006319559141462137\n",
      "train loss:0.01404034054443159\n",
      "train loss:0.05084427831640872\n",
      "train loss:0.005837211130427876\n",
      "train loss:0.00435536362892418\n",
      "train loss:0.03652897576565945\n",
      "train loss:0.008547204356806998\n",
      "train loss:0.0552599601016639\n",
      "train loss:0.022648538894077638\n",
      "train loss:0.003506868749386325\n",
      "train loss:0.026169627777056\n",
      "train loss:0.013335257311466236\n",
      "train loss:0.011128294441863095\n",
      "train loss:0.0028849861971852304\n",
      "train loss:0.0041606324420781415\n",
      "train loss:0.006280310231168433\n",
      "train loss:0.004769386430552958\n",
      "train loss:0.004217677649898011\n",
      "train loss:0.007900095354941558\n",
      "train loss:0.0059008782944029595\n",
      "train loss:0.009799182630670847\n",
      "train loss:0.01878724151249656\n",
      "train loss:0.00420350785211987\n",
      "train loss:0.0052502594338545705\n",
      "train loss:0.005595550547171003\n",
      "train loss:0.0043040047422898955\n",
      "train loss:0.009942897435167165\n",
      "train loss:0.022924275558954262\n",
      "train loss:0.005946684990514717\n",
      "train loss:0.01611084073586939\n",
      "train loss:0.01220818335314621\n",
      "train loss:0.010686621883477574\n",
      "train loss:0.003954018489706513\n",
      "train loss:0.010108309576210141\n",
      "train loss:0.005600046214468097\n",
      "train loss:0.012651445294124852\n",
      "train loss:0.018219208320531925\n",
      "train loss:0.006464484216219348\n",
      "train loss:0.03742886327403341\n",
      "train loss:0.013413721200788558\n",
      "train loss:0.01020307297793002\n",
      "train loss:0.0025432013685423942\n",
      "train loss:0.0055351357911151075\n",
      "train loss:0.012284917693258415\n",
      "train loss:0.0027251618865902698\n",
      "train loss:0.07946533931857828\n",
      "train loss:0.001174490103651659\n",
      "train loss:0.0008582280020948559\n",
      "train loss:0.008608063826006169\n",
      "train loss:0.002177868458833267\n",
      "train loss:0.012144102608435124\n",
      "train loss:0.0013155491770426436\n",
      "train loss:0.0053910866490660845\n",
      "train loss:0.02545698298961975\n",
      "train loss:0.002541182624166667\n",
      "train loss:0.031095605967444265\n",
      "train loss:0.014240731565349565\n",
      "train loss:0.004869443186340708\n",
      "train loss:0.002535966742251573\n",
      "train loss:0.003538996659005506\n",
      "train loss:0.08231793538660331\n",
      "train loss:0.004096016837560315\n",
      "train loss:0.011370812045093402\n",
      "train loss:0.011572921068401973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014515322239808332\n",
      "train loss:0.028476328762818068\n",
      "train loss:0.019065375787087665\n",
      "train loss:0.05650661017165147\n",
      "train loss:0.004226350003196973\n",
      "train loss:0.015336341058530451\n",
      "train loss:0.005341686766275217\n",
      "train loss:0.012606960876569791\n",
      "train loss:0.008977287215535599\n",
      "train loss:0.026374072505594825\n",
      "train loss:0.009049116348170586\n",
      "train loss:0.035944167041034175\n",
      "train loss:0.009659609661214564\n",
      "train loss:0.006890401881024253\n",
      "train loss:0.01845129232332301\n",
      "train loss:0.01054414047134264\n",
      "train loss:0.006407440248358982\n",
      "train loss:0.020455020121791255\n",
      "train loss:0.007112014676402207\n",
      "train loss:0.0015833828942037201\n",
      "train loss:0.0015220496541829662\n",
      "train loss:0.010108901853901484\n",
      "train loss:0.01894047026085878\n",
      "train loss:0.013243281870786938\n",
      "train loss:0.005233687738048117\n",
      "train loss:0.04459892899488526\n",
      "train loss:0.006551037893521129\n",
      "train loss:0.0020108753482791872\n",
      "train loss:0.009251691706894893\n",
      "train loss:0.022054417759724415\n",
      "train loss:0.008778070389155042\n",
      "train loss:0.008074033731204825\n",
      "train loss:0.054098664596771595\n",
      "train loss:0.0071554065560179335\n",
      "train loss:0.004539526872715833\n",
      "train loss:0.0032189580132441164\n",
      "train loss:0.015180597408050587\n",
      "train loss:0.005775126798722005\n",
      "train loss:0.0013299380145929123\n",
      "train loss:0.08745283364315998\n",
      "train loss:0.006411052259646859\n",
      "train loss:0.004465308261429353\n",
      "train loss:0.0006408959111510389\n",
      "train loss:0.023271930897381474\n",
      "train loss:0.010291225009132689\n",
      "train loss:0.008794088115071604\n",
      "train loss:0.0004423014043651046\n",
      "train loss:0.006084033252899433\n",
      "train loss:0.0029979840979353963\n",
      "train loss:0.0036185430483269936\n",
      "train loss:0.004710758132710433\n",
      "train loss:0.010849067193406385\n",
      "train loss:0.006473111544009027\n",
      "train loss:0.007223559311030283\n",
      "train loss:0.01745051154657132\n",
      "train loss:0.06143949613855933\n",
      "train loss:0.003282352498426717\n",
      "train loss:0.005696039900452955\n",
      "train loss:0.025702456302902264\n",
      "train loss:0.009919815696407574\n",
      "train loss:0.003984993738915982\n",
      "train loss:0.030956479142973514\n",
      "train loss:0.011708138940071455\n",
      "train loss:0.020749232040095853\n",
      "train loss:0.006251000419156807\n",
      "train loss:0.008379492127731439\n",
      "train loss:0.0017710807552899675\n",
      "train loss:0.004530418601773563\n",
      "train loss:0.01818963978566885\n",
      "train loss:0.0050871600428791415\n",
      "train loss:0.007152048312954497\n",
      "train loss:0.0029198179520838353\n",
      "train loss:0.001470528302605012\n",
      "train loss:0.046842111083612276\n",
      "train loss:0.001699868908118975\n",
      "train loss:0.0630753245480736\n",
      "train loss:0.00871354142147852\n",
      "train loss:0.004380754909804524\n",
      "train loss:0.018535966731214805\n",
      "train loss:0.017438969558617175\n",
      "train loss:0.0031505297060927567\n",
      "train loss:0.007693580103225603\n",
      "train loss:0.03710962813977659\n",
      "train loss:0.0218284729844947\n",
      "train loss:0.030985968562821528\n",
      "train loss:0.036131034268199705\n",
      "train loss:0.00477778545583775\n",
      "train loss:0.010725872528293344\n",
      "train loss:0.0029922232709512614\n",
      "train loss:0.001634460437458728\n",
      "train loss:0.002159823547717745\n",
      "train loss:0.03562992855900477\n",
      "train loss:0.006904695326175777\n",
      "train loss:0.003442825079306368\n",
      "train loss:0.002842396008089548\n",
      "train loss:0.010156817836473335\n",
      "train loss:0.014051704485900792\n",
      "train loss:0.008168283164415865\n",
      "train loss:0.0016904973044618394\n",
      "train loss:0.01466837725262441\n",
      "train loss:0.023205487713286184\n",
      "train loss:0.013535858031923696\n",
      "train loss:0.0055184107930205065\n",
      "train loss:0.001979181785634136\n",
      "train loss:0.005012492307411066\n",
      "train loss:0.0068211449188464056\n",
      "train loss:0.012769408604017906\n",
      "train loss:0.003246823846742799\n",
      "train loss:0.027685815382728064\n",
      "train loss:0.029042984570177982\n",
      "train loss:0.010495001769359405\n",
      "train loss:0.009897449395369346\n",
      "train loss:0.007052042671977896\n",
      "train loss:0.014881895126723822\n",
      "train loss:0.021808961622829304\n",
      "train loss:0.005441652506631679\n",
      "train loss:0.015648900227382526\n",
      "train loss:0.016047304027244892\n",
      "train loss:0.006470721657391442\n",
      "train loss:0.005362897132352435\n",
      "train loss:0.004210009409379829\n",
      "train loss:0.01795519311520536\n",
      "train loss:0.002744576299683572\n",
      "train loss:0.004562518690829085\n",
      "train loss:0.01005149607997835\n",
      "train loss:0.004783924187135999\n",
      "train loss:0.013019303934043623\n",
      "train loss:0.009488711999772604\n",
      "train loss:0.008409342642870713\n",
      "train loss:0.0033774402048073805\n",
      "train loss:0.02126941129864539\n",
      "train loss:0.0058618081943176805\n",
      "train loss:0.04110788295873779\n",
      "train loss:0.000555717032005371\n",
      "train loss:0.010597429431668417\n",
      "train loss:0.0492283870132955\n",
      "train loss:0.015904183464610696\n",
      "train loss:0.001793492075882961\n",
      "train loss:0.017437013534592323\n",
      "train loss:0.003233850415773364\n",
      "train loss:0.005470307841645286\n",
      "train loss:0.003685138428847393\n",
      "train loss:0.004847320354845438\n",
      "train loss:0.010142131580435447\n",
      "train loss:0.04239397511652276\n",
      "train loss:0.0016793030057915103\n",
      "train loss:0.0013637807984231997\n",
      "train loss:0.010289486445198557\n",
      "train loss:0.001961928950847227\n",
      "train loss:0.007448574171921994\n",
      "train loss:0.008085683188265974\n",
      "train loss:0.009312321845257217\n",
      "train loss:0.007739344421709101\n",
      "train loss:0.007443875741670745\n",
      "train loss:0.01494578431400146\n",
      "train loss:0.011315339259686712\n",
      "train loss:0.001576676046005094\n",
      "train loss:0.004410697035316022\n",
      "train loss:0.005256439641509387\n",
      "train loss:0.014392300728591696\n",
      "train loss:0.019146154244355902\n",
      "train loss:0.006781119805757505\n",
      "train loss:0.005497182262768713\n",
      "train loss:0.005186894375403892\n",
      "train loss:0.012849093921475459\n",
      "train loss:0.0016150046596193398\n",
      "train loss:0.016378093754080777\n",
      "train loss:0.05643626813899038\n",
      "train loss:0.009120962091155557\n",
      "train loss:0.006195020694418188\n",
      "train loss:0.02334026132587004\n",
      "train loss:0.00595445196692738\n",
      "train loss:0.01909015324253271\n",
      "train loss:0.013933197395100965\n",
      "train loss:0.005311078027682929\n",
      "train loss:0.002667732716418337\n",
      "train loss:0.001634537030373585\n",
      "train loss:0.002792936070124182\n",
      "train loss:0.011567590809475567\n",
      "train loss:0.014531503030492639\n",
      "train loss:0.0026973644952104016\n",
      "train loss:0.008332573187974817\n",
      "train loss:0.0035011354668487292\n",
      "train loss:0.004238541688869647\n",
      "train loss:0.017666517387117723\n",
      "train loss:0.005354078054388305\n",
      "train loss:0.007961625925076803\n",
      "train loss:0.021786414409858977\n",
      "train loss:0.001236647137640867\n",
      "train loss:0.016278323258728997\n",
      "train loss:0.005340795989701734\n",
      "train loss:0.004541690583340706\n",
      "train loss:0.013430268581330462\n",
      "train loss:0.014228902722230246\n",
      "train loss:0.0016797534034377068\n",
      "train loss:0.013167755291485237\n",
      "train loss:0.009729369662950078\n",
      "train loss:0.01769716826419096\n",
      "train loss:0.010919302995892102\n",
      "train loss:0.002576233906450541\n",
      "train loss:0.03628059656194979\n",
      "train loss:0.004901018818949588\n",
      "train loss:0.040908578158841157\n",
      "train loss:0.0008532159965034678\n",
      "train loss:0.005340501826440726\n",
      "train loss:0.0032808899721945427\n",
      "train loss:0.0023232527563850896\n",
      "train loss:0.011370329469873519\n",
      "train loss:0.004880354128559287\n",
      "train loss:0.01598996550910288\n",
      "train loss:0.027306375467186082\n",
      "train loss:0.02474437484159692\n",
      "train loss:0.0032817829494743637\n",
      "train loss:0.004753508866051376\n",
      "train loss:0.17849302552855625\n",
      "train loss:0.08202204893484742\n",
      "train loss:0.02082329540161175\n",
      "train loss:0.004168627481068267\n",
      "train loss:0.0019615828537895025\n",
      "train loss:0.02881293226890474\n",
      "train loss:0.007382665846579951\n",
      "train loss:0.012070370411702573\n",
      "train loss:0.04029698495262866\n",
      "train loss:0.0022384772806349758\n",
      "train loss:0.04492309319407942\n",
      "train loss:0.021710054679603692\n",
      "train loss:0.003789476076544451\n",
      "train loss:0.02559064303714211\n",
      "train loss:0.003667936092745026\n",
      "train loss:0.06645533821702859\n",
      "train loss:0.003467364085587919\n",
      "train loss:0.007482041987641448\n",
      "train loss:0.04409179704059452\n",
      "train loss:0.002017142436773089\n",
      "train loss:0.026371966049461234\n",
      "train loss:0.009457917534300017\n",
      "train loss:0.02306776363202667\n",
      "train loss:0.0030216717012185226\n",
      "train loss:0.009182893179595576\n",
      "train loss:0.009939733057274249\n",
      "train loss:0.0014850289775783243\n",
      "train loss:0.037340873690676\n",
      "train loss:0.0028696930348100992\n",
      "train loss:0.008674251992341411\n",
      "train loss:0.004067823011142849\n",
      "train loss:0.0042271138595004485\n",
      "train loss:0.010136228489213901\n",
      "train loss:0.008075768347450744\n",
      "train loss:0.01130068670498808\n",
      "train loss:0.008023766530141191\n",
      "train loss:0.012874576962858089\n",
      "train loss:0.00716825346255143\n",
      "train loss:0.009675395775988246\n",
      "train loss:0.012163432744595314\n",
      "train loss:0.014641335230043104\n",
      "train loss:0.0018209388121887065\n",
      "train loss:0.007404931461364186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0023559914263684605\n",
      "train loss:0.00900259512871077\n",
      "train loss:0.006402688866528635\n",
      "train loss:0.004763788126212955\n",
      "train loss:0.024410204297708845\n",
      "train loss:0.002214312699354907\n",
      "train loss:0.01094508518303081\n",
      "train loss:0.0036794836108264483\n",
      "train loss:0.011846218371870852\n",
      "train loss:0.015454069830176371\n",
      "train loss:0.009486979323873662\n",
      "train loss:0.004223185260914795\n",
      "train loss:0.08964939282591244\n",
      "train loss:0.017601838479238397\n",
      "train loss:0.016179015477270388\n",
      "train loss:0.035711473801131134\n",
      "train loss:0.0064657589928801785\n",
      "train loss:0.0037036368156792283\n",
      "train loss:0.004931175472314036\n",
      "train loss:0.037186710844497026\n",
      "train loss:0.013766669500613535\n",
      "train loss:0.017007168955239446\n",
      "train loss:0.0054796449753419275\n",
      "train loss:0.0012194044179950174\n",
      "train loss:0.01801166957077866\n",
      "train loss:0.013052224005808133\n",
      "train loss:0.00834293468857123\n",
      "train loss:0.007512606347820691\n",
      "train loss:0.0192392569141373\n",
      "train loss:0.038467799131525336\n",
      "train loss:0.016433438766590237\n",
      "train loss:0.005278176902847446\n",
      "train loss:0.008302642991214332\n",
      "train loss:0.007133488571720054\n",
      "train loss:0.0034670840409293064\n",
      "train loss:0.018112806127645088\n",
      "train loss:0.007166784781854167\n",
      "train loss:0.004699122434777485\n",
      "train loss:0.002372911270482597\n",
      "train loss:0.015911907365134172\n",
      "train loss:0.01761006196336349\n",
      "train loss:0.029928530025100722\n",
      "train loss:0.014295088610198362\n",
      "train loss:0.0014023721145274047\n",
      "train loss:0.0019772848616963767\n",
      "train loss:0.011802641503136818\n",
      "train loss:0.006526262230416317\n",
      "train loss:0.01475789451225539\n",
      "train loss:0.020424783667380656\n",
      "train loss:0.005105138235008687\n",
      "train loss:0.0026942778724462386\n",
      "train loss:0.003184121524159405\n",
      "train loss:0.007449264994325062\n",
      "train loss:0.009966689048585825\n",
      "train loss:0.006201252625547046\n",
      "train loss:0.01145357730521469\n",
      "train loss:0.011392617582829515\n",
      "train loss:0.03270741238428462\n",
      "train loss:0.02303187016178341\n",
      "train loss:0.022018326572706456\n",
      "train loss:0.008341544714829839\n",
      "train loss:0.01033941309170786\n",
      "train loss:0.00533982363738911\n",
      "train loss:0.006956380048017149\n",
      "train loss:0.004056500957665597\n",
      "train loss:0.0245446839822881\n",
      "train loss:0.00919954969608762\n",
      "train loss:0.025834565529175447\n",
      "train loss:0.01877656768439936\n",
      "train loss:0.0034651902848328382\n",
      "train loss:0.008811504483685057\n",
      "train loss:0.010220465180885027\n",
      "train loss:0.0042072875655102\n",
      "train loss:0.048438970060766556\n",
      "train loss:0.00931254802725816\n",
      "train loss:0.0211121756722708\n",
      "train loss:0.006585161899294197\n",
      "train loss:0.004733909386442584\n",
      "train loss:0.0028464040541965863\n",
      "train loss:0.028909253535788045\n",
      "train loss:0.005530065735836956\n",
      "train loss:0.029069804822995707\n",
      "train loss:0.01658788573179163\n",
      "train loss:0.0015286146337493331\n",
      "train loss:0.023234896485891655\n",
      "train loss:0.01994230598102931\n",
      "train loss:0.05973799276425601\n",
      "train loss:0.02408264232873848\n",
      "train loss:0.03076765834763617\n",
      "train loss:0.002379744271825292\n",
      "train loss:0.01669675875098617\n",
      "train loss:0.007647783708984653\n",
      "train loss:0.005493328601836421\n",
      "train loss:0.00210490463529247\n",
      "train loss:0.0012488700988199605\n",
      "train loss:0.00651972618375975\n",
      "train loss:0.003423016262525695\n",
      "train loss:0.006880152142770012\n",
      "train loss:0.009767528215191508\n",
      "train loss:0.0028677844185911795\n",
      "train loss:0.018559703840555875\n",
      "train loss:0.00902330956603223\n",
      "train loss:0.03529349321492013\n",
      "train loss:0.02448463205445642\n",
      "train loss:0.017590356625920237\n",
      "train loss:0.005516205461753022\n",
      "train loss:0.026697405322032984\n",
      "train loss:0.024496258498856793\n",
      "train loss:0.030727204462154857\n",
      "train loss:0.0071242415561937585\n",
      "train loss:0.007442043572344082\n",
      "train loss:0.004303578281625094\n",
      "train loss:0.007728134410264438\n",
      "train loss:0.0183838443331836\n",
      "train loss:0.015208500385367408\n",
      "train loss:0.007728814349316255\n",
      "train loss:0.013609750226629566\n",
      "train loss:0.004610170148745132\n",
      "train loss:0.0038783497138850033\n",
      "train loss:0.03263692164999367\n",
      "train loss:0.013683577067246513\n",
      "train loss:0.002525614853736871\n",
      "train loss:0.0013159986743074969\n",
      "train loss:0.031107915793158115\n",
      "train loss:0.025238215806289488\n",
      "train loss:0.012071251118984027\n",
      "train loss:0.0018740745006337594\n",
      "train loss:0.0006230701055300785\n",
      "train loss:0.02261095833879259\n",
      "train loss:0.011893033891449514\n",
      "train loss:0.0009028079607288044\n",
      "train loss:0.22680642132418577\n",
      "train loss:0.012333814370001093\n",
      "train loss:0.014299450405112584\n",
      "train loss:0.005415174796047605\n",
      "train loss:0.004508325953958286\n",
      "train loss:0.00800805646745762\n",
      "train loss:0.005639082501452132\n",
      "train loss:0.007510157896282461\n",
      "train loss:0.0028687995462727003\n",
      "train loss:0.004838095216669087\n",
      "train loss:0.003222107761516443\n",
      "train loss:0.011783077474360854\n",
      "train loss:0.008481253001546243\n",
      "train loss:0.005583464638309887\n",
      "train loss:0.039909198930091254\n",
      "train loss:0.02229985054037655\n",
      "train loss:0.006061160383924034\n",
      "train loss:0.015458673472823476\n",
      "train loss:0.03582955253733843\n",
      "train loss:0.004534565158510187\n",
      "train loss:0.11994203551375918\n",
      "train loss:0.05531577786381822\n",
      "train loss:0.0032991623985789155\n",
      "train loss:0.006445139122217246\n",
      "train loss:0.004544254657018595\n",
      "train loss:0.013508319762479877\n",
      "train loss:0.011974140925345891\n",
      "train loss:0.0009655720998204395\n",
      "train loss:0.008870059155102557\n",
      "train loss:0.00915816248830352\n",
      "train loss:0.01058788599502376\n",
      "train loss:0.01732419425942159\n",
      "train loss:0.004396470446552948\n",
      "train loss:0.007325506056060307\n",
      "train loss:0.0018300947727615791\n",
      "train loss:0.012229674236593126\n",
      "train loss:0.01702676866368037\n",
      "train loss:0.008499980029307125\n",
      "train loss:0.006859964693130184\n",
      "train loss:0.0101550222930491\n",
      "train loss:0.008971350491950546\n",
      "train loss:0.006087903476267782\n",
      "train loss:0.013211319882544101\n",
      "train loss:0.005243970176524665\n",
      "train loss:0.0035929174970844944\n",
      "train loss:0.015006637503693123\n",
      "train loss:0.019898831352524207\n",
      "train loss:0.019078747238226564\n",
      "train loss:0.011580470005923322\n",
      "train loss:0.00818586417530472\n",
      "train loss:0.007755141919200343\n",
      "train loss:0.012211946694723261\n",
      "train loss:0.002879516730430977\n",
      "=== epoch:10, train acc:0.993, test acc:0.987 ===\n",
      "train loss:0.010517240434849029\n",
      "train loss:0.002906676747485901\n",
      "train loss:0.004501022312842678\n",
      "train loss:0.004060250932617317\n",
      "train loss:0.0007421842647875362\n",
      "train loss:0.005647525513672151\n",
      "train loss:0.011063949382622323\n",
      "train loss:0.005993629176632078\n",
      "train loss:0.002499005853400683\n",
      "train loss:0.0023272079171723233\n",
      "train loss:0.01917195356390093\n",
      "train loss:0.023742685230595043\n",
      "train loss:0.006951108841645765\n",
      "train loss:0.02102327171259196\n",
      "train loss:0.0008154006413875825\n",
      "train loss:0.008552903610204141\n",
      "train loss:0.017841455058233747\n",
      "train loss:0.027196812222325263\n",
      "train loss:0.047510790715019985\n",
      "train loss:0.0038705329822502355\n",
      "train loss:0.011717428707010417\n",
      "train loss:0.011621607779569356\n",
      "train loss:0.013017142882993538\n",
      "train loss:0.0075588077884515105\n",
      "train loss:0.008371702587935397\n",
      "train loss:0.004185355640259442\n",
      "train loss:0.002334500205032995\n",
      "train loss:0.009895707705215655\n",
      "train loss:0.03032821974355755\n",
      "train loss:0.005657147825677243\n",
      "train loss:0.026525474719880794\n",
      "train loss:0.02793353985112465\n",
      "train loss:0.008218702586424594\n",
      "train loss:0.0031037254001678384\n",
      "train loss:0.003985401307087364\n",
      "train loss:0.003949636097537356\n",
      "train loss:0.006595007631197984\n",
      "train loss:0.006198244837966728\n",
      "train loss:0.009002466514071092\n",
      "train loss:0.006406628339743723\n",
      "train loss:0.004776577754152133\n",
      "train loss:0.013363019854244977\n",
      "train loss:0.003400491249433667\n",
      "train loss:0.004989352145168363\n",
      "train loss:0.006454862666062084\n",
      "train loss:0.004340767318864615\n",
      "train loss:0.0006854243816804839\n",
      "train loss:0.0015793196784248992\n",
      "train loss:0.00310339987462406\n",
      "train loss:0.0058949913624680135\n",
      "train loss:0.012886390141471462\n",
      "train loss:0.017265674236172052\n",
      "train loss:0.004479566466899058\n",
      "train loss:0.01396456765815291\n",
      "train loss:0.011810235924127515\n",
      "train loss:0.009821568050948849\n",
      "train loss:0.011317436678990761\n",
      "train loss:0.0014282246964629588\n",
      "train loss:0.01703183135143446\n",
      "train loss:0.018284683077606126\n",
      "train loss:0.0003907123515769747\n",
      "train loss:0.0013045243148806787\n",
      "train loss:0.001189206931488532\n",
      "train loss:0.04172523140038927\n",
      "train loss:0.012065871860026505\n",
      "train loss:0.004889371778571434\n",
      "train loss:0.012901044292097373\n",
      "train loss:0.0056541194479476815\n",
      "train loss:0.0011615311487440094\n",
      "train loss:0.008135485579585745\n",
      "train loss:0.01038778940669388\n",
      "train loss:0.008556497025999562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002766565451608158\n",
      "train loss:0.0083375802745277\n",
      "train loss:0.005001501951693046\n",
      "train loss:0.0007653414499113317\n",
      "train loss:0.011445513676078808\n",
      "train loss:0.012434224972095745\n",
      "train loss:0.017397166094044337\n",
      "train loss:0.01583723572372027\n",
      "train loss:0.006980829186929447\n",
      "train loss:0.0029307536997985354\n",
      "train loss:0.0006942601423418005\n",
      "train loss:0.0006575174284010956\n",
      "train loss:0.006782695259446985\n",
      "train loss:0.020073856063058993\n",
      "train loss:0.014162397217621848\n",
      "train loss:0.03936982174807373\n",
      "train loss:0.002055280293712067\n",
      "train loss:0.0021270233365217996\n",
      "train loss:0.07415055996132919\n",
      "train loss:0.14197702646711366\n",
      "train loss:0.012153574897229518\n",
      "train loss:0.005592233426074935\n",
      "train loss:0.0025181423335479164\n",
      "train loss:0.0036233707404358727\n",
      "train loss:0.00872952735692401\n",
      "train loss:0.02223015881368445\n",
      "train loss:0.01676639361659576\n",
      "train loss:0.0007174321686760517\n",
      "train loss:0.02435140088549577\n",
      "train loss:0.010022516800925472\n",
      "train loss:0.0022489050347173157\n",
      "train loss:0.043036745063451114\n",
      "train loss:0.0008756707829677893\n",
      "train loss:0.010709555280308758\n",
      "train loss:0.0039071660257373455\n",
      "train loss:0.00828539798617141\n",
      "train loss:0.05636923584276\n",
      "train loss:0.016084703347935467\n",
      "train loss:0.027177358939151977\n",
      "train loss:0.006276275570574765\n",
      "train loss:0.011394168959067093\n",
      "train loss:0.008673796321850977\n",
      "train loss:0.004414320292318895\n",
      "train loss:0.011261018618557925\n",
      "train loss:0.021164324116932\n",
      "train loss:0.0163567126811998\n",
      "train loss:0.004450387751691861\n",
      "train loss:0.01841849918737439\n",
      "train loss:0.008628418776872296\n",
      "train loss:0.00982554414030162\n",
      "train loss:0.0070767078867763735\n",
      "train loss:0.03736524043681297\n",
      "train loss:0.00797348872576934\n",
      "train loss:0.030154724906248886\n",
      "train loss:0.005722379477914009\n",
      "train loss:0.002742771041375593\n",
      "train loss:0.0031095095909103587\n",
      "train loss:0.06584582324372755\n",
      "train loss:0.028426267034607343\n",
      "train loss:0.004480052325907009\n",
      "train loss:0.0026655077038916872\n",
      "train loss:0.015481912768368642\n",
      "train loss:0.004348913902391749\n",
      "train loss:0.023653955755548354\n",
      "train loss:0.000785851481494286\n",
      "train loss:0.020926958520259088\n",
      "train loss:0.01329608712420707\n",
      "train loss:0.0014279740149893488\n",
      "train loss:0.004537599190369635\n",
      "train loss:0.004669425532443649\n",
      "train loss:0.004772379976476252\n",
      "train loss:0.012862544145765757\n",
      "train loss:0.00606071171637613\n",
      "train loss:0.026592376643233863\n",
      "train loss:0.0021452623334520244\n",
      "train loss:0.017224214345808564\n",
      "train loss:0.024131061071876552\n",
      "train loss:0.16547819683757442\n",
      "train loss:0.09192591565124847\n",
      "train loss:0.00251880184706106\n",
      "train loss:0.0028378290583185506\n",
      "train loss:0.002167522237391934\n",
      "train loss:0.023713651841308078\n",
      "train loss:0.022226023110192818\n",
      "train loss:0.0028168125276815457\n",
      "train loss:0.007169319959303362\n",
      "train loss:0.005738939641352623\n",
      "train loss:0.05205018685157656\n",
      "train loss:0.004662182956859223\n",
      "train loss:0.01530121006241862\n",
      "train loss:0.005666617803281126\n",
      "train loss:0.02510271467179706\n",
      "train loss:0.007910204854896805\n",
      "train loss:0.00083067107640164\n",
      "train loss:0.006089198141822388\n",
      "train loss:0.014193445296053726\n",
      "train loss:0.006074652273151893\n",
      "train loss:0.010332680256003833\n",
      "train loss:0.006230082117306461\n",
      "train loss:0.013419786060162997\n",
      "train loss:0.010966351692200766\n",
      "train loss:0.002879644970623053\n",
      "train loss:0.013208719554821334\n",
      "train loss:0.010850353323784083\n",
      "train loss:0.001699212956936828\n",
      "train loss:0.006390077319608406\n",
      "train loss:0.021821084360554886\n",
      "train loss:0.040207951256412876\n",
      "train loss:0.0247769810420722\n",
      "train loss:0.006420670801147474\n",
      "train loss:0.006484642722871815\n",
      "train loss:0.006022057374524584\n",
      "train loss:0.01018887166083857\n",
      "train loss:0.013290263564159892\n",
      "train loss:0.0030774184910510954\n",
      "train loss:0.005981040826548365\n",
      "train loss:0.05755862477072924\n",
      "train loss:0.01523266174433503\n",
      "train loss:0.007152093632796089\n",
      "train loss:0.05590125625468827\n",
      "train loss:0.0029959821280165356\n",
      "train loss:0.009436505387632854\n",
      "train loss:0.008909480921381755\n",
      "train loss:0.0005794322338992067\n",
      "train loss:0.006202565737167408\n",
      "train loss:0.007865233012341426\n",
      "train loss:0.005996873070411397\n",
      "train loss:0.00525515897504588\n",
      "train loss:0.03987770682238885\n",
      "train loss:0.004905773369342776\n",
      "train loss:0.005960553360934453\n",
      "train loss:0.013139957008099645\n",
      "train loss:0.029050567944287807\n",
      "train loss:0.05548124264167667\n",
      "train loss:0.007769675520188094\n",
      "train loss:0.011516720149523867\n",
      "train loss:0.00792253333775461\n",
      "train loss:0.05335690758704909\n",
      "train loss:0.02556077200523272\n",
      "train loss:0.004025757660895047\n",
      "train loss:0.01384468925732994\n",
      "train loss:0.00753785036079533\n",
      "train loss:0.0045993628563994835\n",
      "train loss:0.00226986711522742\n",
      "train loss:0.004932033749428146\n",
      "train loss:0.011945701202216087\n",
      "train loss:0.005823687856556143\n",
      "train loss:0.01889682421108682\n",
      "train loss:0.0056976785467248445\n",
      "train loss:0.011359244443418196\n",
      "train loss:0.023914626155434063\n",
      "train loss:0.021890850604216958\n",
      "train loss:0.002028123520457144\n",
      "train loss:0.00267415313355258\n",
      "train loss:0.004365093910289019\n",
      "train loss:0.002634858310626007\n",
      "train loss:0.002998482135083503\n",
      "train loss:0.04904407683439209\n",
      "train loss:0.017681573552022732\n",
      "train loss:0.018470740076057698\n",
      "train loss:0.04233940670205305\n",
      "train loss:0.013071120372568388\n",
      "train loss:0.01691015723511441\n",
      "train loss:0.0028355634119920452\n",
      "train loss:0.009731670019082173\n",
      "train loss:0.012900531957874838\n",
      "train loss:0.013382447740796515\n",
      "train loss:0.008028918282471537\n",
      "train loss:0.017472961061017214\n",
      "train loss:0.01742327480981525\n",
      "train loss:0.03471815068371378\n",
      "train loss:0.0016041334234212345\n",
      "train loss:0.007565516370648562\n",
      "train loss:0.012185497292609634\n",
      "train loss:0.0030359768613694047\n",
      "train loss:0.012928198508993597\n",
      "train loss:0.002055483272347014\n",
      "train loss:0.020176777515926437\n",
      "train loss:0.014197409425353233\n",
      "train loss:0.004526842592781542\n",
      "train loss:0.001956939381833112\n",
      "train loss:0.004574588736612395\n",
      "train loss:0.012559670621487138\n",
      "train loss:0.003551033695704898\n",
      "train loss:0.010812414873084058\n",
      "train loss:0.011954604313060238\n",
      "train loss:0.006082094618885252\n",
      "train loss:0.009375826650521576\n",
      "train loss:0.0065909881698993445\n",
      "train loss:0.008785093941017985\n",
      "train loss:0.00417040721935184\n",
      "train loss:0.003087046116440568\n",
      "train loss:0.006839400895989485\n",
      "train loss:0.004302140039172318\n",
      "train loss:0.01330355212526639\n",
      "train loss:0.003397300833228677\n",
      "train loss:0.0016662824400812569\n",
      "train loss:0.013663710410792864\n",
      "train loss:0.006392745132078682\n",
      "train loss:0.009304502880010867\n",
      "train loss:0.027124615492212095\n",
      "train loss:0.018055745334867843\n",
      "train loss:0.00943613875499984\n",
      "train loss:0.0009341933947535591\n",
      "train loss:0.027911554564372543\n",
      "train loss:0.002906421013424282\n",
      "train loss:0.007673552127118173\n",
      "train loss:0.01623337003148073\n",
      "train loss:0.0013666800100573182\n",
      "train loss:0.0073048423349865044\n",
      "train loss:0.006132827205305329\n",
      "train loss:0.002550788465932577\n",
      "train loss:0.0032541458626040897\n",
      "train loss:0.0023274106384184603\n",
      "train loss:0.0422297016130101\n",
      "train loss:0.006843233483395176\n",
      "train loss:0.011588801885010758\n",
      "train loss:0.031604018534183355\n",
      "train loss:0.014542293363823313\n",
      "train loss:0.005828329506025558\n",
      "train loss:0.0023967268475686217\n",
      "train loss:0.0014852793665972041\n",
      "train loss:0.02426440981182707\n",
      "train loss:0.01436888195156663\n",
      "train loss:0.018029206015766144\n",
      "train loss:0.004361689065820793\n",
      "train loss:0.006570109573577466\n",
      "train loss:0.0007275453960553967\n",
      "train loss:0.004588925505610657\n",
      "train loss:0.013682130204198457\n",
      "train loss:0.008030279434481006\n",
      "train loss:0.005599688499231065\n",
      "train loss:0.007741748140606407\n",
      "train loss:0.004195819535849774\n",
      "train loss:0.0258995420484406\n",
      "train loss:0.01299107982202099\n",
      "train loss:0.005967150243903143\n",
      "train loss:0.020646256980219376\n",
      "train loss:0.0009049853844850753\n",
      "train loss:0.0014584375632100707\n",
      "train loss:0.008611542432720854\n",
      "train loss:0.06391733150986507\n",
      "train loss:0.014197310749984047\n",
      "train loss:0.005949089259149594\n",
      "train loss:0.007125826823122745\n",
      "train loss:0.015543596520301713\n",
      "train loss:0.0020031824585835683\n",
      "train loss:0.003370091130774664\n",
      "train loss:0.00043321394053031764\n",
      "train loss:0.0062059294556322635\n",
      "train loss:0.0035064352632251244\n",
      "train loss:0.0030297637147103733\n",
      "train loss:0.007173880246105876\n",
      "train loss:0.04172310993951652\n",
      "train loss:0.0015604157382623832\n",
      "train loss:0.038865063592755884\n",
      "train loss:0.032950589564918385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004310847515725937\n",
      "train loss:0.018037783004523945\n",
      "train loss:0.00649683057507564\n",
      "train loss:0.02537761775750832\n",
      "train loss:0.006387494005842534\n",
      "train loss:0.02836664776674604\n",
      "train loss:0.0040445274969818125\n",
      "train loss:0.015785565294404048\n",
      "train loss:0.012617988517513043\n",
      "train loss:0.006368531766464175\n",
      "train loss:0.0036113519082303027\n",
      "train loss:0.004831864586258547\n",
      "train loss:0.0034988293846451753\n",
      "train loss:0.011099666315499988\n",
      "train loss:0.04312519263341122\n",
      "train loss:0.002760175447567978\n",
      "train loss:0.0008534340717639387\n",
      "train loss:0.0022939183046524593\n",
      "train loss:0.010756555672789304\n",
      "train loss:0.05564227773485058\n",
      "train loss:0.00789326429822855\n",
      "train loss:0.01627787592893277\n",
      "train loss:0.002813065419659092\n",
      "train loss:0.03589543769072549\n",
      "train loss:0.003291008449250254\n",
      "train loss:0.014245255482930768\n",
      "train loss:0.006931294205377307\n",
      "train loss:0.004459173596933586\n",
      "train loss:0.00391173335592178\n",
      "train loss:0.009950091584464775\n",
      "train loss:0.012085867369189209\n",
      "train loss:0.0018684234211509493\n",
      "train loss:0.05152741918753012\n",
      "train loss:0.005933955881488592\n",
      "train loss:0.006293726983625826\n",
      "train loss:0.024728194327215326\n",
      "train loss:0.004908028142720504\n",
      "train loss:0.031128311540560557\n",
      "train loss:0.0018623605615883728\n",
      "train loss:0.005868073900501255\n",
      "train loss:0.00907314112340958\n",
      "train loss:0.006521498736162729\n",
      "train loss:0.003001209151626452\n",
      "train loss:0.004324504159074004\n",
      "train loss:0.022836163594428985\n",
      "train loss:0.0055783437752414755\n",
      "train loss:0.004086310550965827\n",
      "train loss:0.0066673318880755865\n",
      "train loss:0.0025660111093524472\n",
      "train loss:0.005439967126384112\n",
      "train loss:0.0036318399665426276\n",
      "train loss:0.015060091934234084\n",
      "train loss:0.010885659694714816\n",
      "train loss:0.001924426039598249\n",
      "train loss:0.005483036658909611\n",
      "train loss:0.004169511818596993\n",
      "train loss:0.004802772583892942\n",
      "train loss:0.003346129529761893\n",
      "train loss:0.004036597886929899\n",
      "train loss:0.020475989067735813\n",
      "train loss:0.003865143373718955\n",
      "train loss:0.0017473054760631663\n",
      "train loss:0.004757377955303924\n",
      "train loss:0.011238751238123014\n",
      "train loss:0.0074176695344654745\n",
      "train loss:0.005381913011663507\n",
      "train loss:0.02269962793128818\n",
      "train loss:0.005007742924749366\n",
      "train loss:0.011754640641017835\n",
      "train loss:0.019083281333853216\n",
      "train loss:0.004514432077957019\n",
      "train loss:0.005835753385364978\n",
      "train loss:0.00652349160319075\n",
      "train loss:0.0046287199687539944\n",
      "train loss:0.015242681267147944\n",
      "train loss:0.010542837142791799\n",
      "train loss:0.0056935934549789645\n",
      "train loss:0.00528681675201081\n",
      "train loss:0.004325403467718101\n",
      "train loss:0.006455740394717565\n",
      "train loss:0.027871983767736697\n",
      "train loss:0.0016221154222928228\n",
      "train loss:0.00490600054365307\n",
      "train loss:0.0028572902301989976\n",
      "train loss:0.013395058490573914\n",
      "train loss:0.0011132630764676386\n",
      "train loss:0.013924971192214263\n",
      "train loss:0.007766459863613217\n",
      "train loss:0.024568254954516665\n",
      "train loss:0.0067217423148104236\n",
      "train loss:0.004948666351447436\n",
      "train loss:0.00874263060773703\n",
      "train loss:0.0030613967050176043\n",
      "train loss:0.046796530893855964\n",
      "train loss:0.006915112185952215\n",
      "train loss:0.003615199522419334\n",
      "train loss:0.0009579713807305264\n",
      "train loss:0.0626672677675656\n",
      "train loss:0.0037521294809358674\n",
      "train loss:0.005539905599435543\n",
      "train loss:0.013883890561968542\n",
      "train loss:0.01842787176305304\n",
      "train loss:0.003948857656429525\n",
      "train loss:0.010075146570228757\n",
      "train loss:0.005753851161744599\n",
      "train loss:0.004890232882030395\n",
      "train loss:0.015826539261390958\n",
      "train loss:0.0342527377332187\n",
      "train loss:0.0022660334313749993\n",
      "train loss:0.014642401588389089\n",
      "train loss:0.01055982171478534\n",
      "train loss:0.009770455259000891\n",
      "train loss:0.0006229840140463868\n",
      "train loss:0.011195635034686307\n",
      "train loss:0.003706884536940705\n",
      "train loss:0.019759658338526533\n",
      "train loss:0.004645068071717199\n",
      "train loss:0.0037896754599429138\n",
      "train loss:0.011898405281023372\n",
      "train loss:0.0013884975364918306\n",
      "train loss:0.02220594112004705\n",
      "train loss:0.008395214056345137\n",
      "train loss:0.006628701724141607\n",
      "train loss:0.0020858561660188502\n",
      "train loss:0.0008094496020536608\n",
      "train loss:0.003921032083265244\n",
      "train loss:0.017737138403145825\n",
      "train loss:0.006018421442741031\n",
      "train loss:0.0032852294179148566\n",
      "train loss:0.009628351987879334\n",
      "train loss:0.003041620009353658\n",
      "train loss:0.011521697763754737\n",
      "train loss:0.005484385142072694\n",
      "train loss:0.008892593329886065\n",
      "train loss:0.015952454695878943\n",
      "train loss:0.008142939318850819\n",
      "train loss:0.008513623172984269\n",
      "train loss:0.0021452793518569884\n",
      "train loss:0.015232768072102346\n",
      "train loss:0.0032419797146507143\n",
      "train loss:0.005201179297007367\n",
      "train loss:0.004175410358660171\n",
      "train loss:0.002512778508393057\n",
      "train loss:0.01305944648561041\n",
      "train loss:0.013213048017606872\n",
      "train loss:0.006370429999467143\n",
      "train loss:0.003537093673837189\n",
      "train loss:0.02920839399336567\n",
      "train loss:0.012210411836399765\n",
      "train loss:0.02238430701825421\n",
      "train loss:0.006570660140615993\n",
      "train loss:0.004829596611236752\n",
      "train loss:0.0033162924204456295\n",
      "train loss:0.004275989870558943\n",
      "train loss:0.1679036909524583\n",
      "train loss:0.006277108585679814\n",
      "train loss:0.01695096020327034\n",
      "train loss:0.012860172516392966\n",
      "train loss:0.007975835256213381\n",
      "train loss:0.013496871409416876\n",
      "train loss:0.007179590766830061\n",
      "train loss:0.008169946382675687\n",
      "train loss:0.005989615078307839\n",
      "train loss:0.0907637061293684\n",
      "train loss:0.029029083992542795\n",
      "train loss:0.004236493832054937\n",
      "train loss:0.013603778619838525\n",
      "train loss:0.002132191155299094\n",
      "train loss:0.014023829115268262\n",
      "train loss:0.007283144304054046\n",
      "train loss:0.00800487918234472\n",
      "train loss:0.0034973405502211874\n",
      "train loss:0.004269640964136429\n",
      "train loss:0.005595780239377041\n",
      "train loss:0.005344330032640328\n",
      "train loss:0.014563063277896401\n",
      "train loss:0.015344985916329285\n",
      "train loss:0.007875804622335478\n",
      "train loss:0.03671014364708895\n",
      "train loss:0.01598317596111765\n",
      "train loss:0.007024199050697775\n",
      "train loss:0.00745974398093241\n",
      "train loss:0.006110005482052861\n",
      "train loss:0.014475066948997799\n",
      "train loss:0.0063043873847201115\n",
      "train loss:0.045073557491401024\n",
      "train loss:0.025293314989455095\n",
      "train loss:0.005046466238323988\n",
      "train loss:0.0042564541284749\n",
      "train loss:0.0005784702329576031\n",
      "train loss:0.07800944327434343\n",
      "train loss:0.002832278790131016\n",
      "train loss:0.006248635990835983\n",
      "train loss:0.007017650223106897\n",
      "train loss:0.005180979344957303\n",
      "train loss:0.006383279485049916\n",
      "train loss:0.017031293159206342\n",
      "train loss:0.004937416975986087\n",
      "train loss:0.0014351053140862914\n",
      "train loss:0.003133847608897374\n",
      "train loss:0.004820332527195917\n",
      "train loss:0.009439864469149477\n",
      "train loss:0.019327910445306698\n",
      "train loss:0.0021406990551341345\n",
      "train loss:0.008782112078037585\n",
      "train loss:0.00400177556721852\n",
      "train loss:0.030307255470996716\n",
      "train loss:0.012835387898483422\n",
      "train loss:0.007216989439249326\n",
      "train loss:0.0050912798508484765\n",
      "train loss:0.003169999030965534\n",
      "train loss:0.026317658499960084\n",
      "train loss:0.012050234548330731\n",
      "train loss:0.009028530783136715\n",
      "train loss:0.006382203985864725\n",
      "train loss:0.010308352774882986\n",
      "train loss:0.0033918246033575734\n",
      "train loss:0.008398380617855316\n",
      "train loss:0.0034380970199160634\n",
      "train loss:0.001761585302600899\n",
      "train loss:0.004115292878677239\n",
      "train loss:0.0035716588772533066\n",
      "train loss:0.005727836593865953\n",
      "train loss:0.008758390786909572\n",
      "train loss:0.0006928626951678161\n",
      "train loss:0.01774030743866633\n",
      "train loss:0.020233569564418102\n",
      "train loss:0.0014207438999905852\n",
      "train loss:0.0168122096538736\n",
      "train loss:0.0053476731164876735\n",
      "train loss:0.006338762926238537\n",
      "train loss:0.00755725402877119\n",
      "train loss:0.00155272019866102\n",
      "train loss:0.008209722487609008\n",
      "train loss:0.002070941037928095\n",
      "train loss:0.004076791415129638\n",
      "train loss:0.0077922496907685355\n",
      "train loss:0.0020275708148135337\n",
      "train loss:0.0011741919121004826\n",
      "train loss:0.05279022218390178\n",
      "train loss:0.025996814230994335\n",
      "train loss:0.013667668320913094\n",
      "train loss:0.023264130356235327\n",
      "train loss:0.004091552976445976\n",
      "train loss:0.03131218616307794\n",
      "train loss:0.0019024357859832768\n",
      "train loss:0.002376977008160071\n",
      "train loss:0.01142741807102041\n",
      "train loss:0.017313002928916615\n",
      "train loss:0.008167185963469282\n",
      "train loss:0.002163128665483193\n",
      "train loss:0.007771120603149828\n",
      "train loss:0.002466403061579145\n",
      "train loss:0.007592239854886013\n",
      "train loss:0.007113034957570207\n",
      "train loss:0.0164675829925431\n",
      "train loss:0.015392692338531189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00764821601167707\n",
      "train loss:0.022904234579711844\n",
      "train loss:0.013955456486010183\n",
      "train loss:0.005023684383883668\n",
      "train loss:0.0034593951506317866\n",
      "train loss:0.005597923854083522\n",
      "train loss:0.02087553028223883\n",
      "train loss:0.011503890173405529\n",
      "train loss:0.011841679196257669\n",
      "train loss:0.00029348149840626836\n",
      "train loss:0.0020864243463792663\n",
      "train loss:0.0012624830773181519\n",
      "train loss:0.12998820591891946\n",
      "train loss:0.008279647154182052\n",
      "=== epoch:11, train acc:0.996, test acc:0.983 ===\n",
      "train loss:0.008348647362347292\n",
      "train loss:0.003812744225409444\n",
      "train loss:0.02290950293284541\n",
      "train loss:0.009087027549785454\n",
      "train loss:0.00022709587552511207\n",
      "train loss:0.0073486772057114545\n",
      "train loss:0.023459297090896086\n",
      "train loss:0.0012569417025757666\n",
      "train loss:0.010768730816204308\n",
      "train loss:0.11360722426423539\n",
      "train loss:0.005942399760390253\n",
      "train loss:0.006619565970828411\n",
      "train loss:0.004220494353875893\n",
      "train loss:0.015126555023378114\n",
      "train loss:0.03205702041886232\n",
      "train loss:0.002117620822301969\n",
      "train loss:0.008470535659022914\n",
      "train loss:0.0013734070803243844\n",
      "train loss:0.02470578411541384\n",
      "train loss:0.015988992601000566\n",
      "train loss:0.009591096978952832\n",
      "train loss:0.023280730747007698\n",
      "train loss:0.01667871662078724\n",
      "train loss:0.010974949654049375\n",
      "train loss:0.028708337721269538\n",
      "train loss:0.057808147969492386\n",
      "train loss:0.009690894757112059\n",
      "train loss:0.00977282044368634\n",
      "train loss:0.000827512347676971\n",
      "train loss:0.025459084510610817\n",
      "train loss:0.0036312387673292958\n",
      "train loss:0.007128155730083185\n",
      "train loss:0.010101219639771519\n",
      "train loss:0.0010489698375682824\n",
      "train loss:0.004577792924598382\n",
      "train loss:0.001884800623815285\n",
      "train loss:0.011289674455559564\n",
      "train loss:0.002906939488735369\n",
      "train loss:0.0071662154867218044\n",
      "train loss:0.006654252006148388\n",
      "train loss:0.004502090708265241\n",
      "train loss:0.009707062444519566\n",
      "train loss:0.041189980824336433\n",
      "train loss:0.03434652013624112\n",
      "train loss:0.005335567968215526\n",
      "train loss:0.025399105253585443\n",
      "train loss:0.026419490991045375\n",
      "train loss:0.011601355493728215\n",
      "train loss:0.0007308337729181201\n",
      "train loss:0.006352525429015369\n",
      "train loss:0.010692813551631148\n",
      "train loss:0.01037658057956018\n",
      "train loss:0.004409199230338497\n",
      "train loss:0.007264492276738066\n",
      "train loss:0.003381235125816185\n",
      "train loss:0.01774072077286939\n",
      "train loss:0.0028619560739942883\n",
      "train loss:0.012858942607043978\n",
      "train loss:0.01956531094527802\n",
      "train loss:0.006099260366676224\n",
      "train loss:0.011393311155812267\n",
      "train loss:0.008146403018212454\n",
      "train loss:0.0014775677802382134\n",
      "train loss:0.0050546007303885745\n",
      "train loss:0.004606216368874095\n",
      "train loss:0.001157330982364038\n",
      "train loss:0.008010384531226196\n",
      "train loss:0.0019026175700652382\n",
      "train loss:0.0025571167377645585\n",
      "train loss:0.014463809131292608\n",
      "train loss:0.0037869606455044947\n",
      "train loss:0.001487265957028877\n",
      "train loss:0.0030909643505764033\n",
      "train loss:0.007913101732257616\n",
      "train loss:0.021165440343818242\n",
      "train loss:0.019615207733656572\n",
      "train loss:0.0007475704610699904\n",
      "train loss:0.03097466641528728\n",
      "train loss:0.010647201969721165\n",
      "train loss:0.0008401639288941654\n",
      "train loss:0.007798058280211229\n",
      "train loss:0.00021030772540842543\n",
      "train loss:0.003935800918227079\n",
      "train loss:0.0015611556915179807\n",
      "train loss:0.0044988981382070616\n",
      "train loss:0.011926509044076052\n",
      "train loss:0.005565850524170354\n",
      "train loss:0.002307077629820452\n",
      "train loss:0.0004799933158381876\n",
      "train loss:0.0034414611934008494\n",
      "train loss:0.0018919496125967433\n",
      "train loss:0.0013081137180364784\n",
      "train loss:0.04630294467668791\n",
      "train loss:0.010674965342983275\n",
      "train loss:0.00738637001653297\n",
      "train loss:0.003682648726982288\n",
      "train loss:0.0015334281832613684\n",
      "train loss:0.007788495755216153\n",
      "train loss:0.003892368948595122\n",
      "train loss:0.002047014170919662\n",
      "train loss:0.0033093936666352924\n",
      "train loss:0.061816003210475035\n",
      "train loss:0.008496089252370305\n",
      "train loss:0.037582362313114584\n",
      "train loss:0.0032800042541058665\n",
      "train loss:0.0013763016351045875\n",
      "train loss:0.01575366393285095\n",
      "train loss:0.0059632322388769735\n",
      "train loss:0.008966923820400865\n",
      "train loss:0.02342064724349781\n",
      "train loss:0.02170548669017625\n",
      "train loss:0.00746987688111115\n",
      "train loss:0.0008497475208553011\n",
      "train loss:0.001318700336706133\n",
      "train loss:0.0077809659556734015\n",
      "train loss:0.0027101770305119934\n",
      "train loss:0.03187633955464692\n",
      "train loss:0.00342138445300114\n",
      "train loss:0.004699920910801854\n",
      "train loss:0.01019284285923886\n",
      "train loss:0.004060828823750643\n",
      "train loss:0.002555252467675498\n",
      "train loss:0.005662095721897679\n",
      "train loss:0.0051454799549422855\n",
      "train loss:0.00836062943365831\n",
      "train loss:0.0017406351161846816\n",
      "train loss:0.02292903898367858\n",
      "train loss:0.008503171947535583\n",
      "train loss:0.012399436587927994\n",
      "train loss:0.004927815692866775\n",
      "train loss:0.0015757106792701607\n",
      "train loss:0.001605359393210907\n",
      "train loss:0.0012958148457459845\n",
      "train loss:0.001375552528981866\n",
      "train loss:0.004594871568395415\n",
      "train loss:0.007370748098014302\n",
      "train loss:0.015160605150649148\n",
      "train loss:0.007511681917194551\n",
      "train loss:0.015495399676709355\n",
      "train loss:0.001614487319818962\n",
      "train loss:0.003751612443988553\n",
      "train loss:0.01673795153912032\n",
      "train loss:0.000527975649204701\n",
      "train loss:0.001914757384648943\n",
      "train loss:0.0031780310941510524\n",
      "train loss:0.002366442386371974\n",
      "train loss:0.0309655719149864\n",
      "train loss:0.0056185900608903125\n",
      "train loss:0.004347355255160608\n",
      "train loss:0.0049166672755734265\n",
      "train loss:0.0038804277128550724\n",
      "train loss:0.008803142742672616\n",
      "train loss:0.0032483754409369982\n",
      "train loss:0.006901516771346115\n",
      "train loss:0.0023445939229841985\n",
      "train loss:0.0017486286320543512\n",
      "train loss:0.04363096849682801\n",
      "train loss:0.00893883624823084\n",
      "train loss:0.006046158610796025\n",
      "train loss:0.019647512959416046\n",
      "train loss:0.0013716323054312584\n",
      "train loss:0.0019756601101458006\n",
      "train loss:0.00301849582501926\n",
      "train loss:0.003236599736924472\n",
      "train loss:0.004250908855946019\n",
      "train loss:0.017280173880191325\n",
      "train loss:0.050138842584872514\n",
      "train loss:0.002944368898571104\n",
      "train loss:0.006251052297708895\n",
      "train loss:0.009546536149784459\n",
      "train loss:0.0016487637952638883\n",
      "train loss:0.005088284055865611\n",
      "train loss:0.002356680247891859\n",
      "train loss:0.015156463634083824\n",
      "train loss:0.002581271299234314\n",
      "train loss:0.006185789358344569\n",
      "train loss:0.006394514380995736\n",
      "train loss:0.00166969644795837\n",
      "train loss:0.0008531127472298541\n",
      "train loss:0.000345914320427155\n",
      "train loss:0.006895433686598789\n",
      "train loss:0.0021294750185965956\n",
      "train loss:0.006533222758316267\n",
      "train loss:0.01206372245155764\n",
      "train loss:0.010518326021471937\n",
      "train loss:0.004989017799701895\n",
      "train loss:0.004921326496844364\n",
      "train loss:0.010723465693981698\n",
      "train loss:0.0029050533020239\n",
      "train loss:0.002353981583044833\n",
      "train loss:0.006887652273939624\n",
      "train loss:0.005428763159068\n",
      "train loss:0.0013395277649392904\n",
      "train loss:0.003614243174492684\n",
      "train loss:0.006383516407017353\n",
      "train loss:0.00331254082021203\n",
      "train loss:0.0005746587310754012\n",
      "train loss:0.01955660604521621\n",
      "train loss:0.029432360932864852\n",
      "train loss:0.003278489076014147\n",
      "train loss:0.005085945926617129\n",
      "train loss:0.0050477514825946505\n",
      "train loss:0.003727211448868407\n",
      "train loss:0.005696856289484269\n",
      "train loss:0.013481190796657208\n",
      "train loss:0.0026044609863773373\n",
      "train loss:0.0001813708934995711\n",
      "train loss:0.0015917933689867658\n",
      "train loss:0.001592965924420772\n",
      "train loss:0.003613029945850218\n",
      "train loss:0.02522587545616563\n",
      "train loss:0.0028695465019035527\n",
      "train loss:0.0010915607574974319\n",
      "train loss:0.0059117740324112645\n",
      "train loss:0.00433674550752013\n",
      "train loss:0.004141485322633469\n",
      "train loss:0.0017638216919531901\n",
      "train loss:0.022061251647462695\n",
      "train loss:0.02072364482207142\n",
      "train loss:0.010546446688712036\n",
      "train loss:0.006617949784955811\n",
      "train loss:0.0002716990454932086\n",
      "train loss:0.0007786672325214207\n",
      "train loss:0.018011811914069663\n",
      "train loss:0.015850376924752357\n",
      "train loss:0.005092394901593324\n",
      "train loss:0.001668629788463805\n",
      "train loss:0.017615953230375923\n",
      "train loss:0.009174442577141097\n",
      "train loss:0.0008514638930870763\n",
      "train loss:0.0018130484646472263\n",
      "train loss:0.002509122684362549\n",
      "train loss:0.004030000676073311\n",
      "train loss:0.01376630631277513\n",
      "train loss:0.01030724266709191\n",
      "train loss:0.0005628149862146772\n",
      "train loss:0.0017057158323721708\n",
      "train loss:0.05732216746977279\n",
      "train loss:0.007339614379484715\n",
      "train loss:0.006987401326695476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006689314666488283\n",
      "train loss:0.0036132896237378114\n",
      "train loss:0.0014107272540523766\n",
      "train loss:0.004407343420949975\n",
      "train loss:0.002815650520543344\n",
      "train loss:0.017408036908945504\n",
      "train loss:0.0013274535533649837\n",
      "train loss:0.0013069461853746531\n",
      "train loss:0.0008725738298982448\n",
      "train loss:0.03798938296144607\n",
      "train loss:0.0042653595907794824\n",
      "train loss:0.009996010607673037\n",
      "train loss:0.004244619348225183\n",
      "train loss:0.024288905354367226\n",
      "train loss:0.0033745193468894593\n",
      "train loss:0.00982252137156117\n",
      "train loss:0.00944627996484826\n",
      "train loss:0.001465922826251647\n",
      "train loss:0.005192285459781593\n",
      "train loss:0.008490944034018207\n",
      "train loss:0.0015761182195453503\n",
      "train loss:0.02621082902175804\n",
      "train loss:0.001704107740092298\n",
      "train loss:0.0068090273368725295\n",
      "train loss:0.0030910066024919503\n",
      "train loss:0.09848970217242739\n",
      "train loss:0.005431576386508167\n",
      "train loss:0.004865177824012717\n",
      "train loss:0.009296813775053321\n",
      "train loss:0.015928711281660724\n",
      "train loss:0.000817220043542436\n",
      "train loss:0.0015567025391959748\n",
      "train loss:0.002237398111343996\n",
      "train loss:0.005112249472299895\n",
      "train loss:0.010086284892178839\n",
      "train loss:0.013782039237692018\n",
      "train loss:0.003625166252455383\n",
      "train loss:0.00653851790745298\n",
      "train loss:0.0041158295498195\n",
      "train loss:0.005576567412281823\n",
      "train loss:0.017978189506463592\n",
      "train loss:0.00466595166773065\n",
      "train loss:0.004255159809424824\n",
      "train loss:0.004737903704301852\n",
      "train loss:0.013645562971297215\n",
      "train loss:0.0008671628149972465\n",
      "train loss:0.012702381650230425\n",
      "train loss:0.022324080846502545\n",
      "train loss:0.004121507688699195\n",
      "train loss:0.012880527425063014\n",
      "train loss:0.007103082002462417\n",
      "train loss:0.005903599556020664\n",
      "train loss:0.007307854986155326\n",
      "train loss:0.007709732716496744\n",
      "train loss:0.017722651336567828\n",
      "train loss:0.00034803161341792496\n",
      "train loss:0.06453892792810935\n",
      "train loss:0.0006021769452969587\n",
      "train loss:0.002888659584411459\n",
      "train loss:0.00143787089732162\n",
      "train loss:0.0039825277443997055\n",
      "train loss:0.011793491706698791\n",
      "train loss:0.0021064598646396374\n",
      "train loss:0.014052045806487492\n",
      "train loss:0.00577196657396822\n",
      "train loss:0.001367020466612882\n",
      "train loss:0.006457015159549594\n",
      "train loss:0.002441419210174756\n",
      "train loss:0.005624630916120845\n",
      "train loss:0.0025476598650255324\n",
      "train loss:0.004240473110016218\n",
      "train loss:0.0039800304496430275\n",
      "train loss:0.0044367527180442365\n",
      "train loss:0.009141862070604745\n",
      "train loss:0.002471122198150823\n",
      "train loss:0.017566573951781246\n",
      "train loss:0.013232709436441026\n",
      "train loss:0.004032483328478453\n",
      "train loss:0.014481751682432098\n",
      "train loss:0.003452880959128255\n",
      "train loss:0.010067151163716337\n",
      "train loss:0.00817488915567005\n",
      "train loss:0.012294090152716366\n",
      "train loss:0.006603294382840882\n",
      "train loss:0.0013553442799646414\n",
      "train loss:0.00838676411493574\n",
      "train loss:0.0032023197294495914\n",
      "train loss:0.018147086985117616\n",
      "train loss:0.01598361642012884\n",
      "train loss:0.009026617985378927\n",
      "train loss:0.004380228308245353\n",
      "train loss:0.008120761141276167\n",
      "train loss:0.0015359230293214435\n",
      "train loss:0.0048905622926854134\n",
      "train loss:0.004035987453319949\n",
      "train loss:0.009627057356452194\n",
      "train loss:0.0019622823870998622\n",
      "train loss:0.0007187194642813878\n",
      "train loss:0.009458039123831924\n",
      "train loss:0.005786256202478376\n",
      "train loss:0.010565060196020904\n",
      "train loss:0.017220792888821244\n",
      "train loss:0.008023396568623947\n",
      "train loss:0.014713613176258552\n",
      "train loss:0.0016888154526805755\n",
      "train loss:0.007327839872011058\n",
      "train loss:0.0055387660341775\n",
      "train loss:0.0007856795948852736\n",
      "train loss:0.0046894031309140565\n",
      "train loss:0.0076242760443070365\n",
      "train loss:0.0033574181150605024\n",
      "train loss:0.001161502091860059\n",
      "train loss:0.006498666910330938\n",
      "train loss:0.0015062976541004817\n",
      "train loss:0.009250432101968027\n",
      "train loss:0.0014387204444285774\n",
      "train loss:0.0037708697919740662\n",
      "train loss:0.004582563456036787\n",
      "train loss:0.0018333816952886062\n",
      "train loss:0.0035321252288237808\n",
      "train loss:0.009192906003320556\n",
      "train loss:0.0053698358810004045\n",
      "train loss:0.004046962438116531\n",
      "train loss:0.004250856374189313\n",
      "train loss:0.0022726043181737986\n",
      "train loss:0.00897214581204778\n",
      "train loss:0.014351186740720438\n",
      "train loss:0.003894704416718329\n",
      "train loss:0.0012242065108860707\n",
      "train loss:0.004670181244494259\n",
      "train loss:0.007087567667201639\n",
      "train loss:0.0042153683177419245\n",
      "train loss:0.012054765562613588\n",
      "train loss:0.01578909297784163\n",
      "train loss:0.009458589320113077\n",
      "train loss:0.0012482404468394533\n",
      "train loss:0.001792537857575436\n",
      "train loss:0.005280727756060212\n",
      "train loss:0.0072473426321784\n",
      "train loss:0.0010232522177950356\n",
      "train loss:0.004558724929242809\n",
      "train loss:0.001512321597321375\n",
      "train loss:0.031206091517540824\n",
      "train loss:0.0005758280775010254\n",
      "train loss:0.0024699111897436795\n",
      "train loss:0.002235852809982336\n",
      "train loss:0.005815422943100327\n",
      "train loss:0.0022049057754980933\n",
      "train loss:0.0062640265579063945\n",
      "train loss:0.004692865580947526\n",
      "train loss:0.008693666097777754\n",
      "train loss:0.0035009463820263255\n",
      "train loss:0.00141524343754377\n",
      "train loss:0.0066645593576190425\n",
      "train loss:0.0001730873262841666\n",
      "train loss:0.0052165589082623694\n",
      "train loss:0.04138933184094312\n",
      "train loss:0.008133344110302617\n",
      "train loss:0.003636558808177431\n",
      "train loss:0.0036996975250376896\n",
      "train loss:0.007811047968570222\n",
      "train loss:0.010156482457273002\n",
      "train loss:0.00209804839222035\n",
      "train loss:0.00705430677178863\n",
      "train loss:0.004282021685252135\n",
      "train loss:0.0023443255293668108\n",
      "train loss:0.000407134974357595\n",
      "train loss:0.0008967498130450414\n",
      "train loss:0.004178557518949767\n",
      "train loss:0.005659197384160527\n",
      "train loss:0.015384324105890957\n",
      "train loss:0.0017559496794607833\n",
      "train loss:0.0011745730899366076\n",
      "train loss:0.010365722854896217\n",
      "train loss:0.07104071736354622\n",
      "train loss:0.009474707454709748\n",
      "train loss:0.0019961286618978627\n",
      "train loss:0.002200591949273198\n",
      "train loss:0.00516573458276201\n",
      "train loss:0.00532779562580055\n",
      "train loss:0.00230383402778945\n",
      "train loss:0.005901236681173696\n",
      "train loss:0.008314163152845774\n",
      "train loss:0.0048546801397671225\n",
      "train loss:0.007524864989816495\n",
      "train loss:0.002504641201590544\n",
      "train loss:0.003168920197720992\n",
      "train loss:0.015771771359793428\n",
      "train loss:0.021221717502102173\n",
      "train loss:0.0016586002224703055\n",
      "train loss:0.005215688341607671\n",
      "train loss:0.0016547914290379528\n",
      "train loss:0.002563864403632819\n",
      "train loss:0.0038276772291745693\n",
      "train loss:0.012110438258680849\n",
      "train loss:0.0022089218574247883\n",
      "train loss:0.011659401247021141\n",
      "train loss:0.02576685356964054\n",
      "train loss:0.005291339320368607\n",
      "train loss:0.001622238441650627\n",
      "train loss:0.0069984949998725746\n",
      "train loss:0.005275254463143827\n",
      "train loss:0.012673411356959659\n",
      "train loss:0.0057458492093930835\n",
      "train loss:0.03272286028194674\n",
      "train loss:0.002959757522450969\n",
      "train loss:0.01627994076313515\n",
      "train loss:0.00793567435044388\n",
      "train loss:0.0008998253472046361\n",
      "train loss:0.004421992974204036\n",
      "train loss:0.0024619183197955143\n",
      "train loss:0.009732497806397773\n",
      "train loss:0.003956815586995975\n",
      "train loss:0.006511878039823684\n",
      "train loss:0.009394878979864314\n",
      "train loss:0.0021240569278670332\n",
      "train loss:0.002169861043230258\n",
      "train loss:0.004934960985995151\n",
      "train loss:0.005054693383212016\n",
      "train loss:0.0053871669068202175\n",
      "train loss:0.004146225124032338\n",
      "train loss:0.001631214616216462\n",
      "train loss:0.00848708594736265\n",
      "train loss:0.00035522827853521586\n",
      "train loss:0.001020763783375846\n",
      "train loss:0.006823759479469445\n",
      "train loss:0.0011264383536733894\n",
      "train loss:0.013650959298979476\n",
      "train loss:0.004948360854150773\n",
      "train loss:0.0008331016068914779\n",
      "train loss:0.012939240195877576\n",
      "train loss:0.005519579971001707\n",
      "train loss:0.016901666092198616\n",
      "train loss:0.0023057809727016934\n",
      "train loss:0.005292805433793901\n",
      "train loss:0.0017552297824880254\n",
      "train loss:0.00384597798396211\n",
      "train loss:0.005822587379341247\n",
      "train loss:0.006435625507524317\n",
      "train loss:0.006960592742927345\n",
      "train loss:0.006182206607113498\n",
      "train loss:0.0037086828294911234\n",
      "train loss:0.0019538109496967803\n",
      "train loss:0.0035750244840256256\n",
      "train loss:0.005378120744198708\n",
      "train loss:0.005796485539042556\n",
      "train loss:0.0383288771032691\n",
      "train loss:0.0020957970230691876\n",
      "train loss:0.010807159694488387\n",
      "train loss:0.005785934464263045\n",
      "train loss:0.005297705175867268\n",
      "train loss:0.00243910732063287\n",
      "train loss:0.002584051945920891\n",
      "train loss:0.0026235999633968782\n",
      "train loss:0.00042555687584576484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005658520657065693\n",
      "train loss:0.018775818145412484\n",
      "train loss:0.003149749727542389\n",
      "train loss:0.005090859575720965\n",
      "train loss:0.0024165897129183244\n",
      "train loss:0.006894520222906645\n",
      "train loss:0.0008104904436203329\n",
      "train loss:0.01065188969665259\n",
      "train loss:0.032429265305430534\n",
      "train loss:0.01394456752714088\n",
      "train loss:0.007726752624606158\n",
      "train loss:0.0015797279483739666\n",
      "train loss:0.00395995925310879\n",
      "train loss:0.004570756000793556\n",
      "train loss:0.0021345180424780998\n",
      "train loss:0.0003791711954050531\n",
      "train loss:0.000877061677366741\n",
      "train loss:0.0018142526326557157\n",
      "train loss:0.005573907818844471\n",
      "train loss:0.012911590966173902\n",
      "train loss:0.006963403939300811\n",
      "train loss:0.0008651272288838972\n",
      "train loss:0.013845367257228815\n",
      "train loss:0.0014416066815236175\n",
      "train loss:0.007683014416210902\n",
      "train loss:0.004590788859135129\n",
      "train loss:0.002972984656327676\n",
      "train loss:0.009240289955557085\n",
      "train loss:0.003469534935303073\n",
      "train loss:0.0014618980458229577\n",
      "train loss:0.0008288237898158347\n",
      "train loss:0.0024011197658807344\n",
      "train loss:0.0033333675612158605\n",
      "train loss:0.0005920371679736128\n",
      "train loss:0.0013175609351316888\n",
      "train loss:0.06204530532804804\n",
      "train loss:0.020809500207452838\n",
      "train loss:0.009815695772277089\n",
      "train loss:0.0020906006449294013\n",
      "train loss:0.017382726750953946\n",
      "train loss:0.005220652254642216\n",
      "train loss:0.09360264388422297\n",
      "train loss:0.0014574791087351338\n",
      "train loss:0.0005216269999281478\n",
      "train loss:0.002650599455516973\n",
      "train loss:0.0007452726152141363\n",
      "train loss:0.03163683375176594\n",
      "train loss:0.004818437691495458\n",
      "train loss:0.025346974293798386\n",
      "train loss:0.03711392845987052\n",
      "train loss:0.0029134422514897813\n",
      "train loss:0.0019176163910918933\n",
      "train loss:0.00464255014936095\n",
      "train loss:0.013368269084810565\n",
      "train loss:0.00543823062688182\n",
      "train loss:0.0101303833178012\n",
      "train loss:0.0019054999763198474\n",
      "train loss:0.006000290276473646\n",
      "train loss:0.002289994908905687\n",
      "train loss:0.007351198696497982\n",
      "train loss:0.002534717182356533\n",
      "train loss:0.02045324108366491\n",
      "train loss:0.01131584542023176\n",
      "train loss:0.002175785911687036\n",
      "train loss:0.006405047924553882\n",
      "train loss:0.0108657202694673\n",
      "train loss:0.0041021222786320295\n",
      "train loss:0.004222711497793583\n",
      "train loss:0.0007375810688928569\n",
      "train loss:0.040522294065825415\n",
      "train loss:0.00039099287344254176\n",
      "train loss:0.0002377870239667305\n",
      "train loss:0.10729539270443393\n",
      "train loss:0.04486331727453674\n",
      "train loss:0.008114926738634582\n",
      "train loss:0.024485149588842833\n",
      "train loss:0.0019473516484037946\n",
      "train loss:0.005311417181382288\n",
      "train loss:0.007385350185250487\n",
      "train loss:0.0031909563394554746\n",
      "train loss:0.005226190351314656\n",
      "train loss:0.005152944275463275\n",
      "train loss:0.001410959722098373\n",
      "train loss:0.004601868124811488\n",
      "train loss:0.008118790301134642\n",
      "train loss:0.014316449730965089\n",
      "train loss:0.03486608610592359\n",
      "train loss:0.01154782584745912\n",
      "train loss:0.00952069509154518\n",
      "train loss:0.0025297356624073906\n",
      "train loss:0.002258596312245736\n",
      "train loss:0.0040358500699062706\n",
      "train loss:0.012342934972289363\n",
      "train loss:0.004910977853787679\n",
      "train loss:0.017010843461652478\n",
      "train loss:0.035795830508638646\n",
      "train loss:0.003999648818983387\n",
      "train loss:0.007657178422651928\n",
      "train loss:0.0033297534959651123\n",
      "train loss:0.04648890684227962\n",
      "train loss:0.007233859227633004\n",
      "train loss:0.0005340716969211067\n",
      "train loss:0.011378646406855328\n",
      "train loss:0.012100863827011537\n",
      "train loss:0.0064506319822021044\n",
      "=== epoch:12, train acc:0.992, test acc:0.983 ===\n",
      "train loss:0.0029374546202408465\n",
      "train loss:0.013627127886052698\n",
      "train loss:0.005834251865401554\n",
      "train loss:0.003906986147275297\n",
      "train loss:0.003886400764010736\n",
      "train loss:0.0012403489283184068\n",
      "train loss:0.0019712692954872856\n",
      "train loss:0.004044784114470069\n",
      "train loss:0.007355393523700982\n",
      "train loss:0.0015250408526731236\n",
      "train loss:0.0028831723202562055\n",
      "train loss:0.0039017359255823637\n",
      "train loss:0.001164757189874125\n",
      "train loss:0.009419709777105266\n",
      "train loss:0.0007665226606684803\n",
      "train loss:0.0002015824595990125\n",
      "train loss:0.006089673960666304\n",
      "train loss:0.01263031979383922\n",
      "train loss:0.0026278080882905217\n",
      "train loss:0.001324296050246993\n",
      "train loss:0.013445905460147605\n",
      "train loss:0.0029416796787390988\n",
      "train loss:0.005519761869654967\n",
      "train loss:0.0035081206637241984\n",
      "train loss:0.001743082329197999\n",
      "train loss:0.0015418446698752687\n",
      "train loss:0.11613618461036798\n",
      "train loss:0.0033082396164376034\n",
      "train loss:0.0009177671466957869\n",
      "train loss:0.0019541734519722244\n",
      "train loss:0.0026198673817737455\n",
      "train loss:0.0015080350076698546\n",
      "train loss:0.022884255599468453\n",
      "train loss:0.008844358858541962\n",
      "train loss:0.05743231422703502\n",
      "train loss:0.005913583350522936\n",
      "train loss:0.007847319142662939\n",
      "train loss:0.019155709882856153\n",
      "train loss:0.0045444793608651205\n",
      "train loss:0.016031481086307985\n",
      "train loss:0.004914107399640665\n",
      "train loss:0.015062673508504274\n",
      "train loss:0.002509240566364166\n",
      "train loss:0.006703695557983158\n",
      "train loss:0.004400984379444417\n",
      "train loss:0.00396465886810261\n",
      "train loss:0.0020049536323983046\n",
      "train loss:0.05161287616112272\n",
      "train loss:0.012544273699069169\n",
      "train loss:0.00423241395099607\n",
      "train loss:0.0052288876516473435\n",
      "train loss:0.0038012441171577194\n",
      "train loss:0.004825232346496109\n",
      "train loss:0.0015604230795021145\n",
      "train loss:0.021121841179506422\n",
      "train loss:0.00927488351428702\n",
      "train loss:0.001061027183718149\n",
      "train loss:0.0054389579788371644\n",
      "train loss:0.003464005998543429\n",
      "train loss:0.017294219639197916\n",
      "train loss:0.009345186048612047\n",
      "train loss:0.006423180250229683\n",
      "train loss:0.013335079434468343\n",
      "train loss:0.002304609279410456\n",
      "train loss:0.01021540469246178\n",
      "train loss:0.005767923358606054\n",
      "train loss:0.0019333907699220704\n",
      "train loss:0.00158467369842649\n",
      "train loss:0.0026090672929035084\n",
      "train loss:0.009960430483353287\n",
      "train loss:0.004384529363059863\n",
      "train loss:0.008711579138292257\n",
      "train loss:0.001505568075174662\n",
      "train loss:0.006836347102639039\n",
      "train loss:0.006058275177754308\n",
      "train loss:0.004220395768799932\n",
      "train loss:0.003238145079203223\n",
      "train loss:0.00039947095848516816\n",
      "train loss:0.005256453095622908\n",
      "train loss:0.0010615360683232885\n",
      "train loss:0.00786350056747219\n",
      "train loss:0.005249154600027947\n",
      "train loss:0.015205131463591613\n",
      "train loss:0.00035157966284320874\n",
      "train loss:0.00297071280457341\n",
      "train loss:0.009655162917248576\n",
      "train loss:0.009843742381414717\n",
      "train loss:0.0060948371131151835\n",
      "train loss:0.003555862574900939\n",
      "train loss:0.002745641266126302\n",
      "train loss:0.019286456191509305\n",
      "train loss:0.008689535995398996\n",
      "train loss:0.00581716727034681\n",
      "train loss:0.0032839801852396146\n",
      "train loss:0.01060359829568884\n",
      "train loss:0.015712472772781212\n",
      "train loss:0.008934530158781592\n",
      "train loss:0.0010945246492544576\n",
      "train loss:0.0032864108546170577\n",
      "train loss:0.002843575084214712\n",
      "train loss:0.0017471234277867218\n",
      "train loss:0.002641187880439832\n",
      "train loss:0.001426140875360243\n",
      "train loss:0.031257216999701146\n",
      "train loss:0.0060848053165570406\n",
      "train loss:0.0033020760316488378\n",
      "train loss:0.0018461680041523365\n",
      "train loss:0.0005978056617781371\n",
      "train loss:0.007250890218878234\n",
      "train loss:0.0037620224914565676\n",
      "train loss:0.013620346279629119\n",
      "train loss:0.003923377063453121\n",
      "train loss:0.007339436413903602\n",
      "train loss:0.0033982784755847606\n",
      "train loss:0.003969042078482016\n",
      "train loss:0.002136097141069944\n",
      "train loss:0.0007109292516046654\n",
      "train loss:0.002641134687952636\n",
      "train loss:0.005792660479289953\n",
      "train loss:0.0033759600033655473\n",
      "train loss:0.0027854417743065807\n",
      "train loss:0.002160640191882047\n",
      "train loss:0.00949461334538149\n",
      "train loss:0.0045001932585867245\n",
      "train loss:0.0034334806060642136\n",
      "train loss:0.007593601562911153\n",
      "train loss:0.0038677044670898954\n",
      "train loss:0.004803336156524642\n",
      "train loss:0.0013905342279035122\n",
      "train loss:0.01100498489904099\n",
      "train loss:0.013755880692226658\n",
      "train loss:0.0015394572053829556\n",
      "train loss:0.0055633557766614486\n",
      "train loss:0.01713968083249886\n",
      "train loss:0.0035353017459544456\n",
      "train loss:0.0007842925252553963\n",
      "train loss:0.0027485972924531366\n",
      "train loss:0.0008700121408031339\n",
      "train loss:0.0007132112870700259\n",
      "train loss:0.009390065238539082\n",
      "train loss:0.002658108770858774\n",
      "train loss:0.0003735351992051754\n",
      "train loss:0.000432508325655273\n",
      "train loss:0.003993476248433859\n",
      "train loss:0.005931380613453081\n",
      "train loss:0.0005439547092834968\n",
      "train loss:0.0034551328145783072\n",
      "train loss:0.0033148391439189726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022024377086112697\n",
      "train loss:0.011473312367461732\n",
      "train loss:0.006099705683811662\n",
      "train loss:0.01131056257245947\n",
      "train loss:0.0013759417298491114\n",
      "train loss:0.006098066625139291\n",
      "train loss:0.0003489456632436361\n",
      "train loss:0.004911536369745327\n",
      "train loss:0.007113185323562915\n",
      "train loss:0.00043893104255887433\n",
      "train loss:0.010405133737465114\n",
      "train loss:0.006788187277001701\n",
      "train loss:0.02387101031739971\n",
      "train loss:0.001993018280144895\n",
      "train loss:0.0017253165310946571\n",
      "train loss:0.004051487542258851\n",
      "train loss:0.0003074694370138481\n",
      "train loss:0.004592520042668848\n",
      "train loss:0.0034179337067849896\n",
      "train loss:0.0012644320349891108\n",
      "train loss:0.0021450626710353745\n",
      "train loss:0.006681188419790843\n",
      "train loss:0.008077177198072294\n",
      "train loss:0.01238716796473428\n",
      "train loss:0.0007372938340062171\n",
      "train loss:0.00222063751507701\n",
      "train loss:0.0003109166776914608\n",
      "train loss:0.002426340116934896\n",
      "train loss:0.004298593631648464\n",
      "train loss:0.0009539682125057986\n",
      "train loss:0.011966221424090505\n",
      "train loss:0.010945838523610025\n",
      "train loss:0.004162347187132805\n",
      "train loss:0.0020820404383219385\n",
      "train loss:0.0044789383734395085\n",
      "train loss:0.02013268110693347\n",
      "train loss:0.004721141190317918\n",
      "train loss:0.006255623338034353\n",
      "train loss:0.001500495955753395\n",
      "train loss:0.0017098862711863994\n",
      "train loss:0.0016114320132449129\n",
      "train loss:0.0067481860516345905\n",
      "train loss:0.005878176938183492\n",
      "train loss:0.00447690245441994\n",
      "train loss:0.01119282727322083\n",
      "train loss:0.004681481263601243\n",
      "train loss:0.003823004733331408\n",
      "train loss:0.012694496153162987\n",
      "train loss:0.005586934093729714\n",
      "train loss:0.015045358169766838\n",
      "train loss:0.0019065372148348643\n",
      "train loss:0.0021619000236546143\n",
      "train loss:0.0031196990209416153\n",
      "train loss:0.0051087370973303915\n",
      "train loss:0.009152675050881054\n",
      "train loss:0.005215210810400579\n",
      "train loss:0.002491174606810954\n",
      "train loss:0.006876777759913269\n",
      "train loss:0.0028674038489919194\n",
      "train loss:0.0023004171697947502\n",
      "train loss:0.0011074563264534209\n",
      "train loss:0.004637231924947562\n",
      "train loss:0.008731843935675034\n",
      "train loss:0.029405765498763\n",
      "train loss:0.0020996705214844074\n",
      "train loss:0.0033477308804048733\n",
      "train loss:0.006518062370169\n",
      "train loss:0.0007410448569585919\n",
      "train loss:0.012991434138860954\n",
      "train loss:0.009713452628992873\n",
      "train loss:0.008737046549373252\n",
      "train loss:0.005390583432446905\n",
      "train loss:0.005834190925929264\n",
      "train loss:0.0007263624201886653\n",
      "train loss:0.019502948171275424\n",
      "train loss:0.00419050664884467\n",
      "train loss:0.010927519511153259\n",
      "train loss:0.0027035799320163285\n",
      "train loss:0.027298896537527616\n",
      "train loss:0.0032002162959162677\n",
      "train loss:0.0016995540494305372\n",
      "train loss:0.0013522107657682808\n",
      "train loss:0.0015227932829045788\n",
      "train loss:0.017135818082829934\n",
      "train loss:0.004872982761757168\n",
      "train loss:0.004335958755430105\n",
      "train loss:0.013085548899255887\n",
      "train loss:0.0032840122139537616\n",
      "train loss:0.0032166220970217202\n",
      "train loss:0.014738259502880824\n",
      "train loss:0.004250823506689581\n",
      "train loss:0.011435379625954123\n",
      "train loss:0.0036794013744636607\n",
      "train loss:0.0006612027531562942\n",
      "train loss:0.000780101891503119\n",
      "train loss:0.0038517298648958224\n",
      "train loss:0.0038414926567370096\n",
      "train loss:0.013836393034215464\n",
      "train loss:0.004320156346808945\n",
      "train loss:0.004489337670307553\n",
      "train loss:0.002474639823822364\n",
      "train loss:0.019770052600900076\n",
      "train loss:0.03771189884191123\n",
      "train loss:0.003156117202043929\n",
      "train loss:0.00027449912397959974\n",
      "train loss:0.007886968086265747\n",
      "train loss:0.0030498439984998904\n",
      "train loss:0.005106714549211025\n",
      "train loss:0.005805863934403992\n",
      "train loss:0.0036594643435109825\n",
      "train loss:0.004620663306976728\n",
      "train loss:0.00033803702346019127\n",
      "train loss:0.010129973578722857\n",
      "train loss:0.0029787953011242547\n",
      "train loss:0.0038335741703048685\n",
      "train loss:0.0009927759262842368\n",
      "train loss:0.0017058941494602798\n",
      "train loss:0.004375982626915495\n",
      "train loss:0.008300966327057797\n",
      "train loss:0.010303709554951412\n",
      "train loss:0.005453973719694468\n",
      "train loss:0.0031083647046894324\n",
      "train loss:0.0013417263831191975\n",
      "train loss:0.010831314750626401\n",
      "train loss:0.0017538487564509122\n",
      "train loss:0.006071133730340585\n",
      "train loss:0.005078797308729768\n",
      "train loss:0.010067037510087622\n",
      "train loss:0.0005723040499612261\n",
      "train loss:0.005436862624106742\n",
      "train loss:0.008567849334442377\n",
      "train loss:0.007298813059412664\n",
      "train loss:0.0035349243050686926\n",
      "train loss:0.012933369497656735\n",
      "train loss:0.0022905291365432024\n",
      "train loss:0.002570559103824765\n",
      "train loss:0.0027839037517386734\n",
      "train loss:0.001254213335724354\n",
      "train loss:0.013457006903336233\n",
      "train loss:0.00011185730678393073\n",
      "train loss:0.0008428737795669203\n",
      "train loss:0.009822264529001833\n",
      "train loss:0.0037244051496833535\n",
      "train loss:0.010753840670214005\n",
      "train loss:0.02161213366681261\n",
      "train loss:0.007820903265813197\n",
      "train loss:0.006746457781725739\n",
      "train loss:0.0017939343205542243\n",
      "train loss:0.008728366827667087\n",
      "train loss:0.007211641473794019\n",
      "train loss:0.001882666857608868\n",
      "train loss:0.010726511820841056\n",
      "train loss:0.002937960067566188\n",
      "train loss:0.004063281679212606\n",
      "train loss:0.031279406885743204\n",
      "train loss:0.0047551167644589755\n",
      "train loss:0.008110938148746418\n",
      "train loss:0.0011569674920073347\n",
      "train loss:0.01868942794223548\n",
      "train loss:0.01226946054190696\n",
      "train loss:0.005059533070985055\n",
      "train loss:0.011602339363592486\n",
      "train loss:0.0002392328246149023\n",
      "train loss:0.0023050936150253425\n",
      "train loss:0.012072065024646495\n",
      "train loss:0.0038725195375074128\n",
      "train loss:0.0033833606174329613\n",
      "train loss:0.001041711682932249\n",
      "train loss:0.0015461247589750643\n",
      "train loss:0.020120206910919043\n",
      "train loss:0.0017130793334021164\n",
      "train loss:0.004570861901583908\n",
      "train loss:0.005246865128143912\n",
      "train loss:0.0044463797156845284\n",
      "train loss:0.0006558996941122428\n",
      "train loss:0.005797377520557277\n",
      "train loss:0.0111610180959144\n",
      "train loss:0.0008380481389262783\n",
      "train loss:0.0010414947523227178\n",
      "train loss:0.0008423133274456122\n",
      "train loss:0.005127599798402038\n",
      "train loss:0.002916605651791041\n",
      "train loss:0.002954231583164985\n",
      "train loss:0.006467390242856987\n",
      "train loss:0.0030816540002665455\n",
      "train loss:0.009379552157497145\n",
      "train loss:0.0005559862554347728\n",
      "train loss:0.002920677429414001\n",
      "train loss:0.0031147601826873018\n",
      "train loss:0.0015138405310369675\n",
      "train loss:0.003976464683326871\n",
      "train loss:0.002102554347013669\n",
      "train loss:0.0011778060418861055\n",
      "train loss:0.03188676760603522\n",
      "train loss:0.010778526774022038\n",
      "train loss:0.000368396464092742\n",
      "train loss:0.00253076602116595\n",
      "train loss:0.004651943785175578\n",
      "train loss:0.0032332069116546153\n",
      "train loss:0.00298855077738869\n",
      "train loss:0.0010009038395285474\n",
      "train loss:0.004282965506698284\n",
      "train loss:0.006124560103198448\n",
      "train loss:0.008423922432457912\n",
      "train loss:0.0070167736724976735\n",
      "train loss:0.005436279647515224\n",
      "train loss:0.0012694144009324552\n",
      "train loss:0.0073059446307490615\n",
      "train loss:0.0024641907488003006\n",
      "train loss:0.0022678025416992807\n",
      "train loss:0.003307454745083243\n",
      "train loss:0.0037171990609221046\n",
      "train loss:0.0003318964475966522\n",
      "train loss:0.0029896409689240456\n",
      "train loss:0.0018457508352772178\n",
      "train loss:0.026814255655582497\n",
      "train loss:0.008321383969340186\n",
      "train loss:0.05387646607526109\n",
      "train loss:0.0018902433170288949\n",
      "train loss:0.005847219061340835\n",
      "train loss:0.001568781777990881\n",
      "train loss:0.007276179629942576\n",
      "train loss:0.002371417488344494\n",
      "train loss:0.0012530055541552223\n",
      "train loss:0.005775725381897615\n",
      "train loss:0.0012209571192402535\n",
      "train loss:0.021799568283934288\n",
      "train loss:0.0015070297946778955\n",
      "train loss:0.01788111498943335\n",
      "train loss:0.0020228162510172914\n",
      "train loss:0.002955454656031829\n",
      "train loss:0.003239404333401787\n",
      "train loss:0.001662002095893708\n",
      "train loss:0.0004574612685690898\n",
      "train loss:0.004130801873990965\n",
      "train loss:0.00022320618523932203\n",
      "train loss:0.0006447167749484908\n",
      "train loss:0.0015722474846767602\n",
      "train loss:0.0003995600225981316\n",
      "train loss:0.0008529521046355698\n",
      "train loss:0.0040013037020643905\n",
      "train loss:0.006212959638866508\n",
      "train loss:0.0009490215666359715\n",
      "train loss:0.008034293532253732\n",
      "train loss:0.0026273619101309753\n",
      "train loss:0.001353868850118603\n",
      "train loss:0.0010398463516091917\n",
      "train loss:0.0017711300854239798\n",
      "train loss:0.0005231216425188766\n",
      "train loss:0.002309826330614487\n",
      "train loss:0.005007864013777231\n",
      "train loss:0.0008615815650321773\n",
      "train loss:0.014461793858964367\n",
      "train loss:0.0015188373642408678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00885556138341052\n",
      "train loss:0.004027064524646045\n",
      "train loss:0.002073793042940857\n",
      "train loss:0.004582903235997498\n",
      "train loss:0.015569819116427299\n",
      "train loss:0.0021171949653587367\n",
      "train loss:0.014098099104418654\n",
      "train loss:0.002085444146484465\n",
      "train loss:0.005438091940277514\n",
      "train loss:0.0009475803747999084\n",
      "train loss:0.0009032341894480539\n",
      "train loss:0.00504562121637619\n",
      "train loss:0.003116941509319033\n",
      "train loss:0.0044514969562756915\n",
      "train loss:0.005598609308626487\n",
      "train loss:0.0016569354334062423\n",
      "train loss:0.0029572318443092387\n",
      "train loss:0.003867008013657239\n",
      "train loss:0.007918044914577777\n",
      "train loss:0.007678941476755677\n",
      "train loss:0.01974239696792789\n",
      "train loss:0.020505357531133944\n",
      "train loss:0.009808236513831064\n",
      "train loss:0.022098634217832647\n",
      "train loss:0.0023278969422589886\n",
      "train loss:0.0035134516954890742\n",
      "train loss:0.022841928225849722\n",
      "train loss:0.0019929110051100834\n",
      "train loss:0.0019385415473509645\n",
      "train loss:0.005985643577869824\n",
      "train loss:0.0008245869850769556\n",
      "train loss:0.012589203164355528\n",
      "train loss:0.003487539643197354\n",
      "train loss:0.00037725014389599715\n",
      "train loss:0.0019772261492967606\n",
      "train loss:0.012539020431367686\n",
      "train loss:0.00047528123308915424\n",
      "train loss:0.010407257205563536\n",
      "train loss:0.0011677114457236063\n",
      "train loss:0.0022403801995200152\n",
      "train loss:0.008595442717116812\n",
      "train loss:0.0010791069217883132\n",
      "train loss:0.004368605584597775\n",
      "train loss:0.004944095606538223\n",
      "train loss:0.0036617552347373407\n",
      "train loss:0.0009723250856260227\n",
      "train loss:0.00552946643019328\n",
      "train loss:0.002627876492621663\n",
      "train loss:0.005116459176858313\n",
      "train loss:0.0005732838389761999\n",
      "train loss:0.0018128805375848933\n",
      "train loss:0.008523653523459948\n",
      "train loss:0.0005436488080789553\n",
      "train loss:0.012148325981672724\n",
      "train loss:0.0008501495518970832\n",
      "train loss:0.005214743767643467\n",
      "train loss:0.0022583700805138816\n",
      "train loss:0.0006609616460320401\n",
      "train loss:0.0027564256556385507\n",
      "train loss:0.0002845821648496625\n",
      "train loss:0.0013082238937736782\n",
      "train loss:0.0015860660775375013\n",
      "train loss:0.003999231304805471\n",
      "train loss:0.00712695841215461\n",
      "train loss:0.0032580718822859903\n",
      "train loss:0.00021276077745727476\n",
      "train loss:0.007105901740120055\n",
      "train loss:0.007370056342897487\n",
      "train loss:0.006633251695843415\n",
      "train loss:0.004328362336362108\n",
      "train loss:0.0017848449470680957\n",
      "train loss:0.0029191446931552917\n",
      "train loss:0.002668945349284356\n",
      "train loss:0.0037819451638489558\n",
      "train loss:0.01703011665227788\n",
      "train loss:0.0006931561354234155\n",
      "train loss:0.02868346769570537\n",
      "train loss:0.0009920595565798712\n",
      "train loss:0.0001956613817048473\n",
      "train loss:0.03094955005174438\n",
      "train loss:0.000810894686184432\n",
      "train loss:0.013700693817798142\n",
      "train loss:0.0001987808201477508\n",
      "train loss:0.0007410225399278629\n",
      "train loss:0.005344175949860509\n",
      "train loss:0.002915502924479676\n",
      "train loss:0.00414387389890703\n",
      "train loss:0.003414233430465858\n",
      "train loss:0.011155388354257072\n",
      "train loss:0.0013437713302517232\n",
      "train loss:0.0043899952681476315\n",
      "train loss:0.0011283043203899128\n",
      "train loss:0.003102070141776091\n",
      "train loss:0.0033089413428344905\n",
      "train loss:0.0003025199419168203\n",
      "train loss:0.0018422281148232217\n",
      "train loss:0.006065427073505847\n",
      "train loss:0.0006649267209121961\n",
      "train loss:0.0013111145971913879\n",
      "train loss:0.018122171528237897\n",
      "train loss:0.0006899518665887469\n",
      "train loss:0.006775865807753004\n",
      "train loss:0.0027477251732520645\n",
      "train loss:0.0027933547960297856\n",
      "train loss:0.0015545005646626791\n",
      "train loss:0.002064820201641336\n",
      "train loss:0.0016949364883742102\n",
      "train loss:0.0006819019616175156\n",
      "train loss:0.002251194286602057\n",
      "train loss:0.0009748069228031544\n",
      "train loss:0.0025246341832306594\n",
      "train loss:0.01501637441529547\n",
      "train loss:0.005594174162506011\n",
      "train loss:0.0011238720214878097\n",
      "train loss:0.004187642537179017\n",
      "train loss:0.012242596153645835\n",
      "train loss:0.001450356232332976\n",
      "train loss:0.0015956842388953547\n",
      "train loss:0.008218486681537964\n",
      "train loss:0.0005804690533044933\n",
      "train loss:0.007133568089932894\n",
      "train loss:0.0013352234630970258\n",
      "train loss:0.002762656030707915\n",
      "train loss:0.0025662007843707587\n",
      "train loss:0.00011978663868734628\n",
      "train loss:0.037128865514509696\n",
      "train loss:0.0012841595220781333\n",
      "train loss:0.006969836972128725\n",
      "train loss:0.0019308436415190228\n",
      "train loss:0.004473854703027491\n",
      "train loss:0.0033148348539461855\n",
      "train loss:0.008153182312596404\n",
      "train loss:0.006557250966375584\n",
      "train loss:0.004290087789739919\n",
      "train loss:0.00310264437681353\n",
      "train loss:0.0017042772103836787\n",
      "train loss:0.0005650173364218243\n",
      "train loss:0.00248353680581809\n",
      "train loss:0.0014116470536896996\n",
      "train loss:0.004891529756398483\n",
      "train loss:0.001812352852551241\n",
      "train loss:0.004728173055378362\n",
      "train loss:0.0013417629215030744\n",
      "train loss:0.007085567796679942\n",
      "train loss:0.0006130813687343357\n",
      "train loss:0.004167454206746701\n",
      "train loss:0.013464523953894105\n",
      "train loss:0.0003624955290371937\n",
      "train loss:0.005708722979211937\n",
      "train loss:0.0012275860168068067\n",
      "train loss:0.005426798823710476\n",
      "train loss:0.0017662097807569876\n",
      "train loss:0.0037590005280470074\n",
      "train loss:0.005424037046778382\n",
      "train loss:0.0027805709494286225\n",
      "train loss:0.002086467262198303\n",
      "train loss:0.00333112823505936\n",
      "train loss:0.004887179022103275\n",
      "train loss:0.0026079052811797117\n",
      "train loss:0.018653240501113687\n",
      "train loss:0.0016651648569473013\n",
      "train loss:0.0012531423359047847\n",
      "train loss:0.00012536538067975056\n",
      "train loss:0.0030178213573125545\n",
      "train loss:0.004347712178275308\n",
      "train loss:0.00761293977211673\n",
      "train loss:0.0034180118197717556\n",
      "train loss:0.009954352657052917\n",
      "train loss:0.004064459516321235\n",
      "train loss:0.0003877297191181149\n",
      "train loss:0.0027982327101767936\n",
      "train loss:0.000962739040785823\n",
      "train loss:0.0024388440463127057\n",
      "train loss:0.005724949472164867\n",
      "train loss:0.0020554713918702885\n",
      "train loss:0.0029413871898934223\n",
      "train loss:0.0025222778720971127\n",
      "train loss:0.0008376692228425457\n",
      "train loss:0.008578795205066686\n",
      "train loss:0.0037028945307123547\n",
      "train loss:0.005062674184921374\n",
      "train loss:0.00535855204424506\n",
      "train loss:0.0032240845063881336\n",
      "train loss:0.0018325420740892967\n",
      "train loss:0.004087234891841303\n",
      "train loss:0.001142439234531765\n",
      "train loss:0.0017724173287709114\n",
      "train loss:0.0016357774695899701\n",
      "train loss:0.0022286731941293524\n",
      "train loss:0.0030280218548305294\n",
      "train loss:0.003922579501890298\n",
      "train loss:0.0020900176082674447\n",
      "train loss:0.006853210278204743\n",
      "train loss:0.0025192315609939863\n",
      "train loss:0.002596562523625049\n",
      "train loss:0.005476685493260093\n",
      "train loss:0.0012556919190970246\n",
      "train loss:0.05554466716963094\n",
      "=== epoch:13, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.006249400414614033\n",
      "train loss:0.007482455087571103\n",
      "train loss:0.002547986777579691\n",
      "train loss:0.0020595008498546213\n",
      "train loss:0.0022136302863068587\n",
      "train loss:0.0004775145896908313\n",
      "train loss:0.001671583106090215\n",
      "train loss:0.003499092667098176\n",
      "train loss:0.008505018508980928\n",
      "train loss:0.0023247217892438097\n",
      "train loss:0.0019243276078883661\n",
      "train loss:0.006469373459406474\n",
      "train loss:0.0017559293389348392\n",
      "train loss:0.0018089305946058112\n",
      "train loss:0.012578751888107165\n",
      "train loss:0.012883649380954829\n",
      "train loss:0.0034781107617570463\n",
      "train loss:0.0007369527012709314\n",
      "train loss:0.0008496552913184878\n",
      "train loss:0.0019686167595980115\n",
      "train loss:0.04263669064961698\n",
      "train loss:0.0029370276365365596\n",
      "train loss:0.000779425429104188\n",
      "train loss:0.0028112702327534335\n",
      "train loss:0.005874140610616116\n",
      "train loss:0.0037414979354601892\n",
      "train loss:0.00040836726163734523\n",
      "train loss:0.005702166201714456\n",
      "train loss:0.0052619495674102144\n",
      "train loss:0.0034081523434186327\n",
      "train loss:0.0012940559796752193\n",
      "train loss:0.0018397016704367571\n",
      "train loss:0.003078798142494149\n",
      "train loss:0.004182574485192889\n",
      "train loss:0.008880519808359596\n",
      "train loss:0.0045285030937971815\n",
      "train loss:0.005667978059053256\n",
      "train loss:0.003921726350466597\n",
      "train loss:0.0003539067771809935\n",
      "train loss:0.0008344782185439925\n",
      "train loss:0.010458062185208013\n",
      "train loss:0.001177414235251571\n",
      "train loss:0.0017420872763226935\n",
      "train loss:0.000693284855722126\n",
      "train loss:0.0008777340075778388\n",
      "train loss:0.004607281266364738\n",
      "train loss:0.00204963329857234\n",
      "train loss:0.0140230358680428\n",
      "train loss:0.003401852903457124\n",
      "train loss:0.005959987402020885\n",
      "train loss:0.0011287439866385167\n",
      "train loss:0.0018461154291896733\n",
      "train loss:0.0009517599153728969\n",
      "train loss:0.0022569522925287785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004015884932473592\n",
      "train loss:0.0018454778035657132\n",
      "train loss:0.000564421426836669\n",
      "train loss:0.00800893630820013\n",
      "train loss:0.006907967265512567\n",
      "train loss:0.00505492063577195\n",
      "train loss:0.007231542844018723\n",
      "train loss:0.008783837749926283\n",
      "train loss:0.0037186902638473573\n",
      "train loss:0.002130482206390754\n",
      "train loss:0.011264845447711207\n",
      "train loss:0.008862679839399345\n",
      "train loss:0.0008076579939239513\n",
      "train loss:0.0014918596120587497\n",
      "train loss:0.004937198089268412\n",
      "train loss:0.0010563085104716046\n",
      "train loss:0.0028529243759165823\n",
      "train loss:0.004533141212588739\n",
      "train loss:0.03711450493588975\n",
      "train loss:0.0034706398538350215\n",
      "train loss:0.004191124667704655\n",
      "train loss:0.0019626932440433803\n",
      "train loss:0.0006363206571788311\n",
      "train loss:0.0018203430430462275\n",
      "train loss:0.0035237087832224773\n",
      "train loss:0.0017241261079353892\n",
      "train loss:0.0021193374560590627\n",
      "train loss:0.004222353996978574\n",
      "train loss:0.001060243675662568\n",
      "train loss:0.00047130507871624537\n",
      "train loss:0.004000593710817207\n",
      "train loss:0.02360157625785242\n",
      "train loss:0.020972693207005205\n",
      "train loss:0.001442556674385631\n",
      "train loss:0.0021715006916896025\n",
      "train loss:0.011274226351712633\n",
      "train loss:0.001229125909927594\n",
      "train loss:0.003461071996947699\n",
      "train loss:0.001743191471388405\n",
      "train loss:0.0019881054804854756\n",
      "train loss:0.0027051046871651692\n",
      "train loss:0.009048675490957992\n",
      "train loss:0.01718410528548409\n",
      "train loss:0.012724018223231392\n",
      "train loss:0.020993652541836782\n",
      "train loss:0.0011517705321129963\n",
      "train loss:0.004198274104867786\n",
      "train loss:0.005631108498022109\n",
      "train loss:0.008857663720268326\n",
      "train loss:0.0057395889975282435\n",
      "train loss:0.0109948856993987\n",
      "train loss:0.0028750436716987533\n",
      "train loss:0.009210031612352393\n",
      "train loss:0.00985543126974236\n",
      "train loss:0.013469627107482805\n",
      "train loss:0.0010259801307318192\n",
      "train loss:0.005597233658491632\n",
      "train loss:0.001415390033915169\n",
      "train loss:0.03083218339393981\n",
      "train loss:0.028834648431218017\n",
      "train loss:0.007897431884480896\n",
      "train loss:0.009487933638519776\n",
      "train loss:0.006100726884626853\n",
      "train loss:0.008715990528818756\n",
      "train loss:0.0016317358146896702\n",
      "train loss:0.010649901522803103\n",
      "train loss:0.00285129173324387\n",
      "train loss:0.0039078592149658\n",
      "train loss:0.0010495217702366061\n",
      "train loss:0.001283342717568777\n",
      "train loss:0.0029329574703230053\n",
      "train loss:0.009134126399431482\n",
      "train loss:0.0007177258661358868\n",
      "train loss:0.008197627716865713\n",
      "train loss:0.0023102066862940047\n",
      "train loss:0.0036215684376761704\n",
      "train loss:0.0008684009803844868\n",
      "train loss:0.011561615826793232\n",
      "train loss:0.0030770721199149757\n",
      "train loss:0.0017011913412718059\n",
      "train loss:0.025671370590615812\n",
      "train loss:0.01260607302135163\n",
      "train loss:0.002044374922780475\n",
      "train loss:0.006378727958579435\n",
      "train loss:0.022047284759870417\n",
      "train loss:0.0012370402066200106\n",
      "train loss:0.0021712118952634347\n",
      "train loss:0.005714235538370554\n",
      "train loss:0.0012039612114603606\n",
      "train loss:0.014512992174292328\n",
      "train loss:0.000979209819543267\n",
      "train loss:0.01907209060171402\n",
      "train loss:0.009846837544300322\n",
      "train loss:0.0011856808114399848\n",
      "train loss:0.001343275825857578\n",
      "train loss:0.03515854254328818\n",
      "train loss:0.014462445372755473\n",
      "train loss:0.0031174602238613156\n",
      "train loss:0.0035386298627708853\n",
      "train loss:0.011958525548434249\n",
      "train loss:0.007480182614857848\n",
      "train loss:0.008998687380614403\n",
      "train loss:0.010204405291076935\n",
      "train loss:0.009134382541383114\n",
      "train loss:0.0016579227569797972\n",
      "train loss:0.0010282356851692488\n",
      "train loss:0.0018429526204642385\n",
      "train loss:0.004779258878229212\n",
      "train loss:0.0074799139955390274\n",
      "train loss:0.006929093870726839\n",
      "train loss:0.005101066350200556\n",
      "train loss:0.005472556818637791\n",
      "train loss:0.0033512738790586836\n",
      "train loss:0.012437092830025365\n",
      "train loss:0.0005160557196097242\n",
      "train loss:0.007986765007545062\n",
      "train loss:0.0033397888919808245\n",
      "train loss:0.004988958715650425\n",
      "train loss:0.00454151790566387\n",
      "train loss:0.00402303881832552\n",
      "train loss:0.0047881176312135265\n",
      "train loss:0.004922744731829386\n",
      "train loss:0.0015139636323392442\n",
      "train loss:0.009042062120904639\n",
      "train loss:0.002762549016531545\n",
      "train loss:0.003703592064255754\n",
      "train loss:0.0012124994826662764\n",
      "train loss:0.0003184308736550486\n",
      "train loss:0.008819041198101644\n",
      "train loss:0.026591088901901053\n",
      "train loss:0.008163087234126433\n",
      "train loss:0.0052771801679435985\n",
      "train loss:0.0011893838734558582\n",
      "train loss:0.0028947449904595975\n",
      "train loss:0.006624294688931493\n",
      "train loss:0.0253843275399256\n",
      "train loss:0.010379482511298782\n",
      "train loss:0.0017174054247057848\n",
      "train loss:0.004378473495262571\n",
      "train loss:0.0023786333797716917\n",
      "train loss:0.0008014527511528983\n",
      "train loss:0.0034180241316435463\n",
      "train loss:0.003230606407316132\n",
      "train loss:0.0013905318065792946\n",
      "train loss:0.015425856208716561\n",
      "train loss:0.01591234462676729\n",
      "train loss:0.01784297691087701\n",
      "train loss:0.001409157050585222\n",
      "train loss:0.010637709455450523\n",
      "train loss:0.004751994673533771\n",
      "train loss:0.0012869240720704935\n",
      "train loss:0.0019894134050120397\n",
      "train loss:0.0010406036131295547\n",
      "train loss:0.005075947960453393\n",
      "train loss:0.00371187737503064\n",
      "train loss:0.013908908573788315\n",
      "train loss:0.0034623826453703123\n",
      "train loss:0.0020951571115673958\n",
      "train loss:0.004941569302323984\n",
      "train loss:0.00350611263861221\n",
      "train loss:0.002172066120428321\n",
      "train loss:0.002929503944517063\n",
      "train loss:0.007071696445796385\n",
      "train loss:0.003573658700740187\n",
      "train loss:0.015406257793285036\n",
      "train loss:0.004730581638570843\n",
      "train loss:0.012553642090425737\n",
      "train loss:0.0027889311803932465\n",
      "train loss:0.0011613710502872115\n",
      "train loss:0.011474464415026829\n",
      "train loss:0.009228576805173073\n",
      "train loss:0.0020223650718839263\n",
      "train loss:0.00678805724180157\n",
      "train loss:0.0040601950229438985\n",
      "train loss:0.005764287637294623\n",
      "train loss:0.0017686410554788195\n",
      "train loss:0.009545108121956613\n",
      "train loss:0.0016882176742247811\n",
      "train loss:0.002178221332386148\n",
      "train loss:0.0016704933286091422\n",
      "train loss:0.003251237044710743\n",
      "train loss:0.005148545738341347\n",
      "train loss:0.02156776031497376\n",
      "train loss:0.00039004239052234645\n",
      "train loss:0.0011975482862334752\n",
      "train loss:0.006709076876894485\n",
      "train loss:0.0006029550397879199\n",
      "train loss:0.0026542090938023715\n",
      "train loss:0.002470937200242303\n",
      "train loss:0.00364320092155186\n",
      "train loss:0.00023798305674763588\n",
      "train loss:0.00045669381266859766\n",
      "train loss:0.018455619281262197\n",
      "train loss:0.002376937963059138\n",
      "train loss:0.010530564795156789\n",
      "train loss:0.0002451204570152799\n",
      "train loss:0.00014364523399940004\n",
      "train loss:0.00650492628527234\n",
      "train loss:0.0019645024002380796\n",
      "train loss:0.0021712966275973795\n",
      "train loss:0.08963515192958324\n",
      "train loss:0.0028314197791967067\n",
      "train loss:0.0016730566189521792\n",
      "train loss:0.0028783399742734273\n",
      "train loss:0.005970307919631549\n",
      "train loss:0.0014031209007281142\n",
      "train loss:0.0070705989822048175\n",
      "train loss:0.0035408957245390694\n",
      "train loss:0.01915583202127159\n",
      "train loss:0.0029726849851416633\n",
      "train loss:0.001333262234903481\n",
      "train loss:0.0026573821718799268\n",
      "train loss:0.0026900179234143735\n",
      "train loss:0.0011074529503225022\n",
      "train loss:0.007329337502901433\n",
      "train loss:0.01010736864489293\n",
      "train loss:0.002379043157898919\n",
      "train loss:0.0011322978878232114\n",
      "train loss:0.0031233776117957934\n",
      "train loss:0.0029882871562384784\n",
      "train loss:0.013492092706344383\n",
      "train loss:0.003773019547875329\n",
      "train loss:0.006140508110065369\n",
      "train loss:0.0041307423828125965\n",
      "train loss:0.008341620214683796\n",
      "train loss:0.001081845805777833\n",
      "train loss:0.013419953224158659\n",
      "train loss:0.001006506151375676\n",
      "train loss:0.003546301672539715\n",
      "train loss:0.0012016872451377973\n",
      "train loss:0.0023823686324750855\n",
      "train loss:0.009917127817424905\n",
      "train loss:0.005636580465616746\n",
      "train loss:0.011136266409196826\n",
      "train loss:0.014835518208449415\n",
      "train loss:0.0021663809559531923\n",
      "train loss:0.004309041900703719\n",
      "train loss:0.004101647555831039\n",
      "train loss:0.0025583635410772665\n",
      "train loss:0.005155868900060554\n",
      "train loss:0.00909676901211414\n",
      "train loss:0.001702615925429003\n",
      "train loss:0.006693537878084251\n",
      "train loss:0.003444641354827571\n",
      "train loss:0.0010031532572356697\n",
      "train loss:0.0014345897412410351\n",
      "train loss:0.00043799794472990095\n",
      "train loss:0.00251029909587563\n",
      "train loss:0.003166475912853866\n",
      "train loss:0.0021479770430773678\n",
      "train loss:0.003104526501112659\n",
      "train loss:0.006301914431938598\n",
      "train loss:0.002783681536442364\n",
      "train loss:0.0010705094694675203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.030276682695113542\n",
      "train loss:0.0036376122417969285\n",
      "train loss:0.002631982639978188\n",
      "train loss:0.011882532611338472\n",
      "train loss:0.0024617411310597524\n",
      "train loss:0.0019856672563914237\n",
      "train loss:0.006385645572343248\n",
      "train loss:0.0006591199423310684\n",
      "train loss:0.0037864530082946574\n",
      "train loss:0.002896057148828992\n",
      "train loss:0.003036552808584576\n",
      "train loss:0.01101636263739478\n",
      "train loss:0.0005349672435143635\n",
      "train loss:0.0018994468451549599\n",
      "train loss:0.0043168528678048\n",
      "train loss:0.007059351070776363\n",
      "train loss:0.0014173237165042254\n",
      "train loss:0.007969024864784187\n",
      "train loss:0.040180321292448154\n",
      "train loss:0.0014913631104828652\n",
      "train loss:0.009333723403251983\n",
      "train loss:0.012774310376408247\n",
      "train loss:0.004606711962909063\n",
      "train loss:0.0006001484334178352\n",
      "train loss:0.0013109511238399403\n",
      "train loss:0.011378502479856036\n",
      "train loss:0.0010937171741453853\n",
      "train loss:0.0033814338199028367\n",
      "train loss:0.0017678683018275349\n",
      "train loss:0.019848341041595344\n",
      "train loss:0.0005439681024310095\n",
      "train loss:0.02049852989726806\n",
      "train loss:0.003915420118659918\n",
      "train loss:0.0004570639590140782\n",
      "train loss:0.010213823359848223\n",
      "train loss:0.02027316815233167\n",
      "train loss:0.0028832883127442146\n",
      "train loss:0.003410449521954549\n",
      "train loss:0.007145384494845938\n",
      "train loss:0.002827912256705306\n",
      "train loss:0.011687967782950977\n",
      "train loss:0.0006023017733240744\n",
      "train loss:0.0006539969586056229\n",
      "train loss:0.0029608445471611716\n",
      "train loss:0.008171128566121623\n",
      "train loss:0.012597760858131586\n",
      "train loss:0.0010158891943441945\n",
      "train loss:0.022549898651039825\n",
      "train loss:0.0030559900894728594\n",
      "train loss:0.007809485154371557\n",
      "train loss:0.02101561112103983\n",
      "train loss:0.0032051075270844265\n",
      "train loss:0.0014426416548154629\n",
      "train loss:0.0005323897034885497\n",
      "train loss:0.004463913505496211\n",
      "train loss:0.0014023108799019154\n",
      "train loss:0.003132124418651722\n",
      "train loss:0.0014837233608504304\n",
      "train loss:0.0016513743337735112\n",
      "train loss:0.008045386978678236\n",
      "train loss:0.028926495085231232\n",
      "train loss:0.004008880580511678\n",
      "train loss:0.006985226246042311\n",
      "train loss:0.01065734291868986\n",
      "train loss:0.002502013697628613\n",
      "train loss:0.017413743330624395\n",
      "train loss:0.00629356927726301\n",
      "train loss:0.0005751347286031174\n",
      "train loss:0.03615374863636543\n",
      "train loss:0.0018721089059258518\n",
      "train loss:0.0006671503865193897\n",
      "train loss:0.004242662046040605\n",
      "train loss:0.016022608764548568\n",
      "train loss:0.004689425567396624\n",
      "train loss:0.0046019175229420044\n",
      "train loss:0.001552013120833338\n",
      "train loss:0.0033727840774277675\n",
      "train loss:0.0011450657847625215\n",
      "train loss:0.005819357142376005\n",
      "train loss:0.0047017766393621895\n",
      "train loss:0.0010956351334341073\n",
      "train loss:4.999509750161294e-05\n",
      "train loss:0.00650357976462875\n",
      "train loss:0.004527314072646949\n",
      "train loss:0.002011701370791243\n",
      "train loss:0.0022069107776924316\n",
      "train loss:0.0032323542619745855\n",
      "train loss:0.0007994391710209252\n",
      "train loss:0.002046875583055147\n",
      "train loss:0.0018120208503764764\n",
      "train loss:0.0009542238295457924\n",
      "train loss:0.0029410825120596657\n",
      "train loss:0.0022780820426201985\n",
      "train loss:0.0015830042043368116\n",
      "train loss:0.06127754260724086\n",
      "train loss:0.0012036501803191259\n",
      "train loss:0.0003576756882385639\n",
      "train loss:0.002736307312580314\n",
      "train loss:0.0006126956888415007\n",
      "train loss:0.0005182276308140673\n",
      "train loss:0.0009372784070029391\n",
      "train loss:0.04301756876654518\n",
      "train loss:0.0023125829894871676\n",
      "train loss:0.0003508114941924761\n",
      "train loss:0.006170080476343901\n",
      "train loss:0.0004735641632945711\n",
      "train loss:0.0006767926578667888\n",
      "train loss:0.0075729466466483205\n",
      "train loss:0.0023569754063475037\n",
      "train loss:0.0073648780539618906\n",
      "train loss:0.01565985612454337\n",
      "train loss:0.003698211802782724\n",
      "train loss:0.00266503204045483\n",
      "train loss:0.0006165143782323038\n",
      "train loss:0.0010684208814924765\n",
      "train loss:0.0013331714433430526\n",
      "train loss:0.00024240036060465476\n",
      "train loss:0.000431304093118826\n",
      "train loss:0.006277823482266687\n",
      "train loss:0.0009829788716516814\n",
      "train loss:0.0025556472865490526\n",
      "train loss:0.0038177338829272545\n",
      "train loss:0.0013803226981110683\n",
      "train loss:0.00041614466133699403\n",
      "train loss:0.001046160429075308\n",
      "train loss:0.0007032061975511869\n",
      "train loss:0.0011967398511490248\n",
      "train loss:0.002988467378338016\n",
      "train loss:0.007284091933055989\n",
      "train loss:0.0008122557197360078\n",
      "train loss:0.0029782626640532635\n",
      "train loss:0.00115668195346402\n",
      "train loss:0.007009298422071149\n",
      "train loss:0.002181785436260205\n",
      "train loss:0.005497129558294659\n",
      "train loss:0.0015197708957072186\n",
      "train loss:0.0036726402823064066\n",
      "train loss:0.0008647408729199132\n",
      "train loss:0.000583169327955662\n",
      "train loss:0.0013017935264469905\n",
      "train loss:0.0029432385247744343\n",
      "train loss:0.0016104888799508001\n",
      "train loss:0.0005645941723839903\n",
      "train loss:0.0031658015988310396\n",
      "train loss:0.005927609469102815\n",
      "train loss:0.0004065902435094803\n",
      "train loss:0.0019461861943295103\n",
      "train loss:0.00539344423813958\n",
      "train loss:0.001524640518762242\n",
      "train loss:0.0027888766318624673\n",
      "train loss:0.003895628994339425\n",
      "train loss:0.0030943951888278763\n",
      "train loss:0.0033539517523926876\n",
      "train loss:0.0007794313351785875\n",
      "train loss:0.0012600105201030802\n",
      "train loss:0.0006390859417907146\n",
      "train loss:0.0007471644573316442\n",
      "train loss:0.005702982041919239\n",
      "train loss:0.004509942794942084\n",
      "train loss:0.0036529023969991263\n",
      "train loss:0.006119446219597963\n",
      "train loss:0.006206178183043025\n",
      "train loss:0.0034657919486615675\n",
      "train loss:0.0016776023737303792\n",
      "train loss:0.0025850164003241465\n",
      "train loss:0.002483184501404396\n",
      "train loss:0.006091012232290494\n",
      "train loss:0.0010699890678665988\n",
      "train loss:0.001112190863101747\n",
      "train loss:0.0008486642649507696\n",
      "train loss:0.0036791993883305662\n",
      "train loss:0.001038245963367765\n",
      "train loss:0.005403759689572573\n",
      "train loss:0.008633980636274984\n",
      "train loss:0.0028020706347165214\n",
      "train loss:0.0010980209300342756\n",
      "train loss:0.001069432868441875\n",
      "train loss:0.002593664326751731\n",
      "train loss:0.00035992063762496483\n",
      "train loss:0.005269921007882702\n",
      "train loss:0.004783349824253957\n",
      "train loss:0.012350911961601036\n",
      "train loss:0.000774649269238745\n",
      "train loss:0.00042717221288450833\n",
      "train loss:0.004264844883951779\n",
      "train loss:0.0005564713965451847\n",
      "train loss:0.0021452268395948126\n",
      "train loss:0.0016316380578214845\n",
      "train loss:4.477425606185782e-05\n",
      "train loss:0.00030804577717101554\n",
      "train loss:0.0007814433583543168\n",
      "train loss:0.0013265651444981912\n",
      "train loss:0.005077523394250053\n",
      "train loss:0.051637938698200415\n",
      "train loss:0.002640950853485385\n",
      "train loss:0.00040640304468593877\n",
      "train loss:0.008895130425252524\n",
      "train loss:0.001235696964380414\n",
      "train loss:0.01491790471124315\n",
      "train loss:0.01307237393153256\n",
      "train loss:0.004388032804138411\n",
      "train loss:0.001437071625252701\n",
      "train loss:0.00825091811301213\n",
      "train loss:0.00189438220495035\n",
      "train loss:0.0012772014514917296\n",
      "train loss:0.00430984835185102\n",
      "train loss:0.0033336838575729545\n",
      "train loss:0.000972157656122442\n",
      "train loss:0.0069900407081229165\n",
      "train loss:0.004422162480162013\n",
      "train loss:0.0003771021067336502\n",
      "train loss:0.0018613280053472706\n",
      "train loss:0.0039052910407648984\n",
      "train loss:0.004078656599234947\n",
      "train loss:0.012720578801659044\n",
      "train loss:0.006870154612352062\n",
      "train loss:0.0002810676488308693\n",
      "train loss:0.0029802302365152826\n",
      "train loss:0.00025360924111771555\n",
      "train loss:0.0022130728441834306\n",
      "train loss:0.0031319071778727688\n",
      "train loss:0.00563434812604605\n",
      "train loss:0.00029529727626534163\n",
      "train loss:0.00034521503558958906\n",
      "train loss:0.004180296984115963\n",
      "train loss:0.003828837840264801\n",
      "train loss:0.003851887750519178\n",
      "train loss:0.0016997363251180853\n",
      "train loss:0.0017167556365554426\n",
      "train loss:0.04901720911807908\n",
      "train loss:0.0017428380962719128\n",
      "train loss:0.0015464611506540052\n",
      "train loss:0.00633284056065315\n",
      "train loss:0.005547230307622254\n",
      "train loss:0.0034395677081423136\n",
      "train loss:0.003589145063198539\n",
      "train loss:0.000764311591260285\n",
      "train loss:0.002921008748857273\n",
      "train loss:0.0021269718216142364\n",
      "train loss:0.0028318017876141316\n",
      "train loss:0.005523684073083977\n",
      "train loss:0.002452669571081689\n",
      "train loss:0.0009960736611256584\n",
      "train loss:0.0015165117530994224\n",
      "train loss:0.006615028661062582\n",
      "train loss:0.002949374675472976\n",
      "train loss:0.014926310516603203\n",
      "train loss:0.014187381703834222\n",
      "train loss:0.001278733384256857\n",
      "train loss:0.0003437827910270554\n",
      "train loss:0.005096985469367018\n",
      "train loss:0.004612004296951597\n",
      "train loss:0.0029077375711183207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004343165245890759\n",
      "train loss:0.006619441140095899\n",
      "train loss:0.005815144914892822\n",
      "train loss:0.0017144949646598238\n",
      "train loss:0.0024108345993878043\n",
      "train loss:0.0027065023994277885\n",
      "train loss:0.0063465588186548206\n",
      "train loss:0.024967694073060903\n",
      "train loss:0.0011281699827755337\n",
      "train loss:0.009629722657337296\n",
      "train loss:0.0034320997014472302\n",
      "train loss:0.002918979621943729\n",
      "train loss:0.0025187181082929116\n",
      "train loss:0.0039369599479007625\n",
      "train loss:0.002140322082589664\n",
      "train loss:0.003514741152634769\n",
      "train loss:0.005932938671472356\n",
      "train loss:0.0005000844011048353\n",
      "train loss:0.0004973253248299816\n",
      "train loss:0.004471897659632084\n",
      "train loss:0.00041443773655575034\n",
      "train loss:0.0008555112407481497\n",
      "train loss:0.009503313004527196\n",
      "train loss:0.0004990114032046987\n",
      "train loss:0.006596799103582477\n",
      "train loss:0.0009754772269054456\n",
      "train loss:0.014870365010647089\n",
      "train loss:0.0069586895762583836\n",
      "train loss:0.008143804759267662\n",
      "train loss:0.004270399534490919\n",
      "train loss:0.00020992828721861132\n",
      "train loss:0.003912676096036861\n",
      "train loss:0.0023763112934040804\n",
      "train loss:0.0022805825144390736\n",
      "train loss:0.0006857564702675216\n",
      "train loss:0.0002939777981309484\n",
      "train loss:0.0065926036796033986\n",
      "train loss:0.003261585783085155\n",
      "train loss:0.02022295601770241\n",
      "=== epoch:14, train acc:0.995, test acc:0.982 ===\n",
      "train loss:0.0002910832928917817\n",
      "train loss:0.0017231152891334063\n",
      "train loss:0.003321237774888539\n",
      "train loss:0.0022190971975802128\n",
      "train loss:0.007771715102055157\n",
      "train loss:0.0010734350550617208\n",
      "train loss:0.0006041829251066753\n",
      "train loss:0.008830982101558048\n",
      "train loss:0.006910392311516167\n",
      "train loss:0.0158078522531534\n",
      "train loss:0.004585457083306146\n",
      "train loss:0.0013540204379630218\n",
      "train loss:0.001669566460647723\n",
      "train loss:0.0038540239449903935\n",
      "train loss:0.0050052022759239576\n",
      "train loss:0.0016218363561219808\n",
      "train loss:0.0018383186514532846\n",
      "train loss:0.0010130808743820453\n",
      "train loss:0.002080443959303402\n",
      "train loss:0.005548427280995535\n",
      "train loss:0.00976706486893637\n",
      "train loss:0.002339548830181085\n",
      "train loss:0.006682691542206464\n",
      "train loss:0.009370593589814215\n",
      "train loss:0.004532804643283037\n",
      "train loss:0.00019327239171973762\n",
      "train loss:0.009350843742389914\n",
      "train loss:0.0022507652901037536\n",
      "train loss:0.0005244874378149932\n",
      "train loss:0.00515995587011449\n",
      "train loss:0.0011939295054201348\n",
      "train loss:0.0038764369871126876\n",
      "train loss:0.00199488901499154\n",
      "train loss:0.003257788113267326\n",
      "train loss:0.0005805579061751303\n",
      "train loss:0.004643024943651366\n",
      "train loss:0.001390961637397257\n",
      "train loss:0.000746189412762737\n",
      "train loss:0.003913428670964872\n",
      "train loss:0.010225274121587096\n",
      "train loss:0.0011349513085691667\n",
      "train loss:0.006319480580608723\n",
      "train loss:0.03696559749729635\n",
      "train loss:0.004287613353770359\n",
      "train loss:0.004777858342421679\n",
      "train loss:0.0023969860668434646\n",
      "train loss:0.004466145022004622\n",
      "train loss:0.0030028793824192416\n",
      "train loss:0.0010108043083074468\n",
      "train loss:0.0027693047954300736\n",
      "train loss:0.001029522639468185\n",
      "train loss:0.01044910485224451\n",
      "train loss:0.039686377977089925\n",
      "train loss:0.005233979318298316\n",
      "train loss:0.004638756572121667\n",
      "train loss:0.01047224685701425\n",
      "train loss:0.0009147944953778854\n",
      "train loss:0.007340955924379106\n",
      "train loss:0.003181201096656826\n",
      "train loss:0.004917868029812681\n",
      "train loss:0.026955446929783324\n",
      "train loss:0.0009376668954981025\n",
      "train loss:0.002901191239712419\n",
      "train loss:0.0025894612332230966\n",
      "train loss:0.0049355905937502635\n",
      "train loss:0.001619816097324501\n",
      "train loss:0.004202684597273274\n",
      "train loss:0.002599889376019345\n",
      "train loss:0.0015652747323084929\n",
      "train loss:0.002899906798857301\n",
      "train loss:0.0005533538675469419\n",
      "train loss:0.005472201926820925\n",
      "train loss:0.0021339812819009332\n",
      "train loss:0.034466491909488965\n",
      "train loss:0.0008821011287942365\n",
      "train loss:0.002038611923065506\n",
      "train loss:0.0009725068917095122\n",
      "train loss:0.0015941185144944777\n",
      "train loss:0.0006249458777513859\n",
      "train loss:0.0038668687432942372\n",
      "train loss:0.002207692416352478\n",
      "train loss:0.003581173362888196\n",
      "train loss:0.004979419698341797\n",
      "train loss:0.01266579314992521\n",
      "train loss:0.005393241705199888\n",
      "train loss:0.0034426995379535958\n",
      "train loss:0.0005441905970462723\n",
      "train loss:0.00044317495120343027\n",
      "train loss:0.006415139720791523\n",
      "train loss:0.00550629143978635\n",
      "train loss:0.0023722017216785828\n",
      "train loss:0.007777275854296011\n",
      "train loss:0.0027509724295501237\n",
      "train loss:0.002606836996867421\n",
      "train loss:0.000925963650946281\n",
      "train loss:0.0006133308442821116\n",
      "train loss:0.0008896215146039582\n",
      "train loss:0.0035815276002542917\n",
      "train loss:0.028586052167227965\n",
      "train loss:0.0007345525351443587\n",
      "train loss:0.007407402661792736\n",
      "train loss:0.0003881314712243605\n",
      "train loss:0.0007783239988999813\n",
      "train loss:0.003521525286799845\n",
      "train loss:0.0022041694301788805\n",
      "train loss:0.003275487154128473\n",
      "train loss:0.003647252520252846\n",
      "train loss:0.014233466955946175\n",
      "train loss:0.0005161676216968855\n",
      "train loss:0.01016418487781149\n",
      "train loss:0.0022585063822508572\n",
      "train loss:0.0007352575538758072\n",
      "train loss:0.004500270518682555\n",
      "train loss:0.0032166188856537882\n",
      "train loss:6.231056773835309e-05\n",
      "train loss:0.0032088135635872615\n",
      "train loss:0.004993853498039387\n",
      "train loss:0.0006263066341666819\n",
      "train loss:0.002611751008043133\n",
      "train loss:0.0013047772597197182\n",
      "train loss:0.0038289340666226783\n",
      "train loss:0.0006138072749653407\n",
      "train loss:0.002549070296742341\n",
      "train loss:0.011068911877562728\n",
      "train loss:0.0018976968518815717\n",
      "train loss:0.010568563889787115\n",
      "train loss:0.004402780169906446\n",
      "train loss:0.0069782146785241726\n",
      "train loss:0.01628396982527305\n",
      "train loss:0.0010064836904357271\n",
      "train loss:0.004625643863357885\n",
      "train loss:0.004823605092871456\n",
      "train loss:0.010483342791504167\n",
      "train loss:0.0018476739215629787\n",
      "train loss:0.005244804620499723\n",
      "train loss:0.015133403911468047\n",
      "train loss:0.0011356875398313732\n",
      "train loss:0.001959558265028687\n",
      "train loss:0.007503822826472278\n",
      "train loss:0.0007515121352896604\n",
      "train loss:0.003029427300576616\n",
      "train loss:0.015632986506235763\n",
      "train loss:0.0010496295732803044\n",
      "train loss:0.0010068036023069137\n",
      "train loss:0.0016658518528904962\n",
      "train loss:0.000684685017027706\n",
      "train loss:0.0011004147375641403\n",
      "train loss:0.01178517296019038\n",
      "train loss:0.0035088809309846126\n",
      "train loss:0.0015425298877356634\n",
      "train loss:0.0013556491149944332\n",
      "train loss:0.0003804207579214448\n",
      "train loss:0.012564856047346229\n",
      "train loss:0.0015094863964121269\n",
      "train loss:0.0003386703315372416\n",
      "train loss:0.004754793216337248\n",
      "train loss:0.0033642611608962654\n",
      "train loss:0.0005023871223425554\n",
      "train loss:0.0017174478288563\n",
      "train loss:0.0008329140658212623\n",
      "train loss:0.0018880650347137457\n",
      "train loss:0.009064142653324706\n",
      "train loss:0.0007364935346890699\n",
      "train loss:0.0019609822554698076\n",
      "train loss:0.007064184197424975\n",
      "train loss:0.0020762715782568918\n",
      "train loss:0.004666340449929826\n",
      "train loss:0.0011443524491830356\n",
      "train loss:0.0012303945196811433\n",
      "train loss:0.0018439957967249637\n",
      "train loss:0.010375741482800087\n",
      "train loss:0.017442627633480326\n",
      "train loss:0.0035501165764885473\n",
      "train loss:0.0023124454393384218\n",
      "train loss:0.005231528836794948\n",
      "train loss:0.01100806485115747\n",
      "train loss:0.0034047246143512964\n",
      "train loss:0.0007200253381305788\n",
      "train loss:0.011424900543797243\n",
      "train loss:0.00642479875388865\n",
      "train loss:0.0009885972384635056\n",
      "train loss:0.004946617036051349\n",
      "train loss:0.0005732458157260551\n",
      "train loss:0.0007381203118155514\n",
      "train loss:0.0016837686877286798\n",
      "train loss:0.0029776966536621103\n",
      "train loss:0.0005937777650781187\n",
      "train loss:0.0029292458747229673\n",
      "train loss:0.001100755777752875\n",
      "train loss:0.0025063314287586485\n",
      "train loss:0.00309908463519951\n",
      "train loss:0.002715353228291328\n",
      "train loss:0.001053605122281538\n",
      "train loss:0.0006256622048055163\n",
      "train loss:0.0014041010363836312\n",
      "train loss:0.004721385147388416\n",
      "train loss:0.00016721466925233855\n",
      "train loss:0.0028966346541680617\n",
      "train loss:0.0008184964606049188\n",
      "train loss:0.0017843386612484621\n",
      "train loss:0.0001744850491587166\n",
      "train loss:0.0024840463540855818\n",
      "train loss:0.001505837738544113\n",
      "train loss:0.006274468974865421\n",
      "train loss:0.005929554730757604\n",
      "train loss:0.0026964731357155126\n",
      "train loss:0.010613365789228429\n",
      "train loss:0.009170435817827092\n",
      "train loss:0.0016480365387392365\n",
      "train loss:0.0014104924126197237\n",
      "train loss:0.0015333227681730989\n",
      "train loss:0.0005472085990312782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005858991003229377\n",
      "train loss:0.0018562330100527103\n",
      "train loss:0.006293511776371968\n",
      "train loss:0.002541322884891761\n",
      "train loss:0.008306076380194172\n",
      "train loss:0.010069198249424156\n",
      "train loss:0.002133746329885948\n",
      "train loss:0.0013230224322989118\n",
      "train loss:0.007543745107585295\n",
      "train loss:0.017562619344044583\n",
      "train loss:0.00041571735445448314\n",
      "train loss:0.0012752855535586392\n",
      "train loss:0.0031402772679676883\n",
      "train loss:0.0009694264517576244\n",
      "train loss:0.007577599208123735\n",
      "train loss:0.006279635092569794\n",
      "train loss:0.0027302003972875894\n",
      "train loss:0.004544974577951917\n",
      "train loss:0.001219567742681657\n",
      "train loss:0.009454579737089526\n",
      "train loss:0.0006477348436456728\n",
      "train loss:0.00202148587144624\n",
      "train loss:0.0028852702511612837\n",
      "train loss:0.0012966539666398266\n",
      "train loss:0.003887955950093723\n",
      "train loss:0.001641387958828277\n",
      "train loss:0.005995327171637028\n",
      "train loss:0.0032173904468700888\n",
      "train loss:0.0002537984582801003\n",
      "train loss:0.005142977767254405\n",
      "train loss:0.0020412075437476877\n",
      "train loss:0.013427290172586396\n",
      "train loss:0.014423451331718627\n",
      "train loss:0.00014321274094739346\n",
      "train loss:0.0033727414302282457\n",
      "train loss:0.0003968717448130582\n",
      "train loss:0.000252360953815338\n",
      "train loss:0.0015480388166461384\n",
      "train loss:0.004980212684320018\n",
      "train loss:0.0007241203743412971\n",
      "train loss:0.0028537338318893163\n",
      "train loss:0.0017012979748125385\n",
      "train loss:0.0024452660799897\n",
      "train loss:0.0013142353384770393\n",
      "train loss:0.009623102031764112\n",
      "train loss:0.00444630709114387\n",
      "train loss:0.011104204070597116\n",
      "train loss:0.006408335352505873\n",
      "train loss:0.010790679114489308\n",
      "train loss:0.0036940597720697046\n",
      "train loss:0.00022040960942545113\n",
      "train loss:0.0005373610258522164\n",
      "train loss:0.0019545671916716164\n",
      "train loss:0.0020534657920839184\n",
      "train loss:0.0019790394575251264\n",
      "train loss:0.0008192153162732273\n",
      "train loss:0.00017269713548788475\n",
      "train loss:0.005632078248881056\n",
      "train loss:0.0031421157712527487\n",
      "train loss:0.005129713469089911\n",
      "train loss:0.0007945058469873274\n",
      "train loss:0.0009534000145859242\n",
      "train loss:0.0005238666076919521\n",
      "train loss:0.00432162427488144\n",
      "train loss:0.0032263127252144213\n",
      "train loss:0.008099041862110782\n",
      "train loss:0.0022146472642465263\n",
      "train loss:0.001120138198658527\n",
      "train loss:0.0029452649549237936\n",
      "train loss:0.006350676579783876\n",
      "train loss:0.0026376858332859887\n",
      "train loss:0.0034938434824516246\n",
      "train loss:0.000596557296799193\n",
      "train loss:0.00035802988486771886\n",
      "train loss:0.0015646160287002178\n",
      "train loss:0.0010691561088142592\n",
      "train loss:0.0035048332125036112\n",
      "train loss:0.001838669601926277\n",
      "train loss:0.0025244836993317714\n",
      "train loss:0.002298988325527935\n",
      "train loss:0.004148034514979746\n",
      "train loss:0.0017200707599000977\n",
      "train loss:0.002239711200166494\n",
      "train loss:0.002111678853891091\n",
      "train loss:0.00047657890946031393\n",
      "train loss:0.0764331769617601\n",
      "train loss:0.01010682813885762\n",
      "train loss:0.004570140066060004\n",
      "train loss:0.005970558466757801\n",
      "train loss:0.002015720290013685\n",
      "train loss:0.0018692144621955218\n",
      "train loss:0.00492052438755023\n",
      "train loss:0.0003783213457260276\n",
      "train loss:0.002673838227603773\n",
      "train loss:0.004275176169894147\n",
      "train loss:0.0053671885841928635\n",
      "train loss:0.005764789990485095\n",
      "train loss:0.0010403295851768885\n",
      "train loss:0.003890672524908569\n",
      "train loss:0.0015744272014529056\n",
      "train loss:0.00841135089178047\n",
      "train loss:0.004662215325443229\n",
      "train loss:0.001499026574182036\n",
      "train loss:8.369694522263175e-05\n",
      "train loss:0.0006141698179742981\n",
      "train loss:0.0010227390688852186\n",
      "train loss:0.0015777587678772282\n",
      "train loss:0.004394610195829842\n",
      "train loss:5.2585881596975474e-05\n",
      "train loss:0.0013368121823492517\n",
      "train loss:0.0035293716548692655\n",
      "train loss:0.001194249818553191\n",
      "train loss:0.0002139821355007042\n",
      "train loss:0.0424063056568986\n",
      "train loss:0.0020357336862559584\n",
      "train loss:0.003599947911767027\n",
      "train loss:0.0004218396705036712\n",
      "train loss:0.006007400581904358\n",
      "train loss:0.0015324971209613558\n",
      "train loss:0.0012117475464685642\n",
      "train loss:0.001966286133346473\n",
      "train loss:0.005826513059297457\n",
      "train loss:0.0004567845553502641\n",
      "train loss:0.0003767821463465973\n",
      "train loss:0.0031872774175916753\n",
      "train loss:0.0026911329285825825\n",
      "train loss:0.008720178876006526\n",
      "train loss:0.003453640869994892\n",
      "train loss:0.007785875924392078\n",
      "train loss:0.005273115690546551\n",
      "train loss:0.0030704205723848443\n",
      "train loss:0.0007248894764254267\n",
      "train loss:0.0012995122596811124\n",
      "train loss:0.00013782627145495055\n",
      "train loss:0.0005329208787581162\n",
      "train loss:0.0006397978911533451\n",
      "train loss:0.00030751691953917194\n",
      "train loss:0.0004693715887930014\n",
      "train loss:0.005670000684459687\n",
      "train loss:0.0012405671492245886\n",
      "train loss:0.0004412788985038893\n",
      "train loss:0.0002772259514146339\n",
      "train loss:0.002854965678548831\n",
      "train loss:9.030440902043918e-05\n",
      "train loss:0.0017841087816178574\n",
      "train loss:0.016589815129955676\n",
      "train loss:0.0002531271965712819\n",
      "train loss:0.0018221742677608274\n",
      "train loss:8.16104478082744e-05\n",
      "train loss:0.01095329222983805\n",
      "train loss:0.00145650755420675\n",
      "train loss:0.004884504750113074\n",
      "train loss:0.0006980009600559126\n",
      "train loss:0.0053750439154417965\n",
      "train loss:0.002597756309128012\n",
      "train loss:0.010291262070856965\n",
      "train loss:0.007828094718193259\n",
      "train loss:0.0013790548946873693\n",
      "train loss:0.007896899542939033\n",
      "train loss:0.021578938405145486\n",
      "train loss:0.0017619702592590139\n",
      "train loss:0.00042653115165451806\n",
      "train loss:0.004687183145427504\n",
      "train loss:0.0004156774318015769\n",
      "train loss:0.0044818512006504175\n",
      "train loss:0.011627739951334759\n",
      "train loss:0.00022371422974613034\n",
      "train loss:0.0012922425442038336\n",
      "train loss:0.002299470973996568\n",
      "train loss:0.020028167801992763\n",
      "train loss:0.0011673802654200635\n",
      "train loss:0.0017006138599635111\n",
      "train loss:0.0011500576301014364\n",
      "train loss:0.0020562417556699466\n",
      "train loss:0.0030308448134471287\n",
      "train loss:0.02990892430156649\n",
      "train loss:0.0030117429613664543\n",
      "train loss:0.0027021954265805674\n",
      "train loss:0.00042611681237626054\n",
      "train loss:0.004673404356508072\n",
      "train loss:0.022192073179261747\n",
      "train loss:0.004508656791440459\n",
      "train loss:0.05341219228195596\n",
      "train loss:0.0005629484171221688\n",
      "train loss:0.0018229818741495568\n",
      "train loss:0.0017969577378214845\n",
      "train loss:0.004132501313347443\n",
      "train loss:0.0050544111191875496\n",
      "train loss:0.0030091496232945254\n",
      "train loss:0.0025051357041902707\n",
      "train loss:0.003877761392309791\n",
      "train loss:0.05700510880402805\n",
      "train loss:0.06214800772026011\n",
      "train loss:0.005308637809815427\n",
      "train loss:0.004257971492786953\n",
      "train loss:0.018911311102110258\n",
      "train loss:0.0024696992952354803\n",
      "train loss:0.0007828168318784642\n",
      "train loss:0.0031220227568614215\n",
      "train loss:0.010880293793695126\n",
      "train loss:0.016914956056416935\n",
      "train loss:0.004641912629834775\n",
      "train loss:0.0007299571007446202\n",
      "train loss:0.0188642717670375\n",
      "train loss:0.011039508178291434\n",
      "train loss:0.0011863027106957867\n",
      "train loss:0.0019374073790501343\n",
      "train loss:0.0016861706450119953\n",
      "train loss:0.00805077637899839\n",
      "train loss:0.005032586530135232\n",
      "train loss:0.0036204519874932055\n",
      "train loss:0.010667522233252583\n",
      "train loss:0.012089351644557806\n",
      "train loss:0.005361916946574883\n",
      "train loss:0.0016906906958258194\n",
      "train loss:0.0017975189065553162\n",
      "train loss:0.004986405446887523\n",
      "train loss:0.033106741739966944\n",
      "train loss:0.003739757963317219\n",
      "train loss:0.0012960973305996737\n",
      "train loss:0.0033820340908389084\n",
      "train loss:0.0006548166264583548\n",
      "train loss:0.0006815576513486757\n",
      "train loss:0.0004054192491818427\n",
      "train loss:0.00414759760739973\n",
      "train loss:0.005381783826726817\n",
      "train loss:0.002168592693630171\n",
      "train loss:0.003195401495735545\n",
      "train loss:0.0017849024643449758\n",
      "train loss:0.0012862032487113806\n",
      "train loss:0.0008502847108483377\n",
      "train loss:0.004017231851251911\n",
      "train loss:0.003991056965735428\n",
      "train loss:0.005334355610506638\n",
      "train loss:0.001009888731690996\n",
      "train loss:0.004198239004555784\n",
      "train loss:0.008284401295639076\n",
      "train loss:0.001040351827661814\n",
      "train loss:0.0017079184947755924\n",
      "train loss:0.0029695830204883988\n",
      "train loss:0.002475968038129485\n",
      "train loss:0.0157696532305676\n",
      "train loss:0.0006217513727019721\n",
      "train loss:0.0013848524035535597\n",
      "train loss:0.0009532677413054355\n",
      "train loss:0.0057185918014097505\n",
      "train loss:0.004736446209534971\n",
      "train loss:0.0025484457376035107\n",
      "train loss:0.0015069284604463252\n",
      "train loss:0.002164077070853578\n",
      "train loss:0.00724795458173833\n",
      "train loss:0.009298754419574435\n",
      "train loss:0.029467237390772887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008232123117612115\n",
      "train loss:0.0038040761016044002\n",
      "train loss:0.00027505983646442905\n",
      "train loss:0.0002750261291237159\n",
      "train loss:0.0010756544663791175\n",
      "train loss:0.0009606386663075689\n",
      "train loss:0.0011374194676244018\n",
      "train loss:0.000667622870731142\n",
      "train loss:0.005256340535035628\n",
      "train loss:0.021554714326338365\n",
      "train loss:0.02430350851775544\n",
      "train loss:0.00124825099745665\n",
      "train loss:0.0013122676843953848\n",
      "train loss:0.0027925795923065986\n",
      "train loss:0.004590275271832275\n",
      "train loss:0.0068291605383315355\n",
      "train loss:0.014454499357680837\n",
      "train loss:0.004831567596311419\n",
      "train loss:0.002925215421156678\n",
      "train loss:0.0028822089876277073\n",
      "train loss:0.0006612770410832563\n",
      "train loss:0.006552565982370294\n",
      "train loss:0.00912414937495931\n",
      "train loss:0.0011014460283223961\n",
      "train loss:0.004079801834121326\n",
      "train loss:0.004911962339047724\n",
      "train loss:0.001206782318078993\n",
      "train loss:0.00030562981154869855\n",
      "train loss:0.0047169281514847635\n",
      "train loss:0.0010274248358057335\n",
      "train loss:0.0017103893423250755\n",
      "train loss:0.0012200174614488176\n",
      "train loss:0.009680149950323666\n",
      "train loss:0.004079260884294778\n",
      "train loss:0.0012921258086622952\n",
      "train loss:0.0009458660148699122\n",
      "train loss:0.00015402979375122338\n",
      "train loss:0.01372938042319928\n",
      "train loss:0.0019158794784248764\n",
      "train loss:0.00244568089083969\n",
      "train loss:0.0005425554959765769\n",
      "train loss:0.0015179225218434759\n",
      "train loss:0.0006849315861275355\n",
      "train loss:0.0033699106083133258\n",
      "train loss:0.005426978283718492\n",
      "train loss:0.00029746766023305816\n",
      "train loss:0.0009968182474979221\n",
      "train loss:0.002339936293959333\n",
      "train loss:0.0048423464731479435\n",
      "train loss:0.0011771917109088925\n",
      "train loss:0.0006126475049592038\n",
      "train loss:0.012798638742174087\n",
      "train loss:0.003960616643609758\n",
      "train loss:0.0017900147776288287\n",
      "train loss:0.00021626789916001857\n",
      "train loss:0.0004027059935585402\n",
      "train loss:0.0019768653903420026\n",
      "train loss:0.006655457567155215\n",
      "train loss:0.0005879372647419375\n",
      "train loss:0.03650902766376787\n",
      "train loss:0.0010763792388915811\n",
      "train loss:0.004195468764580182\n",
      "train loss:0.0015281927583092189\n",
      "train loss:0.008647803186785402\n",
      "train loss:0.005633281482716289\n",
      "train loss:0.00031455100416226704\n",
      "train loss:0.014109608639529687\n",
      "train loss:0.011878187918184563\n",
      "train loss:0.005128474725164235\n",
      "train loss:0.0008924056579005249\n",
      "train loss:0.0016384228482277721\n",
      "train loss:0.0010071489899923303\n",
      "train loss:0.0007992025061129087\n",
      "train loss:0.001584858792395078\n",
      "train loss:0.0010812922958038749\n",
      "train loss:0.0019751470756959825\n",
      "train loss:0.004671637230103357\n",
      "train loss:0.0027159213363172246\n",
      "train loss:0.0007720993175666374\n",
      "train loss:0.0015842060653628678\n",
      "train loss:0.0012837545849252055\n",
      "train loss:0.0005459950048783885\n",
      "train loss:0.004513475546630013\n",
      "train loss:0.0010491588455426378\n",
      "train loss:0.006984693571105887\n",
      "train loss:0.007090625362379608\n",
      "train loss:0.0017923593295270162\n",
      "train loss:0.0018548879045852805\n",
      "train loss:0.0036925414251314554\n",
      "train loss:0.012889954493050226\n",
      "train loss:0.00760980658247208\n",
      "train loss:0.018443527999800872\n",
      "train loss:0.001619234054931256\n",
      "train loss:0.007737192874437787\n",
      "train loss:0.0020451218274574767\n",
      "train loss:0.004207396904447316\n",
      "train loss:0.0013316288691108222\n",
      "train loss:0.003603140620329468\n",
      "train loss:0.002988847880455663\n",
      "train loss:0.001510963663454673\n",
      "train loss:0.0026006972361983243\n",
      "train loss:0.0005049633068214281\n",
      "train loss:0.007830711507867589\n",
      "train loss:0.00027299405900653423\n",
      "train loss:0.001186473631257829\n",
      "train loss:0.0018711195530942257\n",
      "train loss:0.0007079033649132842\n",
      "train loss:0.0005283380961044425\n",
      "train loss:0.010475925749258938\n",
      "train loss:0.0022518313456097137\n",
      "train loss:0.015388272758028192\n",
      "train loss:0.0008003883123395185\n",
      "train loss:0.000513150439924069\n",
      "train loss:0.002369346848639847\n",
      "train loss:0.0009834304922101999\n",
      "train loss:0.0044273395441826666\n",
      "train loss:0.0006548021360932478\n",
      "train loss:0.00013678602295908246\n",
      "train loss:0.002753680396095311\n",
      "train loss:0.008655484279811575\n",
      "train loss:0.005618850429138449\n",
      "train loss:0.006172906182973372\n",
      "train loss:0.0022731092789177736\n",
      "train loss:0.0015886777260159443\n",
      "train loss:0.002803761551008037\n",
      "train loss:0.005196842180636038\n",
      "train loss:0.0005758141546714883\n",
      "train loss:0.00044997711207045774\n",
      "train loss:0.000905141786485139\n",
      "train loss:0.0038176731246184685\n",
      "train loss:0.0038333833216833203\n",
      "train loss:0.004095655190809383\n",
      "train loss:0.0018911721025713871\n",
      "train loss:0.0027069146091507667\n",
      "train loss:0.005334384982781016\n",
      "=== epoch:15, train acc:0.995, test acc:0.987 ===\n",
      "train loss:0.0013749324164411079\n",
      "train loss:0.007296848332918534\n",
      "train loss:0.0022965727851122462\n",
      "train loss:0.005164033257319143\n",
      "train loss:0.0017645767090750707\n",
      "train loss:0.0004512976776866512\n",
      "train loss:0.0007111124864538164\n",
      "train loss:0.001592105713957441\n",
      "train loss:0.0011430795814296316\n",
      "train loss:0.00029433683442573323\n",
      "train loss:8.583254922278119e-05\n",
      "train loss:0.0006118962798002171\n",
      "train loss:0.0006729797375593715\n",
      "train loss:0.0024949930297222516\n",
      "train loss:0.00028385147078914476\n",
      "train loss:0.0004450998919580649\n",
      "train loss:0.0019259939339954704\n",
      "train loss:0.00696825556480727\n",
      "train loss:0.00036622612120728486\n",
      "train loss:0.017603740105149476\n",
      "train loss:0.00022051854492802277\n",
      "train loss:0.0015422266787101693\n",
      "train loss:0.0014235044075824718\n",
      "train loss:0.0013665760255114111\n",
      "train loss:0.0029272290875394773\n",
      "train loss:0.002025847194649938\n",
      "train loss:0.0020762175253804175\n",
      "train loss:0.0006604192192222028\n",
      "train loss:0.0013625480015492374\n",
      "train loss:0.0009538192577289159\n",
      "train loss:0.004725518932772548\n",
      "train loss:0.0021968598918529203\n",
      "train loss:0.005467638207893359\n",
      "train loss:0.0011168444063476381\n",
      "train loss:0.0010593235731720676\n",
      "train loss:0.0024865990930633634\n",
      "train loss:0.008524445174854988\n",
      "train loss:0.0005000434780446437\n",
      "train loss:0.0021037872060673014\n",
      "train loss:0.0006050048665652574\n",
      "train loss:0.0011704008801349975\n",
      "train loss:0.0010518014077201684\n",
      "train loss:0.0015645021944481038\n",
      "train loss:0.0016517551605468059\n",
      "train loss:0.0013337185265247728\n",
      "train loss:0.0013609864139469405\n",
      "train loss:0.0057802395822191014\n",
      "train loss:0.000205956522992077\n",
      "train loss:0.0015448912764716655\n",
      "train loss:0.009750367078636895\n",
      "train loss:0.0004847019332215358\n",
      "train loss:0.0030264403219002994\n",
      "train loss:0.019360881904303465\n",
      "train loss:0.0007753727965985558\n",
      "train loss:0.0008445448101192535\n",
      "train loss:0.0014116163403634805\n",
      "train loss:0.005224967369203082\n",
      "train loss:0.00023500289234675348\n",
      "train loss:0.0027685431434853035\n",
      "train loss:0.0036510332060635062\n",
      "train loss:0.0004725938568548551\n",
      "train loss:0.0017614363879032593\n",
      "train loss:0.0014246267418128447\n",
      "train loss:0.00617150836676424\n",
      "train loss:0.001063888062088877\n",
      "train loss:0.0018248110938091327\n",
      "train loss:0.0008999809287155461\n",
      "train loss:0.0016882105813517858\n",
      "train loss:0.0015588074013838842\n",
      "train loss:0.000539127326622405\n",
      "train loss:0.025028053569086387\n",
      "train loss:0.0008439422345888356\n",
      "train loss:0.002028087971096291\n",
      "train loss:0.0004893247195874848\n",
      "train loss:0.0008584904664698815\n",
      "train loss:0.0016270848433711832\n",
      "train loss:0.009423336585421122\n",
      "train loss:0.00030670767002131147\n",
      "train loss:0.004403318183384375\n",
      "train loss:0.0016094048684223187\n",
      "train loss:0.0006856392711402605\n",
      "train loss:0.0013724778379158586\n",
      "train loss:0.005782088726931911\n",
      "train loss:0.00418807305399157\n",
      "train loss:0.0013994836310672045\n",
      "train loss:0.008086839078623186\n",
      "train loss:0.000849140031334108\n",
      "train loss:0.0008645376419562005\n",
      "train loss:0.0012931645826241083\n",
      "train loss:0.00037421340124928703\n",
      "train loss:0.01166280052172412\n",
      "train loss:0.011429871356567574\n",
      "train loss:0.002121477692498575\n",
      "train loss:0.0004447582725199775\n",
      "train loss:0.002883778957750501\n",
      "train loss:0.0007527448654947613\n",
      "train loss:0.0006815434606435081\n",
      "train loss:0.004165487621977729\n",
      "train loss:0.000575221716360235\n",
      "train loss:0.00907110428101973\n",
      "train loss:0.00121969222989272\n",
      "train loss:0.004468231205217728\n",
      "train loss:0.0012462725688648871\n",
      "train loss:0.0005184237748110319\n",
      "train loss:0.0017496147007255208\n",
      "train loss:0.0024767067963588\n",
      "train loss:0.0023714355585378955\n",
      "train loss:0.004881239953803034\n",
      "train loss:0.001196634148115331\n",
      "train loss:0.0007121062666586316\n",
      "train loss:0.03491514601235966\n",
      "train loss:0.00018466106153612746\n",
      "train loss:0.00030709530026653555\n",
      "train loss:0.017453801707627593\n",
      "train loss:0.0019129904008484348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00036277636184350425\n",
      "train loss:0.004267400787318459\n",
      "train loss:0.001325006603757128\n",
      "train loss:0.021795215943774995\n",
      "train loss:0.0002488073484610906\n",
      "train loss:0.05292533259297203\n",
      "train loss:0.019429389501783245\n",
      "train loss:0.0009102819755316477\n",
      "train loss:0.00032611208582192003\n",
      "train loss:0.006932313166161489\n",
      "train loss:0.001705771161009773\n",
      "train loss:0.004285886739208791\n",
      "train loss:0.003743837676423554\n",
      "train loss:0.005074420304606273\n",
      "train loss:0.002544324331801573\n",
      "train loss:0.0002808525916032224\n",
      "train loss:0.007546103797780181\n",
      "train loss:0.0004491957746312317\n",
      "train loss:0.0022219629977867313\n",
      "train loss:0.0004432352627142873\n",
      "train loss:0.0023702085798271823\n",
      "train loss:0.00247493887952602\n",
      "train loss:0.008174722568234084\n",
      "train loss:0.004355504090516076\n",
      "train loss:0.0005519000540039086\n",
      "train loss:0.014039777168883773\n",
      "train loss:0.0009425724700737767\n",
      "train loss:0.0037094705405946006\n",
      "train loss:0.013023651397150657\n",
      "train loss:0.0019395578125587397\n",
      "train loss:0.006490781222190656\n",
      "train loss:0.0005551625752436883\n",
      "train loss:0.00016790887860182113\n",
      "train loss:0.00274195848803549\n",
      "train loss:0.023622143268928097\n",
      "train loss:0.010007814964654351\n",
      "train loss:0.002032860407257835\n",
      "train loss:0.000506294910993906\n",
      "train loss:0.0012646837849304097\n",
      "train loss:0.0006776671306230684\n",
      "train loss:0.0007749851400715793\n",
      "train loss:0.004344917988941589\n",
      "train loss:0.002238704740117931\n",
      "train loss:0.004945822262981337\n",
      "train loss:0.005757668989247813\n",
      "train loss:0.0012641957920587535\n",
      "train loss:0.009210923199852316\n",
      "train loss:0.003077848141990192\n",
      "train loss:0.008658473244917295\n",
      "train loss:0.006918676404256118\n",
      "train loss:0.0018998268195996358\n",
      "train loss:0.0007814131475836686\n",
      "train loss:0.002064102854064805\n",
      "train loss:0.0009420293990654604\n",
      "train loss:0.005905833658990326\n",
      "train loss:0.00016286877820473198\n",
      "train loss:0.0015349125060251628\n",
      "train loss:0.004000466748766792\n",
      "train loss:0.004148973976854537\n",
      "train loss:0.0033287814218190357\n",
      "train loss:0.0007960930390845272\n",
      "train loss:0.001363183849335229\n",
      "train loss:0.003836221902252153\n",
      "train loss:0.0005946727185186108\n",
      "train loss:0.0023594077387210986\n",
      "train loss:0.00156359166451381\n",
      "train loss:0.0043273605439370574\n",
      "train loss:0.00020908717299179295\n",
      "train loss:0.006934386991045324\n",
      "train loss:0.00507662637810347\n",
      "train loss:0.003163537488382537\n",
      "train loss:0.0002947100550645574\n",
      "train loss:0.0009917931880126516\n",
      "train loss:0.0005896421888811643\n",
      "train loss:0.002957560902846155\n",
      "train loss:0.0003491604190133884\n",
      "train loss:0.00233371990444292\n",
      "train loss:0.0010092291518350983\n",
      "train loss:0.004506604155673907\n",
      "train loss:0.0007457460547910635\n",
      "train loss:0.00014467373380681978\n",
      "train loss:0.005595539346590438\n",
      "train loss:0.0004525693004350659\n",
      "train loss:0.00024606821084842206\n",
      "train loss:0.006360061070288737\n",
      "train loss:0.0009181734411222753\n",
      "train loss:0.0012588277962167383\n",
      "train loss:0.0033124578323547884\n",
      "train loss:0.0014641799122679913\n",
      "train loss:0.0013090597870459542\n",
      "train loss:0.0002197313446011012\n",
      "train loss:0.0014647295739802183\n",
      "train loss:0.002214501505863738\n",
      "train loss:0.001865985957191633\n",
      "train loss:0.0002565800805481569\n",
      "train loss:0.01317746921567255\n",
      "train loss:0.0001326412082637897\n",
      "train loss:0.0027186750191052485\n",
      "train loss:0.0007382153173949685\n",
      "train loss:0.00028683848796841235\n",
      "train loss:0.002418932046945481\n",
      "train loss:0.005016181348394592\n",
      "train loss:0.0009146145148511669\n",
      "train loss:0.0009484377219744961\n",
      "train loss:0.001788704783148566\n",
      "train loss:0.0016220463595730894\n",
      "train loss:0.0035318931592286428\n",
      "train loss:0.0033210048758085557\n",
      "train loss:0.00024135931874155194\n",
      "train loss:0.0009563863069568613\n",
      "train loss:0.0026654171850428337\n",
      "train loss:0.0002142077500900808\n",
      "train loss:0.000953479613073102\n",
      "train loss:0.0035422117832466906\n",
      "train loss:0.0034761192034069464\n",
      "train loss:0.0017140560489459949\n",
      "train loss:0.0013655827379050979\n",
      "train loss:0.0010700891371009796\n",
      "train loss:0.000263751352144861\n",
      "train loss:0.025769229319594265\n",
      "train loss:0.00023017967491243587\n",
      "train loss:0.004817666218040831\n",
      "train loss:0.0004719557929888559\n",
      "train loss:0.00037093947325336925\n",
      "train loss:0.003875024418584531\n",
      "train loss:0.0002758680730302881\n",
      "train loss:0.0001564289966572177\n",
      "train loss:0.0020373960712477147\n",
      "train loss:0.000182529608944033\n",
      "train loss:0.002065758490512717\n",
      "train loss:0.002052522992760134\n",
      "train loss:0.005076522775544149\n",
      "train loss:0.00036946891691229633\n",
      "train loss:0.005527233019873945\n",
      "train loss:0.0005462414163305331\n",
      "train loss:0.0008198610302857977\n",
      "train loss:0.0023187319104840125\n",
      "train loss:0.0021771443536272566\n",
      "train loss:0.00503800121605051\n",
      "train loss:0.01731116277754427\n",
      "train loss:0.00141486993548698\n",
      "train loss:5.8195023403905896e-05\n",
      "train loss:0.00041770320928888755\n",
      "train loss:0.0027120173518651943\n",
      "train loss:0.0023512239935848957\n",
      "train loss:0.003782414999238493\n",
      "train loss:0.0007588016033910106\n",
      "train loss:0.00727153725920782\n",
      "train loss:0.005425554912905157\n",
      "train loss:0.03811178356041249\n",
      "train loss:0.002001344551423581\n",
      "train loss:0.0032836945836230967\n",
      "train loss:0.004303544354957959\n",
      "train loss:0.0012413221175141898\n",
      "train loss:0.0018601396282022433\n",
      "train loss:0.0029897238392303264\n",
      "train loss:0.0033664519168542673\n",
      "train loss:0.0008403670572682035\n",
      "train loss:0.0054278307774632386\n",
      "train loss:0.0007933276709688726\n",
      "train loss:0.0001221577383750058\n",
      "train loss:0.0006534443018711015\n",
      "train loss:0.004749025283806216\n",
      "train loss:0.0029389924281235753\n",
      "train loss:0.001003075542142537\n",
      "train loss:0.004419428163416955\n",
      "train loss:0.00020540004818108285\n",
      "train loss:0.00285688217630974\n",
      "train loss:0.00031137141461451347\n",
      "train loss:0.0008474991917430122\n",
      "train loss:0.0005735276501209714\n",
      "train loss:0.00038752173188228947\n",
      "train loss:0.004004000178860455\n",
      "train loss:0.006533476506339822\n",
      "train loss:0.004877560189032272\n",
      "train loss:0.01685928355510884\n",
      "train loss:0.0007597781346558178\n",
      "train loss:0.001552593169907114\n",
      "train loss:0.0001540921639730624\n",
      "train loss:0.0002195923887353582\n",
      "train loss:0.001020404663029616\n",
      "train loss:0.0031387967757159152\n",
      "train loss:0.002183878094625421\n",
      "train loss:0.000668631022511684\n",
      "train loss:0.008179580959194114\n",
      "train loss:0.00027166081854021387\n",
      "train loss:0.002240701657154532\n",
      "train loss:0.005792193973584508\n",
      "train loss:0.0002661235813934314\n",
      "train loss:0.000951287029525726\n",
      "train loss:0.0002596437366584543\n",
      "train loss:0.0021707715876847773\n",
      "train loss:0.0005645828058397985\n",
      "train loss:0.0013048622740674124\n",
      "train loss:0.0033524219014841538\n",
      "train loss:0.0020990303031807028\n",
      "train loss:0.0015046972767550702\n",
      "train loss:0.05052556499433234\n",
      "train loss:0.0012328721724561666\n",
      "train loss:0.0002817931687223063\n",
      "train loss:0.002622122069117985\n",
      "train loss:0.0041440593305904026\n",
      "train loss:0.0016316616870596303\n",
      "train loss:0.004044565468323384\n",
      "train loss:0.0008416122690031064\n",
      "train loss:0.0052377123814965265\n",
      "train loss:0.0006331660205650194\n",
      "train loss:0.0009651927525387474\n",
      "train loss:0.0030699590798613273\n",
      "train loss:0.0014318602694777377\n",
      "train loss:0.00030078755790423416\n",
      "train loss:0.0010027996659626103\n",
      "train loss:0.008496523611784728\n",
      "train loss:0.0009439290730277193\n",
      "train loss:0.0015205821208439494\n",
      "train loss:0.0022906965997278685\n",
      "train loss:0.0005117744339815662\n",
      "train loss:0.00023963446823881403\n",
      "train loss:0.0030627106879961338\n",
      "train loss:0.00015136598342080902\n",
      "train loss:0.001701545579321068\n",
      "train loss:0.08121696628604479\n",
      "train loss:0.0013249785446645612\n",
      "train loss:0.0017737085744412079\n",
      "train loss:0.05694443280351122\n",
      "train loss:0.05011829264459058\n",
      "train loss:0.00105901871035059\n",
      "train loss:0.0005220089466641293\n",
      "train loss:0.013649684451172728\n",
      "train loss:0.0006396609452719064\n",
      "train loss:0.006580490294542199\n",
      "train loss:0.00395316137478761\n",
      "train loss:0.0013250711289575063\n",
      "train loss:0.02087995683219692\n",
      "train loss:0.0021863841686408673\n",
      "train loss:0.0038998954637050297\n",
      "train loss:0.004903408560744307\n",
      "train loss:0.004211018882981838\n",
      "train loss:0.006275589431456712\n",
      "train loss:0.00031475764022923934\n",
      "train loss:0.0009251464789697994\n",
      "train loss:0.0014912100111509807\n",
      "train loss:0.0006349436238135328\n",
      "train loss:0.0013253022102700698\n",
      "train loss:0.0002587084962371801\n",
      "train loss:0.0018153033125761877\n",
      "train loss:0.0024915333675999364\n",
      "train loss:0.0014972086378191344\n",
      "train loss:0.0017945160211527578\n",
      "train loss:0.00011399179623748152\n",
      "train loss:0.0011498339342191526\n",
      "train loss:0.000655747862272924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0003306116237513631\n",
      "train loss:0.007593978338845121\n",
      "train loss:0.01662255511200589\n",
      "train loss:0.00199547460077176\n",
      "train loss:0.004279670117934915\n",
      "train loss:0.0009265648784645766\n",
      "train loss:0.002006694784296879\n",
      "train loss:0.00046537924330203393\n",
      "train loss:0.0007689787515493625\n",
      "train loss:0.00341150541266683\n",
      "train loss:0.00014456724610503112\n",
      "train loss:0.009052541314208885\n",
      "train loss:0.0025741260272061656\n",
      "train loss:0.0007009961488165474\n",
      "train loss:0.0001273612535294583\n",
      "train loss:0.00226435435739339\n",
      "train loss:0.001801324764698135\n",
      "train loss:0.00018808338704380786\n",
      "train loss:0.0008327999688468611\n",
      "train loss:0.0001664854883936644\n",
      "train loss:0.0012065949716913418\n",
      "train loss:0.001726934416874898\n",
      "train loss:0.008740247456963012\n",
      "train loss:0.0010715388708216068\n",
      "train loss:0.0014133431917450307\n",
      "train loss:0.01507592294792885\n",
      "train loss:0.00586506835676143\n",
      "train loss:0.000607684929527832\n",
      "train loss:0.0009431982911990489\n",
      "train loss:0.00021066894594225832\n",
      "train loss:0.0025303230273075973\n",
      "train loss:0.000790427078276059\n",
      "train loss:0.0017005445889718713\n",
      "train loss:0.0006595949050810185\n",
      "train loss:0.00021413342926512277\n",
      "train loss:0.0005800657998642357\n",
      "train loss:0.0014229351771236221\n",
      "train loss:0.004758994166913335\n",
      "train loss:0.0015963713805084336\n",
      "train loss:0.0014361868232109253\n",
      "train loss:0.00021481715703558282\n",
      "train loss:0.002393522802628156\n",
      "train loss:0.0003906470822796461\n",
      "train loss:0.033808897372515696\n",
      "train loss:0.002284234518962897\n",
      "train loss:0.10493130865508289\n",
      "train loss:0.0007469823323733134\n",
      "train loss:0.002306111319383796\n",
      "train loss:0.0011018560902878193\n",
      "train loss:0.0007950845785043544\n",
      "train loss:0.0005035147179740653\n",
      "train loss:0.004270829274159481\n",
      "train loss:0.007192515423759902\n",
      "train loss:0.0015933445039031388\n",
      "train loss:0.002291901144784632\n",
      "train loss:0.0055823476248562124\n",
      "train loss:0.0011153861594777469\n",
      "train loss:0.0009545727724014537\n",
      "train loss:0.0013162925942300317\n",
      "train loss:0.0016767115515294146\n",
      "train loss:0.0015201803024845163\n",
      "train loss:0.00011943571273383358\n",
      "train loss:0.00029216742219163264\n",
      "train loss:0.010745978104234659\n",
      "train loss:0.0021794768567368807\n",
      "train loss:0.0010657684816417086\n",
      "train loss:0.0003981650266869142\n",
      "train loss:0.0007058113625276247\n",
      "train loss:0.0007441693637665727\n",
      "train loss:0.0008751668918129867\n",
      "train loss:0.0025645709661143903\n",
      "train loss:0.0016041504184431683\n",
      "train loss:0.001347662991105012\n",
      "train loss:0.0009406295321138296\n",
      "train loss:6.257210431632824e-05\n",
      "train loss:0.0035018686771073945\n",
      "train loss:0.0019450877832912696\n",
      "train loss:0.0024666453978459905\n",
      "train loss:0.00041887554220048853\n",
      "train loss:0.0013001507986042226\n",
      "train loss:0.001133376398183476\n",
      "train loss:0.008221712721378078\n",
      "train loss:0.01284613460449874\n",
      "train loss:0.0031820662425247775\n",
      "train loss:0.0007635936491226112\n",
      "train loss:0.0005645259327891025\n",
      "train loss:0.003244238568924433\n",
      "train loss:0.0003210539801230224\n",
      "train loss:0.00413363808597027\n",
      "train loss:0.010176127033526739\n",
      "train loss:0.00021530192755882618\n",
      "train loss:0.0023735344061379484\n",
      "train loss:0.002403275937699529\n",
      "train loss:0.0014052286772178527\n",
      "train loss:0.0009982505063267546\n",
      "train loss:0.0008152277080224146\n",
      "train loss:0.0030206391196777355\n",
      "train loss:0.07150340445378736\n",
      "train loss:0.0021078484738925127\n",
      "train loss:0.0003048287698953161\n",
      "train loss:0.002683818172278465\n",
      "train loss:0.010433524540503603\n",
      "train loss:0.0009325864297803506\n",
      "train loss:0.0042939061809836076\n",
      "train loss:0.0021960940376492947\n",
      "train loss:0.0008355235181048065\n",
      "train loss:0.004390086906745926\n",
      "train loss:0.0023899066511102874\n",
      "train loss:0.00519724924492097\n",
      "train loss:0.0033486894443480212\n",
      "train loss:0.0011599012039430865\n",
      "train loss:0.002134601640342301\n",
      "train loss:0.0020060513696186703\n",
      "train loss:0.0004190069368592704\n",
      "train loss:0.0038600591349697393\n",
      "train loss:0.0002791150058351233\n",
      "train loss:0.012003111151107297\n",
      "train loss:0.0087783794993341\n",
      "train loss:0.0004172924598128834\n",
      "train loss:0.00830183082975338\n",
      "train loss:0.0078833817224938\n",
      "train loss:0.0016682131434892734\n",
      "train loss:0.0011330637859270798\n",
      "train loss:0.00018755543178617114\n",
      "train loss:0.004737692415515978\n",
      "train loss:0.0035182635930309874\n",
      "train loss:0.0056649993955821465\n",
      "train loss:0.0012953797896187926\n",
      "train loss:0.0016877468627984093\n",
      "train loss:0.0012149341440861618\n",
      "train loss:0.004686804920443563\n",
      "train loss:0.00028150810004352194\n",
      "train loss:0.0049186135214801035\n",
      "train loss:0.0006377799610734525\n",
      "train loss:0.000124668482852115\n",
      "train loss:0.002196957015813916\n",
      "train loss:0.0015155424391240018\n",
      "train loss:0.0008670973335858933\n",
      "train loss:0.0003810420863656702\n",
      "train loss:0.0041388665884625545\n",
      "train loss:0.002669784082106026\n",
      "train loss:0.0031425287058289802\n",
      "train loss:0.0006451638998172972\n",
      "train loss:0.0007966921490679985\n",
      "train loss:7.554861059119783e-05\n",
      "train loss:0.002475887516124173\n",
      "train loss:0.0011945839396883319\n",
      "train loss:0.0023402862749539537\n",
      "train loss:0.008363913224373399\n",
      "train loss:0.0014317786372983767\n",
      "train loss:0.0012646038514650443\n",
      "train loss:0.003863009394676416\n",
      "train loss:9.659137448735605e-05\n",
      "train loss:0.013518837657117498\n",
      "train loss:0.006618336415424542\n",
      "train loss:0.010740684396493918\n",
      "train loss:0.001835789229934435\n",
      "train loss:0.0010466211979827048\n",
      "train loss:0.0003105438996533227\n",
      "train loss:0.001564020592593089\n",
      "train loss:0.006172300163071843\n",
      "train loss:0.001506289886824225\n",
      "train loss:0.00356136805144233\n",
      "train loss:0.006087119353119598\n",
      "train loss:0.002348938345800032\n",
      "train loss:0.004277116090206115\n",
      "train loss:0.0005678939544736051\n",
      "train loss:0.0008497033428303863\n",
      "train loss:0.0015478694263344386\n",
      "train loss:0.0032693166469653628\n",
      "train loss:0.026147423211860768\n",
      "train loss:0.0005772586915227364\n",
      "train loss:0.0033910488726095656\n",
      "train loss:0.006717288929037417\n",
      "train loss:0.012423807716175538\n",
      "train loss:0.0036906045592693805\n",
      "train loss:0.0009673471478413509\n",
      "train loss:0.006998135374447189\n",
      "train loss:0.01094577401309461\n",
      "train loss:0.0017407264594497354\n",
      "train loss:0.010694216422859837\n",
      "train loss:0.004042137148529564\n",
      "train loss:0.0026678424844436095\n",
      "train loss:0.0006430687190810741\n",
      "train loss:0.004646000195370502\n",
      "train loss:0.00045329349004931874\n",
      "train loss:0.0008012798852393055\n",
      "train loss:0.0027894305913380257\n",
      "train loss:0.0031456548659834454\n",
      "train loss:0.00662741558523047\n",
      "train loss:0.012672787486313746\n",
      "train loss:0.030142207637933432\n",
      "train loss:0.0022145247311035976\n",
      "train loss:0.000953595176996426\n",
      "train loss:0.0012630405828334054\n",
      "train loss:0.0015846805290452074\n",
      "train loss:0.0005697168669602247\n",
      "train loss:0.00024281333359297007\n",
      "train loss:0.0017391104945940821\n",
      "train loss:0.004350475189442603\n",
      "train loss:0.0025479674871288194\n",
      "train loss:0.008808455823161166\n",
      "train loss:0.03903989704345255\n",
      "train loss:0.0003643663928291513\n",
      "train loss:0.024535118750714072\n",
      "train loss:0.03304855469129989\n",
      "train loss:0.012027008758827952\n",
      "train loss:0.007757819128802036\n",
      "train loss:0.0033366607680286138\n",
      "train loss:0.05426029279364149\n",
      "train loss:0.0009452415102235832\n",
      "train loss:0.0008800001765755573\n",
      "train loss:0.0020522258057928938\n",
      "train loss:0.009518555519101284\n",
      "train loss:0.0018693500793310709\n",
      "train loss:0.004953771662333497\n",
      "train loss:0.0026617503460701518\n",
      "train loss:0.00837855412442316\n",
      "train loss:0.05733991738360232\n",
      "train loss:0.004457989498178251\n",
      "train loss:0.0016893713072104737\n",
      "train loss:0.0019089246472237475\n",
      "train loss:0.0021354093379139516\n",
      "train loss:0.003063469209030478\n",
      "train loss:0.0007540100368999257\n",
      "train loss:0.010335577577154921\n",
      "train loss:0.006954531188492806\n",
      "train loss:0.009927116787980375\n",
      "train loss:0.003644711237765745\n",
      "train loss:0.001822260731097629\n",
      "train loss:0.0017973078977336953\n",
      "train loss:0.010697046769635237\n",
      "train loss:0.0004990832212878206\n",
      "=== epoch:16, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0015495497027990114\n",
      "train loss:0.007763929210500405\n",
      "train loss:0.001962419253230259\n",
      "train loss:0.0004191687123854921\n",
      "train loss:0.0008172393191951108\n",
      "train loss:0.001297270881452616\n",
      "train loss:0.014325924372777174\n",
      "train loss:0.04083463716050005\n",
      "train loss:0.009049264709332013\n",
      "train loss:0.004303844996807411\n",
      "train loss:0.007056740025190517\n",
      "train loss:0.0017835970278317\n",
      "train loss:0.0044954381351387076\n",
      "train loss:0.0031380208841856284\n",
      "train loss:0.029020625647492842\n",
      "train loss:0.0033817667570626942\n",
      "train loss:0.0006185775891373888\n",
      "train loss:0.00043371993858864517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000693115353221636\n",
      "train loss:0.009680694851172565\n",
      "train loss:0.0035320344974516128\n",
      "train loss:0.00021919176412971638\n",
      "train loss:0.004379675049907178\n",
      "train loss:0.001320746035708617\n",
      "train loss:0.0009154580605652937\n",
      "train loss:0.0007789845428114708\n",
      "train loss:0.0017903948857196656\n",
      "train loss:0.00021147852868391468\n",
      "train loss:0.0003360656478801139\n",
      "train loss:0.0020108348154104\n",
      "train loss:0.0007184545967718347\n",
      "train loss:0.006663512054892102\n",
      "train loss:9.541726309938397e-05\n",
      "train loss:0.002892678419512817\n",
      "train loss:0.004354783486930038\n",
      "train loss:0.002304212262087556\n",
      "train loss:0.0006818552187005695\n",
      "train loss:0.0018894666327852474\n",
      "train loss:0.0027956686660423817\n",
      "train loss:0.0021970362232514064\n",
      "train loss:0.005685433364148673\n",
      "train loss:0.000800379292786342\n",
      "train loss:0.015068318321680365\n",
      "train loss:0.003962244716625468\n",
      "train loss:0.0005731417869881343\n",
      "train loss:0.0003373915596435328\n",
      "train loss:0.007114269982989617\n",
      "train loss:0.0027326295086890456\n",
      "train loss:0.00271338857000896\n",
      "train loss:0.005250322468276665\n",
      "train loss:0.00023955875387958364\n",
      "train loss:0.001338611258257672\n",
      "train loss:0.0007723262273443927\n",
      "train loss:0.0025237974054982677\n",
      "train loss:0.006463808810071418\n",
      "train loss:0.0013013612210601197\n",
      "train loss:0.005125598394031163\n",
      "train loss:0.0012053502914702225\n",
      "train loss:0.02832369767445748\n",
      "train loss:0.0016492974319151652\n",
      "train loss:0.001769043766694567\n",
      "train loss:0.0017578842659609442\n",
      "train loss:0.0003857401673419027\n",
      "train loss:0.0008987913091706661\n",
      "train loss:0.0019084058770878808\n",
      "train loss:0.00022610148083981825\n",
      "train loss:0.0004964527327585343\n",
      "train loss:0.006976246527585862\n",
      "train loss:0.005667518141518887\n",
      "train loss:0.0029142079083735533\n",
      "train loss:0.002944671236990546\n",
      "train loss:0.0007426997206744371\n",
      "train loss:0.011622330593722014\n",
      "train loss:0.003034717441307366\n",
      "train loss:0.005737369171993712\n",
      "train loss:0.0005532312636944296\n",
      "train loss:0.002686703370838347\n",
      "train loss:0.0018980766445215664\n",
      "train loss:0.016593231357413286\n",
      "train loss:0.004937365959826838\n",
      "train loss:0.000687011568073222\n",
      "train loss:0.0003467179098948407\n",
      "train loss:0.00014110752692282738\n",
      "train loss:0.001946688665697707\n",
      "train loss:0.020129902100700665\n",
      "train loss:0.0016896966959610822\n",
      "train loss:0.0003062998364899533\n",
      "train loss:0.0021015047289328374\n",
      "train loss:0.0005374197183086897\n",
      "train loss:0.0020669505740099443\n",
      "train loss:0.02672587795628861\n",
      "train loss:0.0028364806429823693\n",
      "train loss:0.004234485874436651\n",
      "train loss:0.0007266929109357529\n",
      "train loss:0.0001365695863876694\n",
      "train loss:0.0033395292356132806\n",
      "train loss:0.001058633633115086\n",
      "train loss:0.0009934423520497554\n",
      "train loss:0.006940678370173183\n",
      "train loss:0.0008726963223919207\n",
      "train loss:0.0004334707171929917\n",
      "train loss:0.0005826813584221002\n",
      "train loss:0.003068871827106967\n",
      "train loss:0.0020032084284411144\n",
      "train loss:0.0061042828831401755\n",
      "train loss:0.003984031193203652\n",
      "train loss:0.005984424456924618\n",
      "train loss:0.021019377306768682\n",
      "train loss:0.000911903452073565\n",
      "train loss:0.007584519672912995\n",
      "train loss:0.004387956943273995\n",
      "train loss:0.001004798844388835\n",
      "train loss:0.00207280302921047\n",
      "train loss:0.00046205735324206416\n",
      "train loss:0.007464663581631149\n",
      "train loss:0.0021342952635038785\n",
      "train loss:0.00025427087405882344\n",
      "train loss:0.00041211816969391165\n",
      "train loss:0.0005818543062122163\n",
      "train loss:0.0014143296011896581\n",
      "train loss:0.0013490766435698908\n",
      "train loss:0.02328187314265633\n",
      "train loss:0.002274714931226739\n",
      "train loss:0.005145182760675834\n",
      "train loss:0.0014493759621301678\n",
      "train loss:0.008421470905517203\n",
      "train loss:0.010190905046306016\n",
      "train loss:0.023168309031373503\n",
      "train loss:0.0008508553445218753\n",
      "train loss:0.001435307047937524\n",
      "train loss:0.002250546615999924\n",
      "train loss:0.0005951153671375959\n",
      "train loss:0.0007132008689680156\n",
      "train loss:0.003979084996448893\n",
      "train loss:0.0018323695577537075\n",
      "train loss:0.0001616080812008643\n",
      "train loss:0.0029130841417287084\n",
      "train loss:0.0019693117481899293\n",
      "train loss:0.008005197126371794\n",
      "train loss:0.0025893142071010005\n",
      "train loss:0.016995017888081533\n",
      "train loss:0.0011707032671640554\n",
      "train loss:0.0006233328883502262\n",
      "train loss:0.0003639148767918612\n",
      "train loss:0.0006438960955461224\n",
      "train loss:0.0005454291010267867\n",
      "train loss:0.0015067200495614424\n",
      "train loss:0.0044323975944492375\n",
      "train loss:0.0004420151815903693\n",
      "train loss:0.0031252278281673636\n",
      "train loss:0.010767709468267127\n",
      "train loss:0.0032441716297809294\n",
      "train loss:0.0012526562334081246\n",
      "train loss:0.0059330918676457275\n",
      "train loss:0.002347163166954838\n",
      "train loss:0.003273069263679943\n",
      "train loss:0.0004650414812003049\n",
      "train loss:0.00044749457116770807\n",
      "train loss:0.0009425924264848932\n",
      "train loss:0.0009226879493205488\n",
      "train loss:0.001462173075155648\n",
      "train loss:0.001499376912014882\n",
      "train loss:0.0014663806650683777\n",
      "train loss:0.004174853829502831\n",
      "train loss:0.0006332134750659117\n",
      "train loss:0.032725616212372174\n",
      "train loss:0.00743632208155012\n",
      "train loss:5.4563264154498526e-05\n",
      "train loss:0.0015822552369151891\n",
      "train loss:0.00018385250159163653\n",
      "train loss:0.002872537499006868\n",
      "train loss:0.0003323006753942466\n",
      "train loss:0.00011870098301502256\n",
      "train loss:0.000324922418852425\n",
      "train loss:0.00392836872574524\n",
      "train loss:0.001911391971214556\n",
      "train loss:0.0023191959236723656\n",
      "train loss:0.002653091898660319\n",
      "train loss:0.002327341285927328\n",
      "train loss:0.00044964863259585756\n",
      "train loss:0.001746768898424991\n",
      "train loss:0.0012477349316290867\n",
      "train loss:0.002546584836942907\n",
      "train loss:0.002359420554495236\n",
      "train loss:0.007523326075424239\n",
      "train loss:0.0004464897909340369\n",
      "train loss:0.0011540511322868975\n",
      "train loss:0.002838598154046616\n",
      "train loss:0.00815190187393674\n",
      "train loss:0.004395979921937106\n",
      "train loss:0.018063815221278378\n",
      "train loss:0.0008796203089279642\n",
      "train loss:0.00040139958256756795\n",
      "train loss:0.003149317391516115\n",
      "train loss:0.003628442916143792\n",
      "train loss:0.000553892809298405\n",
      "train loss:0.000848390860109789\n",
      "train loss:0.002662243635280234\n",
      "train loss:0.0007263580299663632\n",
      "train loss:0.00018001927165212946\n",
      "train loss:0.001471413136373195\n",
      "train loss:0.0001240213586777588\n",
      "train loss:0.0014323828981131533\n",
      "train loss:0.0011328701821661845\n",
      "train loss:0.0010476978266286475\n",
      "train loss:0.000795685487070375\n",
      "train loss:0.0005534110550405678\n",
      "train loss:0.0014933779763027038\n",
      "train loss:0.0013367934132662983\n",
      "train loss:0.00016798368252339262\n",
      "train loss:0.003197262073842327\n",
      "train loss:0.0028342428464983565\n",
      "train loss:6.188180596732428e-05\n",
      "train loss:0.0012782906589319043\n",
      "train loss:0.0016345370705139156\n",
      "train loss:0.004893781786886808\n",
      "train loss:0.0003469035019120953\n",
      "train loss:0.00041451630435055715\n",
      "train loss:0.0011170018934076153\n",
      "train loss:0.0003865834646621727\n",
      "train loss:0.0003493586325667626\n",
      "train loss:0.003167914627672624\n",
      "train loss:0.001308869436988977\n",
      "train loss:0.0043992934294883376\n",
      "train loss:0.005008583750632475\n",
      "train loss:0.001606593262307009\n",
      "train loss:0.007623349328728235\n",
      "train loss:0.0003878754318615847\n",
      "train loss:0.00015656986811305156\n",
      "train loss:0.0008223144016442669\n",
      "train loss:0.0011159216465317463\n",
      "train loss:0.00576340749646028\n",
      "train loss:0.000877609079074019\n",
      "train loss:0.0008626851361335504\n",
      "train loss:0.0010171283092592271\n",
      "train loss:0.0052080150405297\n",
      "train loss:0.0008439313435946657\n",
      "train loss:0.001128392936588397\n",
      "train loss:0.0009805785634480302\n",
      "train loss:0.00039276625181123307\n",
      "train loss:0.0006922780437460513\n",
      "train loss:0.002294639814705573\n",
      "train loss:0.00014753742473430732\n",
      "train loss:0.0010325145418144488\n",
      "train loss:0.0022214781866241027\n",
      "train loss:0.007194924082375503\n",
      "train loss:0.0020595697905686247\n",
      "train loss:0.002332657553983222\n",
      "train loss:0.018217785659669923\n",
      "train loss:0.004841375778966504\n",
      "train loss:0.0003639418085716313\n",
      "train loss:0.0035524368392832605\n",
      "train loss:0.0021647580664850992\n",
      "train loss:0.0003332601608170068\n",
      "train loss:0.012851054042835708\n",
      "train loss:0.001209276252470383\n",
      "train loss:0.0007504454220018447\n",
      "train loss:0.0009061497653381637\n",
      "train loss:0.00045197142706648527\n",
      "train loss:0.005763099371969053\n",
      "train loss:0.01007438365058516\n",
      "train loss:0.0008597168424438476\n",
      "train loss:0.0008641549332106362\n",
      "train loss:0.00047134176151492345\n",
      "train loss:0.014261617760305257\n",
      "train loss:0.002859174859922776\n",
      "train loss:0.0004728811126308386\n",
      "train loss:0.004214181737603159\n",
      "train loss:0.0006542793355885784\n",
      "train loss:0.0009068003561520492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014021040717218324\n",
      "train loss:7.611891499943934e-05\n",
      "train loss:0.001085080835098025\n",
      "train loss:0.00011527892509955999\n",
      "train loss:0.0008349139663734372\n",
      "train loss:0.0010445541326347906\n",
      "train loss:0.009387977328797396\n",
      "train loss:0.00019173416493901152\n",
      "train loss:0.0001471539072111092\n",
      "train loss:0.004164818733683191\n",
      "train loss:0.00037344259586101074\n",
      "train loss:0.010742738441598778\n",
      "train loss:0.003676438909684398\n",
      "train loss:0.005006467828507608\n",
      "train loss:0.0009770008400258213\n",
      "train loss:0.0014708499615646476\n",
      "train loss:0.006130251278452625\n",
      "train loss:0.00012161683053282213\n",
      "train loss:0.003491264622004838\n",
      "train loss:0.0002191263097851786\n",
      "train loss:0.0012002281795577099\n",
      "train loss:0.0005096639617698736\n",
      "train loss:0.019578145365930066\n",
      "train loss:0.0007753217138348865\n",
      "train loss:0.0010400395993027797\n",
      "train loss:0.006576020776403168\n",
      "train loss:0.000314407804623893\n",
      "train loss:0.004961700086812252\n",
      "train loss:7.794224984729604e-05\n",
      "train loss:0.0009728032957746803\n",
      "train loss:0.015118463406545452\n",
      "train loss:0.0007313323427844802\n",
      "train loss:0.0012245037106830723\n",
      "train loss:0.0019033172423089215\n",
      "train loss:0.013148482612156375\n",
      "train loss:0.004784706243475025\n",
      "train loss:0.01041507016475578\n",
      "train loss:0.002186932942093014\n",
      "train loss:0.004578064515514992\n",
      "train loss:0.001314089828114503\n",
      "train loss:0.00032972938588280446\n",
      "train loss:0.00046989891538547814\n",
      "train loss:0.0006826590494110581\n",
      "train loss:0.003705991824044231\n",
      "train loss:0.0005013279738195512\n",
      "train loss:0.0042070339080454685\n",
      "train loss:0.001246618600317749\n",
      "train loss:0.0036731950011457365\n",
      "train loss:0.0012542675432887112\n",
      "train loss:0.018477364220899937\n",
      "train loss:0.00028988026279740993\n",
      "train loss:0.0012984258166949209\n",
      "train loss:0.0009621275129961398\n",
      "train loss:0.005101017621218261\n",
      "train loss:0.03575877488373322\n",
      "train loss:0.0011119840415045464\n",
      "train loss:0.008291765368084085\n",
      "train loss:0.0030351426196431287\n",
      "train loss:0.0012411939039909845\n",
      "train loss:0.0008254866965988053\n",
      "train loss:0.005719133000269872\n",
      "train loss:0.0011639375494258888\n",
      "train loss:0.001520250259486236\n",
      "train loss:0.0011544569503050047\n",
      "train loss:0.003450279321845543\n",
      "train loss:0.001741906217370604\n",
      "train loss:0.0023302533914683686\n",
      "train loss:0.0015822876287335944\n",
      "train loss:0.0007428344086445456\n",
      "train loss:0.006489336375099562\n",
      "train loss:0.002416107610598021\n",
      "train loss:0.0028919029638131396\n",
      "train loss:0.0004027493005363503\n",
      "train loss:0.001486032241417519\n",
      "train loss:0.016524113572173194\n",
      "train loss:0.0012742646389653617\n",
      "train loss:0.001794144538096954\n",
      "train loss:0.00013938205602950958\n",
      "train loss:0.0001329784243744307\n",
      "train loss:0.0006246180693637548\n",
      "train loss:0.00013744990687860757\n",
      "train loss:0.0025467254301423823\n",
      "train loss:0.002473584476213886\n",
      "train loss:0.003274636074059658\n",
      "train loss:0.005665100420102162\n",
      "train loss:0.006648847602824225\n",
      "train loss:0.0008707446548767645\n",
      "train loss:0.0011452196921399815\n",
      "train loss:0.004557059521221205\n",
      "train loss:0.0009382595030881774\n",
      "train loss:0.0030155609101176722\n",
      "train loss:0.0009804766650460405\n",
      "train loss:0.0009542175894040855\n",
      "train loss:0.004085656413088093\n",
      "train loss:0.0039040703583037377\n",
      "train loss:0.0013966567621658298\n",
      "train loss:0.0014037136019250296\n",
      "train loss:0.005502431593187625\n",
      "train loss:0.0002633547123217234\n",
      "train loss:0.004683391224621267\n",
      "train loss:0.0009274674606775064\n",
      "train loss:0.004563453579756765\n",
      "train loss:3.398380251634159e-05\n",
      "train loss:0.00035240695282432594\n",
      "train loss:0.00585797941947658\n",
      "train loss:0.00026439959192824564\n",
      "train loss:0.0004781303764197788\n",
      "train loss:0.0010468275492288345\n",
      "train loss:0.0023456858685574995\n",
      "train loss:0.013013629510548462\n",
      "train loss:0.010383446349573286\n",
      "train loss:0.002942831050580142\n",
      "train loss:0.0015929568718137841\n",
      "train loss:0.003274085753655566\n",
      "train loss:0.001578771363524497\n",
      "train loss:0.003491295472610617\n",
      "train loss:0.0007115537425102716\n",
      "train loss:0.013214550607380955\n",
      "train loss:0.00766160871495539\n",
      "train loss:0.0014106156482500164\n",
      "train loss:0.005146716886649435\n",
      "train loss:0.005595333951953011\n",
      "train loss:0.0003481659113474883\n",
      "train loss:0.0020839215650160633\n",
      "train loss:0.002969183017710124\n",
      "train loss:0.0006587638560708874\n",
      "train loss:0.0013735436592680456\n",
      "train loss:0.0021174660996690175\n",
      "train loss:0.0048000008890617726\n",
      "train loss:0.00971746553413331\n",
      "train loss:0.003336523522194151\n",
      "train loss:0.0016957529771606016\n",
      "train loss:0.000385508640531401\n",
      "train loss:0.0019971072157454707\n",
      "train loss:0.0010600038647095142\n",
      "train loss:0.00014524312229236398\n",
      "train loss:0.004673162299804931\n",
      "train loss:0.0010323196301117244\n",
      "train loss:0.002095235261422917\n",
      "train loss:0.0014154828208263867\n",
      "train loss:0.0023452457439914784\n",
      "train loss:0.003146866519458304\n",
      "train loss:0.0016258921528678905\n",
      "train loss:0.0005777425277232324\n",
      "train loss:0.0002970155024649566\n",
      "train loss:0.007453615803644259\n",
      "train loss:0.0015811642697618395\n",
      "train loss:0.0020691376990150793\n",
      "train loss:0.004598586870884028\n",
      "train loss:0.004559253296897067\n",
      "train loss:0.009834768210844388\n",
      "train loss:0.00431627984081581\n",
      "train loss:0.00027540319603001223\n",
      "train loss:0.004038758806593989\n",
      "train loss:0.00201416129402751\n",
      "train loss:0.003798078078194576\n",
      "train loss:0.0008158491855469169\n",
      "train loss:0.00026317429439901013\n",
      "train loss:0.0029178218788049716\n",
      "train loss:0.010543824010478453\n",
      "train loss:0.017903794707319964\n",
      "train loss:0.002499948425529896\n",
      "train loss:0.022076599336053132\n",
      "train loss:0.002069306208552532\n",
      "train loss:0.004611407091361275\n",
      "train loss:0.00033197978987791296\n",
      "train loss:0.005969686655829582\n",
      "train loss:0.002082888096789794\n",
      "train loss:0.0046299521462421864\n",
      "train loss:0.00018827080424925304\n",
      "train loss:0.002246350468620137\n",
      "train loss:0.0006671916554272188\n",
      "train loss:0.002724952034399916\n",
      "train loss:0.005466570219240993\n",
      "train loss:0.00018388213477262425\n",
      "train loss:0.0004622717346102581\n",
      "train loss:0.003674805979613709\n",
      "train loss:0.004444752742134991\n",
      "train loss:0.002637314086190527\n",
      "train loss:0.004265481856490135\n",
      "train loss:0.0020281514009582906\n",
      "train loss:0.018662803999865075\n",
      "train loss:0.0017903981694330478\n",
      "train loss:0.003622711393134903\n",
      "train loss:0.0018046228210944124\n",
      "train loss:0.0037009261866396887\n",
      "train loss:0.004711149001156008\n",
      "train loss:0.001403660897981212\n",
      "train loss:0.00414582419354704\n",
      "train loss:0.004898414203058745\n",
      "train loss:0.003744604837122519\n",
      "train loss:0.0005988417683837262\n",
      "train loss:0.0006986718295796242\n",
      "train loss:0.0006420464785904979\n",
      "train loss:0.014705501016424021\n",
      "train loss:0.001636583095814431\n",
      "train loss:0.007192272216211848\n",
      "train loss:0.002437867910735702\n",
      "train loss:0.000354603341120218\n",
      "train loss:0.01883329208956275\n",
      "train loss:0.00015490425425589545\n",
      "train loss:0.0004878412725913227\n",
      "train loss:0.02166960224217462\n",
      "train loss:0.00042354823653887377\n",
      "train loss:0.010916614811440817\n",
      "train loss:0.001276188154250124\n",
      "train loss:0.012165695395010324\n",
      "train loss:0.0033611995839172874\n",
      "train loss:0.023004972268596945\n",
      "train loss:0.0008654761496891708\n",
      "train loss:0.0004539664005988536\n",
      "train loss:0.0005240077420061352\n",
      "train loss:0.013330831802682741\n",
      "train loss:0.02684385156536898\n",
      "train loss:0.0019581784658474185\n",
      "train loss:0.011496170850293445\n",
      "train loss:0.00046465859789504473\n",
      "train loss:0.0019396265255284164\n",
      "train loss:0.008063975044594537\n",
      "train loss:0.05665557423847802\n",
      "train loss:0.0009954732736363304\n",
      "train loss:0.001512361588160214\n",
      "train loss:0.003112033667359773\n",
      "train loss:0.0022533822348028694\n",
      "train loss:0.0004619450102293781\n",
      "train loss:0.003580532857510007\n",
      "train loss:0.0003192847755525002\n",
      "train loss:0.008286533502547367\n",
      "train loss:0.004073586488762435\n",
      "train loss:0.0026948611624613827\n",
      "train loss:0.006298461007929802\n",
      "train loss:0.0036929379910096063\n",
      "train loss:0.01299835104656467\n",
      "train loss:0.005496458633522443\n",
      "train loss:0.007875579983505718\n",
      "train loss:0.0008467433520461411\n",
      "train loss:0.00021850616711371649\n",
      "train loss:0.00038255181181079455\n",
      "train loss:0.004581800426622146\n",
      "train loss:0.002895769162620707\n",
      "train loss:0.0014276546781244333\n",
      "train loss:0.0025138245566379124\n",
      "train loss:0.0035839734485697437\n",
      "train loss:0.00043802302175772155\n",
      "train loss:0.0011144415862039258\n",
      "train loss:0.0017900900575897308\n",
      "train loss:0.0023724883589512774\n",
      "train loss:0.0005109415232169856\n",
      "train loss:0.0005874664088714347\n",
      "train loss:0.002172226483488835\n",
      "train loss:0.006212205347363443\n",
      "train loss:0.0008877965684858473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0019025201990544218\n",
      "train loss:0.0011564196883422973\n",
      "train loss:0.0023171598092845015\n",
      "train loss:0.0002747970105336188\n",
      "train loss:0.0022972436962624197\n",
      "train loss:0.00039460408219614524\n",
      "train loss:0.0015366736865839246\n",
      "train loss:0.002586291831717092\n",
      "train loss:0.010830283910538452\n",
      "train loss:0.010584995274219697\n",
      "train loss:0.001663623553369988\n",
      "train loss:0.006240782984539376\n",
      "train loss:0.004760575181392101\n",
      "train loss:0.0011023608108071655\n",
      "train loss:0.006610561560701792\n",
      "train loss:0.0012932649710847921\n",
      "train loss:0.0007630324059793962\n",
      "train loss:0.0015397520912207984\n",
      "train loss:0.007069160470005104\n",
      "train loss:0.004651426934683936\n",
      "train loss:0.0031160454678306744\n",
      "train loss:0.003675743003343386\n",
      "train loss:0.001153148655749765\n",
      "train loss:0.0011305899496606984\n",
      "train loss:0.007389004298421254\n",
      "train loss:0.0003815579970609832\n",
      "train loss:0.00028235669916428993\n",
      "train loss:0.0015491143123198287\n",
      "train loss:0.0077191241572656995\n",
      "train loss:0.002979642556427601\n",
      "train loss:0.0003776777100524266\n",
      "train loss:0.00021030356619311863\n",
      "train loss:0.002003340300464531\n",
      "train loss:0.00034244265951171844\n",
      "train loss:0.03083973165628744\n",
      "train loss:0.0003332194456095721\n",
      "train loss:0.0009049160971179979\n",
      "train loss:0.007920034324850438\n",
      "train loss:0.0012829122791779607\n",
      "train loss:8.485407023582383e-05\n",
      "train loss:0.006148303712923207\n",
      "train loss:0.0006581526105907806\n",
      "train loss:0.004877695307726648\n",
      "train loss:0.005059676990815482\n",
      "train loss:0.002391511433843233\n",
      "train loss:0.0013536283951890633\n",
      "train loss:0.0018345283423922213\n",
      "train loss:0.005321912154839656\n",
      "train loss:0.0008010400046074274\n",
      "train loss:0.00042142248923235576\n",
      "train loss:0.00017216034097661126\n",
      "train loss:0.00010485971167528505\n",
      "train loss:0.0011568069931306797\n",
      "train loss:0.0008441651608192625\n",
      "train loss:0.0002707917974853172\n",
      "train loss:0.0013358344749741446\n",
      "train loss:0.0005794742321072212\n",
      "train loss:0.015465275038230142\n",
      "train loss:0.00018133945786950878\n",
      "train loss:0.0031202750224008867\n",
      "train loss:0.0006901383339268504\n",
      "train loss:0.0003868311359745144\n",
      "train loss:0.0017321214886294573\n",
      "train loss:0.0030921123792504094\n",
      "train loss:0.0038054773750917747\n",
      "train loss:0.00014500785083213768\n",
      "train loss:0.0011253366539308975\n",
      "train loss:0.0010668855987963585\n",
      "train loss:0.002630327103135668\n",
      "train loss:0.009017634858235023\n",
      "train loss:0.04441967593627031\n",
      "train loss:0.0011230088694912657\n",
      "train loss:0.0008287758302008437\n",
      "train loss:0.01687688137729187\n",
      "train loss:0.017621267031781417\n",
      "train loss:0.0004997961033441216\n",
      "train loss:0.004968482844702676\n",
      "train loss:0.004078119374154147\n",
      "=== epoch:17, train acc:0.997, test acc:0.984 ===\n",
      "train loss:0.00227865995845291\n",
      "train loss:0.0012397630449885462\n",
      "train loss:0.004204380146641996\n",
      "train loss:0.002854544375356086\n",
      "train loss:0.0022634525936811715\n",
      "train loss:0.008594505514508806\n",
      "train loss:0.004705631729433385\n",
      "train loss:0.003153555170783676\n",
      "train loss:0.002908576305364609\n",
      "train loss:0.004800270823497978\n",
      "train loss:0.0014954665969133087\n",
      "train loss:0.0022402598724612604\n",
      "train loss:0.00029239594183174566\n",
      "train loss:0.026832606608298816\n",
      "train loss:0.0033420341729064264\n",
      "train loss:0.001644978735875952\n",
      "train loss:0.00028676039864566487\n",
      "train loss:0.0007037682249685908\n",
      "train loss:0.0006140369546509923\n",
      "train loss:0.0010699028901933335\n",
      "train loss:0.0007145070298077074\n",
      "train loss:0.0024514708250497714\n",
      "train loss:0.011172239226516839\n",
      "train loss:7.562889561807512e-05\n",
      "train loss:0.00024121790937790255\n",
      "train loss:0.0024520915907995967\n",
      "train loss:0.0014885071323453803\n",
      "train loss:0.011878912009155864\n",
      "train loss:0.002235118843102535\n",
      "train loss:0.003933963672283033\n",
      "train loss:0.0020042858425500278\n",
      "train loss:0.0033111450646457685\n",
      "train loss:0.0010445571106587285\n",
      "train loss:0.0021753448900686534\n",
      "train loss:0.0017350856159988057\n",
      "train loss:0.002489794777475823\n",
      "train loss:0.0014757408359361397\n",
      "train loss:0.0009803635831784278\n",
      "train loss:0.0017511527439243485\n",
      "train loss:0.0002525689206457981\n",
      "train loss:0.003145715076278919\n",
      "train loss:0.005936704004288397\n",
      "train loss:0.0006649732852724707\n",
      "train loss:0.00032573812395734857\n",
      "train loss:0.002590011798350528\n",
      "train loss:0.0023852051362028663\n",
      "train loss:0.011532999477883403\n",
      "train loss:0.0017653149661306787\n",
      "train loss:0.007287346440159199\n",
      "train loss:0.001214200071519409\n",
      "train loss:0.002714110207091259\n",
      "train loss:0.0005167253293202078\n",
      "train loss:0.0027086702621670978\n",
      "train loss:0.00022854932935810777\n",
      "train loss:0.0002091890650754057\n",
      "train loss:0.0001678740541311813\n",
      "train loss:0.0003842147831523668\n",
      "train loss:0.00010205760326764483\n",
      "train loss:0.0023643732175767495\n",
      "train loss:0.0024352580240934608\n",
      "train loss:0.002313382850599009\n",
      "train loss:0.0005991013791531173\n",
      "train loss:0.000440851501856713\n",
      "train loss:0.00024851482085285116\n",
      "train loss:0.0009829878050971763\n",
      "train loss:0.0007603730707893058\n",
      "train loss:0.000284048805341988\n",
      "train loss:0.0016919684355599016\n",
      "train loss:0.000885441872596322\n",
      "train loss:0.0010701675185331486\n",
      "train loss:0.0002623313638059658\n",
      "train loss:0.0032691788720152328\n",
      "train loss:0.0012779494391029298\n",
      "train loss:0.00176166932324111\n",
      "train loss:0.0004273863136732749\n",
      "train loss:0.0007797229302854175\n",
      "train loss:0.0017080401172590153\n",
      "train loss:0.009398354691824727\n",
      "train loss:0.006727168230326007\n",
      "train loss:7.85630479040201e-05\n",
      "train loss:0.008526558015466017\n",
      "train loss:0.014139987609597015\n",
      "train loss:0.0017431833881269938\n",
      "train loss:0.004160614755051664\n",
      "train loss:0.0006780734187769838\n",
      "train loss:0.00036536186533594735\n",
      "train loss:0.0006878978730253945\n",
      "train loss:0.0007511993629701215\n",
      "train loss:0.014901618716398102\n",
      "train loss:0.0011059604110533168\n",
      "train loss:0.001558094519575919\n",
      "train loss:0.0024353520377328524\n",
      "train loss:0.00017047303286745553\n",
      "train loss:0.0006726190188562606\n",
      "train loss:0.0005934544354422047\n",
      "train loss:0.0027384963465040507\n",
      "train loss:0.004782361792321012\n",
      "train loss:0.018059538107863968\n",
      "train loss:0.00025000186817786697\n",
      "train loss:0.0005624498064906858\n",
      "train loss:0.0014174344008225023\n",
      "train loss:0.0009935490050425805\n",
      "train loss:0.0005701423233119697\n",
      "train loss:0.04572049363195815\n",
      "train loss:0.0005846516867334326\n",
      "train loss:0.007117025142148797\n",
      "train loss:0.0033472347859437933\n",
      "train loss:0.005632251551923937\n",
      "train loss:0.005563589963330424\n",
      "train loss:0.002290761197151865\n",
      "train loss:0.0027479323189749925\n",
      "train loss:0.004257530694848146\n",
      "train loss:0.0008170581757064936\n",
      "train loss:0.0015408340278670182\n",
      "train loss:0.0004010764567494631\n",
      "train loss:0.0009338529839186284\n",
      "train loss:0.00040227633386078995\n",
      "train loss:0.0006161349908009079\n",
      "train loss:0.0030844921157379356\n",
      "train loss:0.004788737258596976\n",
      "train loss:0.0028980468102497675\n",
      "train loss:0.00669529443978464\n",
      "train loss:0.001063195312364673\n",
      "train loss:0.0010112731695279627\n",
      "train loss:0.0009281295473892844\n",
      "train loss:0.0010915622911893178\n",
      "train loss:0.014249619238035957\n",
      "train loss:0.014205877643513434\n",
      "train loss:0.0008919880084763252\n",
      "train loss:0.01040803116732288\n",
      "train loss:0.004268244749434693\n",
      "train loss:0.0015239884981114817\n",
      "train loss:0.0001706571369913299\n",
      "train loss:0.0003921808533845029\n",
      "train loss:0.0007878288604545779\n",
      "train loss:0.0006611482324709996\n",
      "train loss:6.913563056350032e-05\n",
      "train loss:0.006933788174026452\n",
      "train loss:0.0011590273513486784\n",
      "train loss:0.00017801238839818028\n",
      "train loss:0.006572968775720733\n",
      "train loss:0.006278316540149241\n",
      "train loss:0.000260263001739737\n",
      "train loss:0.0035593523069147558\n",
      "train loss:0.01554783454517183\n",
      "train loss:0.0015816913807119234\n",
      "train loss:0.0045377702607013555\n",
      "train loss:0.018562758532730234\n",
      "train loss:0.0005932531725869507\n",
      "train loss:0.0016200006447191157\n",
      "train loss:0.0003982355827937985\n",
      "train loss:0.0017513241083405055\n",
      "train loss:0.0013087178969710066\n",
      "train loss:0.0005476947968422876\n",
      "train loss:0.00031300613621400373\n",
      "train loss:0.0018021087092155073\n",
      "train loss:0.004006945774154656\n",
      "train loss:0.003509269185879316\n",
      "train loss:0.0004310470004293859\n",
      "train loss:0.00941275435444037\n",
      "train loss:0.0013533904561794216\n",
      "train loss:0.0004667510241427987\n",
      "train loss:0.004814210837740038\n",
      "train loss:0.0002474851080948033\n",
      "train loss:0.0034668605125412867\n",
      "train loss:0.0007990059013369439\n",
      "train loss:0.00547532614244992\n",
      "train loss:0.0013486861214208395\n",
      "train loss:0.0030300884413116944\n",
      "train loss:0.000401424390269455\n",
      "train loss:0.0007159109089943808\n",
      "train loss:0.001946442812815874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0003802472458610747\n",
      "train loss:0.0005598894055310927\n",
      "train loss:0.00027704668143844124\n",
      "train loss:0.003000930220708302\n",
      "train loss:0.009688354538006457\n",
      "train loss:0.0033984234248310556\n",
      "train loss:0.008619740602872456\n",
      "train loss:0.0029215657874939022\n",
      "train loss:0.0005696106928124195\n",
      "train loss:0.00022989002161309668\n",
      "train loss:0.0003606748170864036\n",
      "train loss:0.0012170497375760874\n",
      "train loss:0.0007712216398018212\n",
      "train loss:0.03240422779538538\n",
      "train loss:0.013993210014692281\n",
      "train loss:0.00612837391594512\n",
      "train loss:0.00023313951857326516\n",
      "train loss:0.00028060543802693874\n",
      "train loss:0.00044894287397229197\n",
      "train loss:0.0019412328116791206\n",
      "train loss:0.002636143210124768\n",
      "train loss:0.001948705883499117\n",
      "train loss:0.003642833487888099\n",
      "train loss:0.0016590473622509088\n",
      "train loss:0.00017497130736101002\n",
      "train loss:0.00024440379731878914\n",
      "train loss:0.0011833942475963193\n",
      "train loss:0.002292325204516588\n",
      "train loss:0.0016097767131108074\n",
      "train loss:0.0004335086685236364\n",
      "train loss:0.0004042322927504319\n",
      "train loss:0.0013714191195722098\n",
      "train loss:0.00019685029840143953\n",
      "train loss:0.004511622358779728\n",
      "train loss:0.0029622341653862826\n",
      "train loss:0.0007082447404875925\n",
      "train loss:0.001994522406885386\n",
      "train loss:0.0008314354930511116\n",
      "train loss:0.00016756062337416688\n",
      "train loss:0.0034444625545962527\n",
      "train loss:0.00014104130234457224\n",
      "train loss:0.0024049372947172747\n",
      "train loss:0.0002032457839239982\n",
      "train loss:0.00019935820710080706\n",
      "train loss:0.0021155728805650393\n",
      "train loss:0.0014929430063684893\n",
      "train loss:0.0011131783820428106\n",
      "train loss:0.010710552443037561\n",
      "train loss:0.0007805639206208718\n",
      "train loss:0.00018002453634929417\n",
      "train loss:0.0006666037126997352\n",
      "train loss:0.003699676267036261\n",
      "train loss:0.0015238035272327002\n",
      "train loss:0.0007752131560727429\n",
      "train loss:0.00015995810760437103\n",
      "train loss:0.00037731835511254643\n",
      "train loss:0.0021888730136777556\n",
      "train loss:0.005812212580195309\n",
      "train loss:0.025349200503918663\n",
      "train loss:0.0009026221680333717\n",
      "train loss:0.00041789773274017184\n",
      "train loss:0.002882944594571189\n",
      "train loss:0.00011446163313221856\n",
      "train loss:0.0050543043596559326\n",
      "train loss:0.00036501290690269265\n",
      "train loss:0.0017070056645374762\n",
      "train loss:0.0008640826911634547\n",
      "train loss:0.013585324371321244\n",
      "train loss:0.011223107552728772\n",
      "train loss:0.00031702806386469507\n",
      "train loss:0.00010523186570679313\n",
      "train loss:0.0011193350515540576\n",
      "train loss:0.003923216150981901\n",
      "train loss:0.0006612214984281855\n",
      "train loss:0.0042468410115994275\n",
      "train loss:0.00045355868982097894\n",
      "train loss:0.00018884970804088953\n",
      "train loss:0.0005757917194499273\n",
      "train loss:0.005146402085966868\n",
      "train loss:0.004283476228675558\n",
      "train loss:0.005578923655916062\n",
      "train loss:0.0016729792691233237\n",
      "train loss:0.0009984128040480488\n",
      "train loss:0.00398956578602618\n",
      "train loss:9.367766556890556e-05\n",
      "train loss:0.0028157377667560324\n",
      "train loss:0.0016760850559843323\n",
      "train loss:0.001075204060513212\n",
      "train loss:0.0011712726559931677\n",
      "train loss:0.00013933656285885877\n",
      "train loss:0.00026809096122295585\n",
      "train loss:0.0005780947284072807\n",
      "train loss:0.007665345059306222\n",
      "train loss:0.0004954262602328242\n",
      "train loss:0.0005628865533541548\n",
      "train loss:0.002121077095103167\n",
      "train loss:0.0025032786545112463\n",
      "train loss:0.0004616037013250408\n",
      "train loss:0.00019168778063014628\n",
      "train loss:0.002447645298633688\n",
      "train loss:0.0006182142530617417\n",
      "train loss:8.714243823110577e-05\n",
      "train loss:0.0020115811373915844\n",
      "train loss:0.0027222132571901388\n",
      "train loss:0.002878756099280266\n",
      "train loss:0.0022189358499178752\n",
      "train loss:0.006021062292957822\n",
      "train loss:0.0020001340347443708\n",
      "train loss:0.0016049667910748072\n",
      "train loss:0.0010592114512165865\n",
      "train loss:0.001145117137306416\n",
      "train loss:0.0014458281374363597\n",
      "train loss:0.01526206875513249\n",
      "train loss:0.0040284986659229576\n",
      "train loss:0.000640191255718759\n",
      "train loss:0.000532445987141102\n",
      "train loss:0.0003749348881049711\n",
      "train loss:0.000526510128486365\n",
      "train loss:0.0032701720667306787\n",
      "train loss:0.0003412652944265281\n",
      "train loss:0.020925158994668132\n",
      "train loss:0.001812412490086636\n",
      "train loss:0.011503843795614054\n",
      "train loss:0.000686287803920127\n",
      "train loss:0.000823264721223968\n",
      "train loss:0.0003734855493715163\n",
      "train loss:0.003025605310885196\n",
      "train loss:0.004600487478232369\n",
      "train loss:0.0004760090939060761\n",
      "train loss:0.00042904367376744905\n",
      "train loss:0.0002529626778023409\n",
      "train loss:0.0006141876216561176\n",
      "train loss:0.0014107230231855913\n",
      "train loss:0.0002512939660946515\n",
      "train loss:0.0011809904304296013\n",
      "train loss:0.001114134859663175\n",
      "train loss:0.0005999371576463541\n",
      "train loss:0.0016453522241585885\n",
      "train loss:0.001969082035389677\n",
      "train loss:0.006015237724036927\n",
      "train loss:0.0018847913241994807\n",
      "train loss:0.0016883694248818171\n",
      "train loss:0.0011878545147976875\n",
      "train loss:0.0020353876668981817\n",
      "train loss:5.920966375540831e-05\n",
      "train loss:0.0005972395546178076\n",
      "train loss:0.0008573535615426421\n",
      "train loss:0.0032078207124939364\n",
      "train loss:0.0265108692130668\n",
      "train loss:0.00020088677543356575\n",
      "train loss:0.0012999524632915193\n",
      "train loss:0.0006001132460557785\n",
      "train loss:0.00022659663787140963\n",
      "train loss:0.0035397497161585552\n",
      "train loss:0.004004732959890694\n",
      "train loss:0.002104419812891532\n",
      "train loss:0.0005820584640568192\n",
      "train loss:0.0005704240136719897\n",
      "train loss:0.005698309671034642\n",
      "train loss:0.0010484437072665635\n",
      "train loss:0.0011659234696170387\n",
      "train loss:0.00011394173499800658\n",
      "train loss:0.0019225771311713444\n",
      "train loss:0.0029853875960791174\n",
      "train loss:0.000830575310897776\n",
      "train loss:0.005612534992004854\n",
      "train loss:9.121284182905562e-05\n",
      "train loss:0.0007162204453804884\n",
      "train loss:0.006176115605696019\n",
      "train loss:3.2419266128385045e-05\n",
      "train loss:6.565349103350646e-05\n",
      "train loss:0.0002866767014403437\n",
      "train loss:0.0008899328186280941\n",
      "train loss:0.0026594986885395073\n",
      "train loss:0.002398048148327579\n",
      "train loss:0.005871438915964192\n",
      "train loss:0.0005317383100984681\n",
      "train loss:0.00020108234357520992\n",
      "train loss:0.0003430896900020094\n",
      "train loss:0.002288347564793139\n",
      "train loss:0.0006261024663031929\n",
      "train loss:0.005403999106029484\n",
      "train loss:0.0010706370283406553\n",
      "train loss:0.0012486732301780147\n",
      "train loss:0.004143859131877078\n",
      "train loss:0.0004292287491379699\n",
      "train loss:0.00034762744866094155\n",
      "train loss:0.0011549448411363394\n",
      "train loss:0.00022265253349048545\n",
      "train loss:0.0013930387172577273\n",
      "train loss:0.0033515953766995957\n",
      "train loss:0.0029841689851539104\n",
      "train loss:0.001255070513234242\n",
      "train loss:0.00030782333776984143\n",
      "train loss:0.004267708412324931\n",
      "train loss:0.0017954192529375612\n",
      "train loss:0.0003615659532542084\n",
      "train loss:0.00015320089845899788\n",
      "train loss:7.640211416449316e-05\n",
      "train loss:0.0014112239976379756\n",
      "train loss:0.00029408963157673756\n",
      "train loss:0.0008642083469786635\n",
      "train loss:0.000489120237772898\n",
      "train loss:0.00010564697831633861\n",
      "train loss:0.0005210000951544366\n",
      "train loss:0.0059079033301597\n",
      "train loss:0.00014927113222089057\n",
      "train loss:0.0007743946776849643\n",
      "train loss:9.768965898847081e-05\n",
      "train loss:0.0013790885970792366\n",
      "train loss:0.0013999948373466012\n",
      "train loss:0.0014572595848267166\n",
      "train loss:6.61140762171943e-05\n",
      "train loss:0.00042870792054257106\n",
      "train loss:9.769627598355019e-05\n",
      "train loss:0.0012163854918517988\n",
      "train loss:0.00011138606880132807\n",
      "train loss:0.00042889881875423107\n",
      "train loss:0.0004953526048175181\n",
      "train loss:0.0004797400194112393\n",
      "train loss:0.001605627751689327\n",
      "train loss:0.0018628207529446479\n",
      "train loss:0.002266633464819486\n",
      "train loss:0.0011995519041363056\n",
      "train loss:0.0035188129055881046\n",
      "train loss:0.002786825218530678\n",
      "train loss:0.030309144540557772\n",
      "train loss:0.02772543215999542\n",
      "train loss:0.0008274273281902772\n",
      "train loss:0.0008929104983832579\n",
      "train loss:0.0008515057456557444\n",
      "train loss:0.004104161456578043\n",
      "train loss:0.0008639744358345888\n",
      "train loss:0.00027738591320699906\n",
      "train loss:0.0015448548446440318\n",
      "train loss:0.00022674230688929595\n",
      "train loss:0.017106199365013966\n",
      "train loss:0.0011727851907051812\n",
      "train loss:0.0008898870727252723\n",
      "train loss:0.004118081370251856\n",
      "train loss:0.004226776001715537\n",
      "train loss:0.006587642337657597\n",
      "train loss:0.0005531738880443447\n",
      "train loss:0.0004841858019739561\n",
      "train loss:0.0076364650222080855\n",
      "train loss:0.004650626668154646\n",
      "train loss:0.011671059621185255\n",
      "train loss:0.00018446960290686073\n",
      "train loss:0.0007185566011944075\n",
      "train loss:0.005500711282190973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002375566359560061\n",
      "train loss:0.0017652310570627047\n",
      "train loss:0.0015636968130403643\n",
      "train loss:0.002553266255946617\n",
      "train loss:0.0037148056248064824\n",
      "train loss:0.0018162400813962812\n",
      "train loss:5.209647031043439e-05\n",
      "train loss:0.000423776109836949\n",
      "train loss:0.00014580702614703335\n",
      "train loss:0.00033851612839186357\n",
      "train loss:0.0008878407395460529\n",
      "train loss:0.0021287908769842\n",
      "train loss:0.014385342051676717\n",
      "train loss:4.1850607200813915e-05\n",
      "train loss:0.002997614212383856\n",
      "train loss:0.00208319529724774\n",
      "train loss:0.000966159895107466\n",
      "train loss:0.0012790083117528608\n",
      "train loss:0.010196081707088085\n",
      "train loss:0.0006425315655453861\n",
      "train loss:0.0004769174093801902\n",
      "train loss:0.0030090325819109977\n",
      "train loss:0.0012327168572504655\n",
      "train loss:8.252099585166277e-05\n",
      "train loss:0.0006729391889401955\n",
      "train loss:0.0034458991494757\n",
      "train loss:0.0016963677893136898\n",
      "train loss:0.0004654308896134879\n",
      "train loss:0.0006209765421302478\n",
      "train loss:0.002707601744620466\n",
      "train loss:0.006197456494155681\n",
      "train loss:0.007551711061916811\n",
      "train loss:7.585149222499818e-05\n",
      "train loss:0.002009686478900976\n",
      "train loss:0.00016045781340827278\n",
      "train loss:0.0015706989929266716\n",
      "train loss:0.0018897076157519516\n",
      "train loss:0.0006986281972493382\n",
      "train loss:0.0010677377651245766\n",
      "train loss:0.006302739527049259\n",
      "train loss:0.0031498705144994196\n",
      "train loss:0.0003210461663026741\n",
      "train loss:0.0003450099646614498\n",
      "train loss:0.0016986446822497615\n",
      "train loss:0.0044146484295782586\n",
      "train loss:0.0020966876148596925\n",
      "train loss:0.001488213633487111\n",
      "train loss:0.0011374603087297467\n",
      "train loss:0.0005327636264542282\n",
      "train loss:5.619428612403448e-05\n",
      "train loss:3.554205883749746e-05\n",
      "train loss:0.00010150537821769594\n",
      "train loss:0.0007893271197455581\n",
      "train loss:0.002838821654188195\n",
      "train loss:0.00104179828454549\n",
      "train loss:0.00020112973982697776\n",
      "train loss:0.00018470577553890462\n",
      "train loss:0.0001378089920918068\n",
      "train loss:0.001970292607496273\n",
      "train loss:0.0007569391324580356\n",
      "train loss:0.0027833553137739065\n",
      "train loss:0.0001796728809940765\n",
      "train loss:0.004720749834825665\n",
      "train loss:0.009393156308390035\n",
      "train loss:0.00035166753708739935\n",
      "train loss:0.0009405828372119465\n",
      "train loss:0.001078914691990556\n",
      "train loss:0.00014935494547099008\n",
      "train loss:0.003676386385002107\n",
      "train loss:0.00014623236675241486\n",
      "train loss:0.00015937992611941883\n",
      "train loss:0.0004442063575625916\n",
      "train loss:0.0013372986237441397\n",
      "train loss:0.0003159067811221813\n",
      "train loss:0.0019420459053273644\n",
      "train loss:0.0033090875759361938\n",
      "train loss:0.00012636693139453682\n",
      "train loss:0.009804118205999362\n",
      "train loss:0.0006491368635554924\n",
      "train loss:0.0004465186566705813\n",
      "train loss:0.0008293798780699335\n",
      "train loss:0.002076439306509707\n",
      "train loss:0.005523006725496815\n",
      "train loss:0.00029873766522436787\n",
      "train loss:0.0013142339228152506\n",
      "train loss:0.010824821429349336\n",
      "train loss:0.0007000020763195708\n",
      "train loss:0.0012629021483225949\n",
      "train loss:0.00028334800110652947\n",
      "train loss:0.00038397015100967164\n",
      "train loss:0.002371959008683932\n",
      "train loss:0.00025146856731949653\n",
      "train loss:0.002012901826293546\n",
      "train loss:0.0020500495205949816\n",
      "train loss:0.001158683087321284\n",
      "train loss:0.008524061750692057\n",
      "train loss:0.0037718006721346813\n",
      "train loss:0.001481625985847155\n",
      "train loss:0.0006399857052535733\n",
      "train loss:0.000788874515924604\n",
      "train loss:0.0013704568696339264\n",
      "train loss:0.0010093329361545798\n",
      "train loss:0.001342589887186165\n",
      "train loss:0.0010395389139635075\n",
      "train loss:0.0011011802661739707\n",
      "train loss:0.004075359107154847\n",
      "train loss:0.002758147005412096\n",
      "train loss:0.0011214374847332883\n",
      "train loss:6.408924137403429e-05\n",
      "train loss:0.00024090952540173287\n",
      "train loss:0.0003830394521588178\n",
      "train loss:0.0017812679462191647\n",
      "train loss:0.00044715541005234275\n",
      "train loss:0.00042087075820275167\n",
      "train loss:0.0010727638845758965\n",
      "train loss:0.0009835370892247286\n",
      "train loss:0.00024200327823892096\n",
      "train loss:0.0008947465821103339\n",
      "train loss:0.002871884543480484\n",
      "train loss:0.0009417053655219884\n",
      "train loss:0.00023694535920154198\n",
      "train loss:0.002982444288004498\n",
      "train loss:0.0012796519201327356\n",
      "train loss:9.956003411808123e-05\n",
      "train loss:0.001573388153145746\n",
      "train loss:0.0006215633996646354\n",
      "train loss:0.0013434106428841645\n",
      "train loss:0.0008358910714971369\n",
      "train loss:0.0002009751360258493\n",
      "train loss:0.0003303818089798263\n",
      "train loss:0.0007728727847589559\n",
      "train loss:0.00032981052400292323\n",
      "train loss:0.00012256583132741288\n",
      "train loss:0.0015950552101672883\n",
      "train loss:0.0020760922917682383\n",
      "train loss:0.0005345752626119706\n",
      "train loss:0.006091595395417006\n",
      "train loss:0.004707865394228881\n",
      "train loss:0.0009599749469470332\n",
      "train loss:0.0005113053162061223\n",
      "train loss:0.0005017896963830359\n",
      "train loss:0.00052615635318384\n",
      "train loss:2.5934658971729583e-05\n",
      "train loss:0.001410494330828807\n",
      "train loss:0.00041962104051967096\n",
      "train loss:0.002001921915970105\n",
      "train loss:0.0007689063569039055\n",
      "train loss:0.00022398082252506074\n",
      "train loss:0.0020580862606631935\n",
      "train loss:0.0011177579562892672\n",
      "train loss:0.0011842719613965715\n",
      "train loss:0.0030754332847820988\n",
      "train loss:0.000434288810422645\n",
      "train loss:0.00247641302346375\n",
      "train loss:0.004053884907861867\n",
      "train loss:0.00029081706887195113\n",
      "train loss:0.0007639089869292766\n",
      "train loss:0.0022624289944496246\n",
      "train loss:8.410155940509018e-06\n",
      "train loss:0.0002937294402599437\n",
      "train loss:0.0005758024630219002\n",
      "train loss:0.0007113384132302638\n",
      "train loss:0.004121592268846391\n",
      "train loss:0.0011966186621609088\n",
      "train loss:0.0010169568806904922\n",
      "train loss:0.002185708964188693\n",
      "train loss:0.0013202740405183768\n",
      "train loss:0.00013913424511128092\n",
      "train loss:0.0010894817999054435\n",
      "train loss:0.0005754492074556054\n",
      "train loss:0.0016081762990636365\n",
      "train loss:0.0020695215920599817\n",
      "train loss:0.0026016713715150057\n",
      "train loss:0.00022470738066965329\n",
      "train loss:0.0027720759445284925\n",
      "train loss:0.0004409576680008742\n",
      "train loss:0.0016629092873991164\n",
      "train loss:0.0005111494407057653\n",
      "=== epoch:18, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.0022474660081180375\n",
      "train loss:0.0030255882424451036\n",
      "train loss:0.005796752693510443\n",
      "train loss:6.305162989508996e-05\n",
      "train loss:0.0031073866316522532\n",
      "train loss:0.00035971100616938165\n",
      "train loss:0.0002955405822828081\n",
      "train loss:8.812701478637009e-05\n",
      "train loss:0.007263631783520002\n",
      "train loss:0.0052169136585203625\n",
      "train loss:0.0005860139808345359\n",
      "train loss:0.0062238882639013785\n",
      "train loss:0.0009625112055804056\n",
      "train loss:0.0004512375606105499\n",
      "train loss:0.0021999059501222884\n",
      "train loss:0.00014878943909144837\n",
      "train loss:0.00013817978135215346\n",
      "train loss:0.013996624469728734\n",
      "train loss:0.00023982454161694286\n",
      "train loss:0.000407352477601811\n",
      "train loss:0.0018705982774962096\n",
      "train loss:6.147798867732721e-06\n",
      "train loss:0.00010117112439105846\n",
      "train loss:0.0001204755443414959\n",
      "train loss:0.0006693143488299088\n",
      "train loss:0.0006625366474738045\n",
      "train loss:0.0005633141785794319\n",
      "train loss:0.010829712232728321\n",
      "train loss:0.0006820419308854196\n",
      "train loss:0.00024239992135308133\n",
      "train loss:0.0016052616292953356\n",
      "train loss:4.1385743150260253e-05\n",
      "train loss:0.002193840062846448\n",
      "train loss:0.0001667079454710651\n",
      "train loss:0.0006330183813287641\n",
      "train loss:0.00021411181751834958\n",
      "train loss:0.0011769612638650687\n",
      "train loss:0.009108949449331995\n",
      "train loss:0.0006808929514208434\n",
      "train loss:0.0003890885232520924\n",
      "train loss:0.0016306798748167042\n",
      "train loss:0.0006646046051701018\n",
      "train loss:0.0010205778819467402\n",
      "train loss:0.0018161071092727863\n",
      "train loss:0.0028374816451439138\n",
      "train loss:0.001799666411618825\n",
      "train loss:0.0015880537627814464\n",
      "train loss:0.0016039896239828989\n",
      "train loss:0.00038090874098638066\n",
      "train loss:0.0009831283493542974\n",
      "train loss:0.0003934353515000263\n",
      "train loss:0.0054547798809665695\n",
      "train loss:0.002117587205042289\n",
      "train loss:0.001499320940974399\n",
      "train loss:0.0032545189662477676\n",
      "train loss:0.019628572615667896\n",
      "train loss:7.612595402325558e-05\n",
      "train loss:0.0005618822745791516\n",
      "train loss:0.00011313615984456659\n",
      "train loss:0.0005797591023651114\n",
      "train loss:0.0017794527632487706\n",
      "train loss:0.0011291859483973897\n",
      "train loss:0.000512958893501406\n",
      "train loss:0.0005446731934726026\n",
      "train loss:0.003111793017980718\n",
      "train loss:0.0015601896602745558\n",
      "train loss:0.0011397918737240736\n",
      "train loss:0.0014061214302328936\n",
      "train loss:0.0006578269091375734\n",
      "train loss:0.001063239543528586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:7.26941397053121e-05\n",
      "train loss:0.0005040294567530875\n",
      "train loss:0.0011385983421653633\n",
      "train loss:0.002182041367285257\n",
      "train loss:0.0028101769144851753\n",
      "train loss:0.00044807465941932586\n",
      "train loss:0.00013845979431474428\n",
      "train loss:0.0006876684312496785\n",
      "train loss:2.073535034776574e-05\n",
      "train loss:0.005045253649753096\n",
      "train loss:0.003095303439391131\n",
      "train loss:0.001345811561699587\n",
      "train loss:0.0014412429393835305\n",
      "train loss:0.0026037475866521847\n",
      "train loss:0.0010577969166667563\n",
      "train loss:0.0013496420548710928\n",
      "train loss:0.002890537866217683\n",
      "train loss:0.0038759318808511156\n",
      "train loss:0.00018213983671220156\n",
      "train loss:0.00215896780401942\n",
      "train loss:0.00016869926939511496\n",
      "train loss:1.2433707888303025e-05\n",
      "train loss:0.0009313235402093543\n",
      "train loss:0.04356910956297076\n",
      "train loss:0.002920751638983431\n",
      "train loss:0.002133962325963391\n",
      "train loss:0.004167648140819966\n",
      "train loss:0.00708201706191491\n",
      "train loss:0.00046374469500508526\n",
      "train loss:0.001423455357935774\n",
      "train loss:0.0004656689017368558\n",
      "train loss:0.001618370068507605\n",
      "train loss:0.004625388515716978\n",
      "train loss:0.01035668203778617\n",
      "train loss:0.002201438990576098\n",
      "train loss:0.0029954596443985504\n",
      "train loss:0.003966971839690325\n",
      "train loss:0.002864479595224629\n",
      "train loss:0.0014821461723231574\n",
      "train loss:0.000166905256893454\n",
      "train loss:0.0007560022844885885\n",
      "train loss:0.0023161051678072943\n",
      "train loss:0.0715485495323793\n",
      "train loss:6.269689616089641e-05\n",
      "train loss:0.00048705946388019215\n",
      "train loss:0.0003915638121755044\n",
      "train loss:0.002680762665542547\n",
      "train loss:0.0006694897648644171\n",
      "train loss:0.001830545484238867\n",
      "train loss:0.0008049358569407528\n",
      "train loss:0.0003095149752598318\n",
      "train loss:0.00466023781843303\n",
      "train loss:0.0013863113293045562\n",
      "train loss:0.001847492407649679\n",
      "train loss:0.02035580650375211\n",
      "train loss:0.0033688793576518994\n",
      "train loss:0.0002022148825191892\n",
      "train loss:0.0014267503115335124\n",
      "train loss:0.0019197816653085257\n",
      "train loss:0.0006803478656529735\n",
      "train loss:0.0004941265282928319\n",
      "train loss:0.009669472247263744\n",
      "train loss:0.00015783114456113272\n",
      "train loss:0.0006347718587936075\n",
      "train loss:0.00159761770023554\n",
      "train loss:0.0012125868022310332\n",
      "train loss:0.017879459995966525\n",
      "train loss:0.0011210879301397603\n",
      "train loss:0.0011325390481514601\n",
      "train loss:0.00239078680802733\n",
      "train loss:0.0005459384518173803\n",
      "train loss:0.0026473406226322537\n",
      "train loss:0.004346678944598622\n",
      "train loss:0.0007866576841643517\n",
      "train loss:0.0008716838737294975\n",
      "train loss:0.0005756647330257874\n",
      "train loss:0.0013657021731406285\n",
      "train loss:0.0016861683378937575\n",
      "train loss:0.0008896011495111128\n",
      "train loss:0.0029747976769493585\n",
      "train loss:0.001345471976317502\n",
      "train loss:0.00026762629762745374\n",
      "train loss:0.0027399247086630925\n",
      "train loss:0.00012871675304052335\n",
      "train loss:0.0022501740454737495\n",
      "train loss:0.0004777875546445281\n",
      "train loss:0.0022701033084081474\n",
      "train loss:0.0007707645073687255\n",
      "train loss:0.004806861174856334\n",
      "train loss:0.0001711893133666796\n",
      "train loss:0.001456594021744359\n",
      "train loss:0.0067034220735004025\n",
      "train loss:0.00099424473646616\n",
      "train loss:0.0015295514360997697\n",
      "train loss:0.0011099622177628066\n",
      "train loss:0.00085449245688294\n",
      "train loss:0.0002749290613782511\n",
      "train loss:0.006348253991652627\n",
      "train loss:0.007010069010396553\n",
      "train loss:0.001212070076326334\n",
      "train loss:0.0014091873255553445\n",
      "train loss:0.00346086131150866\n",
      "train loss:0.014449460369032607\n",
      "train loss:0.0003192493020556586\n",
      "train loss:0.0006840810157379972\n",
      "train loss:0.008285299376055835\n",
      "train loss:0.002739110408068973\n",
      "train loss:0.0024776186405501537\n",
      "train loss:0.001288079905937707\n",
      "train loss:0.0008846880223672328\n",
      "train loss:0.0040626191106064675\n",
      "train loss:0.0013719701010468542\n",
      "train loss:0.007379313346226962\n",
      "train loss:0.00012375080680704232\n",
      "train loss:0.0002981313229020148\n",
      "train loss:0.0017073062728691706\n",
      "train loss:0.001152955687755372\n",
      "train loss:0.001451135401489012\n",
      "train loss:0.0012774187174624642\n",
      "train loss:0.0008733695318918473\n",
      "train loss:0.027525677805576097\n",
      "train loss:0.001254819112165009\n",
      "train loss:0.006349452194967015\n",
      "train loss:0.0008590554220061431\n",
      "train loss:0.0013009311922525773\n",
      "train loss:0.002791725494693571\n",
      "train loss:0.0007905882245649681\n",
      "train loss:0.0011646324878097645\n",
      "train loss:0.0017514412735579873\n",
      "train loss:2.739781440840984e-05\n",
      "train loss:0.0010302614290700312\n",
      "train loss:0.004197649262442354\n",
      "train loss:0.002595070317606714\n",
      "train loss:0.0007720522395615986\n",
      "train loss:0.0015587804453936135\n",
      "train loss:0.008266472797118379\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 CNN  시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1 1번째 층의 가중치 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무엇을 보고 있는 것일까?\n",
    "- 에지(색상이 바뀐 경계선), 블롭(국소적으로 덩어리진 영역) 등\n",
    "- 예: 세로 에지(필터1)과 가로 에지(필터2)에 반응하는 필터\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/999F114D5C4D500610\">\n",
    "- 초기 계층에서 필터는 원시적인 정보를 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2 층 깊이에 따른 추출 정보 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계층이 깊어질수록 추출되는 정보(강하게 반응하는 뉴런)는 더 추상화된다.\n",
    "- 예: AlexNet\n",
    "    - 일반 사물 인식 8층 CNN\n",
    "    - 마지막 층은 완전연결 계층\n",
    "    - 1층: 에지와 블롭, 3층 텍스쳐, 5층: 사물의 일부, 마지막층: 사물의 클래스에 주로 반응\n",
    "    - 깊어질 수록 사물의 의미를 이해하도록 변화\n",
    "    <img src=\"https://t1.daumcdn.net/cfile/tistory/99AF37505C4D514115\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 대표적인 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.1 LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99145F445C4D51F114\">\n",
    "\n",
    "- CNN의 원조\n",
    "- 손글씨 숫자 인식 네트워크\n",
    "- 합성곱과 서브 샘플링 계층 반복\n",
    "    - 현재는 서브 샘플링 대신 최대 풀링\n",
    "    - 서브 샘플링은 2X2 필터로 average pooling\n",
    "- 마지막 층: 완전연결 계층\n",
    "- 활성화 함수: sigmoid\n",
    "    - 현재는 주로 ReLU 함수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.2 AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99B4DA3B5C4D52B515\">\n",
    "\n",
    "- 딥러닝 돌풍의 주역\n",
    "- LeNet과 큰 구조에서는 유사\n",
    "- 변경점\n",
    "    - 활성화 함수: ReLU\n",
    "    - LRN(local response normalization): 국소적 정규화 계층\n",
    "    - 드롭아웃\n",
    "    \n",
    "딥러닝의 발전 원동력은?\n",
    "- 빅데이터\n",
    "- GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
